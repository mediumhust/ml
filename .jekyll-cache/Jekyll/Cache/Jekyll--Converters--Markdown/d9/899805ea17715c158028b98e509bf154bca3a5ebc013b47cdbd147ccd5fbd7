I"(°<p><strong>Trong trang n√†y:</strong></p>

<!-- MarkdownTOC -->

<ul>
  <li><a href="#-gioi-thieu">1. Gi·ªõi thi·ªáu</a></li>
  <li><a href="#-maximum-likelihood-estimation">2. Maximum Likelihood Estimation</a>
    <ul>
      <li><a href="#-y-tuong">2.1. √ù t∆∞·ªüng</a></li>
      <li><a href="#-independence-assumption-va-log-likelihood">2.2. Independence Assumption v√† log-likelihood</a></li>
      <li><a href="#-vi-du">2.3. V√≠ d·ª•</a>
        <ul>
          <li><a href="#-vi-du--bernoulli-distribution">2.3.1. V√≠ d·ª• 1: Bernoulli distribution</a></li>
          <li><a href="#-vi-du--categorical-distribution">2.3.2. V√≠ d·ª• 2: Categorical distribution</a></li>
          <li><a href="#-vi-du--univariate-normal-distribution">2.3.3. V√≠ d·ª• 3: Univariate normal distribution</a></li>
          <li><a href="#-vi-du--multivariate-normal-distribution">2.3.4. V√≠ d·ª• 4: Multivariate normal distribution</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#-maximum-a-posteriori">3. Maximum a Posteriori</a>
    <ul>
      <li><a href="#-y-tuong-1">3.1. √ù t∆∞·ªüng</a></li>
      <li><a href="#-conjugate-prior">3.2. Conjugate prior</a></li>
      <li><a href="#-hyperparameters">3.3. Hyperparameters</a></li>
      <li><a href="#-map-giup-tranh-overfitting">3.4. MAP gi√∫p tr√°nh overfitting</a></li>
    </ul>
  </li>
  <li><a href="#-tom-tat">4. T√≥m t·∫Øt</a></li>
  <li><a href="#-tai-lieu-tham-khao">5. T√†i li·ªáu tham kh·∫£o</a></li>
</ul>

<!-- /MarkdownTOC -->

<p><a name="-gioi-thieu"></a></p>

<h2 id="1-gi·ªõi-thi·ªáu">1. Gi·ªõi thi·ªáu</h2>
<p><strong>Nh·ªØng s·ª± ki·ªán c√≥ x√°c su·∫•t cao l√† nh·ªØng s·ª± ki·ªán c√≥ kh·∫£ nƒÉng x·∫£y ra h∆°n.</strong></p>

<p>C√¢u n√≥i <em>n√≥i c≈©ng nh∆∞ kh√¥ng n√†y</em> l√† kh∆°i ngu·ªìn cho r·∫•t nhi·ªÅu c√°c thu·∫≠t to√°n Machine Learning c√≥ li√™n quan ƒë·∫øn x√°c su·∫•t.</p>

<p>C√°ch gi·∫£i quy·∫øt b√†i to√°n Machine Learning c√≥ th·ªÉ vi·∫øt g·ªçn l·∫°i th√†nh 3 b∆∞·ªõc ch√≠nh: <strong>Modeling, Learning</strong> v√† <strong>Inference</strong>. (Xem <a href="http://www.computervisionmodels.com/">Computer Vision: Models, Learning, and Inference</a>)</p>

<p><strong>Modeling l√† vi·ªác ƒëi t√¨m m√¥t m√¥ h√¨nh th√≠ch h·ª£p cho b√†i to√°n c·∫ßn gi·∫£i quy·∫øt.</strong> V·ªõi b√†i to√°n <a href="/2016/12/28/linearregression/">Linear Regression</a>, modeling ch√≠nh l√† vi·ªác m√¥ h√¨nh d·ªØ li·ªáu ƒë·∫ßu ra (output) nh∆∞ l√† t·ªï h·ª£p tuy·∫øn t√≠nh c·ªßa d·ªØ li·ªáu ƒë·∫ßu v√†o (input). V·ªõi b√†i to√°n <a href="/2017/01/01/kmeans/">k-means clustering</a>, modeling ch√≠nh l√† vi·ªác quan s√°t ra r·∫±ng c√°c clusters th∆∞·ªùng ƒë∆∞·ª£c m√¥ t·∫£ b·ªüi c√°c <em>centroids</em> (ho·∫∑c <em>centers</em>) v√† m·ªói ƒëi·ªÉm ƒë∆∞·ª£c x·∫øp v√†o cluster t∆∞∆°ng ·ª©ng v·ªõi centroid g·∫ßn n√≥ nh·∫•t. Trong b√†i to√°n <a href="/2017/04/09/smv/">Support Vector Machine</a> cho d·ªØ li·ªáu linearly separable, modeling ch√≠nh l√† b∆∞·ªõc quan s√°t th·∫•y r·∫±ng ƒë∆∞·ªùng th·∫≥ng ph√¢n chia hai classes ph·∫£i l√† ƒë∆∞·ªùng l√†m cho margin ƒë·∫°t gi√° tr·ªã l·ªõn nh·∫•t. Vi·ªác ƒëi t√¨m ra m√¥ h√¨nh n√†o ph√π h·ª£p cho b√†i to√°n ch√≠nh l√† b∆∞·ªõc <strong>Modeling</strong>.</p>

<p><strong>Learning l√† b∆∞·ªõc ti·∫øn h√†nh t·ªëi ∆∞u c√°c tham s·ªë c·ªßa m√¥ h√¨nh.</strong> M·ªói model ƒë∆∞·ª£c m√¥ h√¨nh b·ªüi m·ªôt b·ªô c√°c tham s·ªë (parameters). V·ªõi Linear Regression, tham s·ªë m√¥ h√¨nh l√† b·ªô vector h·ªá s·ªë v√† bias \((\mathbf{w}, b)\). V·ªõi K-means clustering, tham s·ªë m√¥ h√¨nh c√≥ th·ªÉ ƒë∆∞·ª£c coi l√† c√°c clusters. V·ªõi Support Vector Machine, tham s·ªë m√¥ h√¨nh c√≥ th·ªÉ l√† vector h·ªá s·ªë v√† bias m√¥ t·∫£ ƒë∆∞·ªùng th·∫±ng \((\mathbf{w}, b)\). Vi·ªác ƒëi t√¨m c√°c tham s·ªë cho m√¥ h√¨nh th∆∞·ªùng ƒë∆∞·ª£c th·ª±c hi·ªán b·∫±ng vi·ªác gi·∫£i m·ªôt b√†i to√°n t·ªëi ∆∞u. Qu√° tr√¨nh gi·∫£i b√†i to√°n t·ªëi ∆∞u, hay ch√≠nh l√† qu√° tr√¨nh ƒëi t√¨m tham s·ªë c·ªßa m√¥ h√¨nh, ch√≠nh l√† qu√° tr√¨nh <strong>Learning</strong>. Sau b∆∞·ªõc Learning n√†y, ch√∫ng ta thu ƒë∆∞·ª£c c√°c <em>trained parameters</em>.</p>

<p><strong>Inference l√† b∆∞·ªõc d·ª± ƒëo√°n ouput c·ªßa m√¥ h√¨nh d·ª±a tr√™n c√°c trained parameters.</strong> V·ªõi Linear Regression, Inference ch√≠nh l√† vi·ªác t√≠nh \(y = \mathbf{w}^T\mathbf{x} + b\) d·ª±a tr√™n b·ªô c√°c tham s·ªë ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán \((\mathbf{w}, b)\). V·ªõi K-means clustering, vi·ªác Inference ch√≠nh l√† vi·ªác ƒëi t√¨m centroid g·∫ßn nh·∫•t. V·ªõi Support Vector Machine, Inference ch√≠nh l√† vi·ªác x√°c ƒë·ªãnh class c·ªßa m·ªôt d·ªØ li·ªáu m·ªõi d·ª±a v√†o c√¥ng th·ª©c \(y = \text{sgn}(\mathbf{w}^T\mathbf{x} + b)\). So v·ªõi hai b∆∞·ªõc Modeling v√† Learning, Inference th∆∞·ªùng ƒë∆°n gi·∫£n h∆°n.</p>

<p>Nh∆∞ ƒë√£ ƒë·ªÅ c·∫≠p, ·ªü n·ª≠a sau c·ªßa blog, t√¥i s·∫Ω gi·ªõi thi·ªáu r·∫•t nhi·ªÅu c√°c m√¥ h√¨nh th·ªëng k√™. Trong c√°c m√¥ h√¨nh n√†y, vi·ªác <em>Modeling</em> l√† vi·ªác ƒëi t√¨m m·ªôt m√¥ h√¨nh th·ªëng k√™ (statistical model) ph√π h·ª£p v·ªõi t·ª´ng lo·∫°i d·ªØ li·ªáu v√† b√†i to√°n. Vi·ªác <em>Learning</em> l√† vi·ªác ƒëi t√¨m c√°c tham s·ªë cho m√¥ h√¨nh th·ªëng k√™ ƒë√≥. Vi·ªác <em>Inference</em> c√≥ th·ªÉ coi l√† vi·ªác t√≠nh x√°c su·∫•t ƒë·ªÉ x·∫£y ra m·ªói gi√° tr·ªã ·ªü ƒë·∫ßu ra khi bi·∫øt c√°c gi√° tr·ªã ·ªü ƒë·∫ßu v√†o v√† model ƒë∆∞·ª£c m√¥ t·∫£ b·ªüi c√°c trained parameters.</p>

<p>C√°c M√¥ H√¨nh Th·ªëng K√™ (Statistical Models) th∆∞·ªùng l√† s·ª± k·∫øt h·ª£p c·ªßa c√°c <a href="/2017/07/09/prob/#-mot-vai-xac-suat-thuong-gap.">ph√¢n ph·ªëi x√°c su·∫•t ƒë∆°n gi·∫£n</a>. V·ªõi <a href="/2017/07/09/prob/#-bernouli-distribution">Bernoulli distribution</a>, tham s·ªë l√† bi·∫øn \(\lambda\). V·ªõi <a href="/2017/07/09/prob/#-multivariate-normal-distribution">Multivariate Normal Distribution</a>, tham s·ªë l√† mean vector \(\mu\) v√† ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai \(\Sigma\). V·ªõi m·ªôt m√¥ h√¨nh th√¥ng k√™ b·∫•t k·ª≥, k√Ω hi·ªáu \(\theta\) l√† t·∫≠p h·ª£p t·∫•t c·∫£ c√°c tham s·ªë c·ªßa m√¥ h√¨nh ƒë√≥. Learning ch√≠nh l√† qu√° tr√¨nh ƒë√°nh gi√° (estimate) b·ªô tham s·ªë \(\theta\) sao cho d·ªØ li·ªáu s·∫µn c√≥ v√† m√¥ h√¨nh <em>kh·ªõp</em> v·ªõi nhau nh·∫•t. Qu√° tr√¨nh ƒë√≥ c√≤n ƒë∆∞·ª£c g·ªçi l√† <em>parameter estimation</em>.</p>

<p>C√≥ hai c√°ch ƒë√°nh gi√° tham s·ªë th∆∞·ªùng ƒë∆∞·ª£c d√πng trong Statistical Machine Learning. C√°ch th·ª© nh·∫•t ch·ªâ d·ª±a tr√™n d·ªØ li·ªáu ƒë√£ bi·∫øt trong t·∫≠p traing (training data), ƒë∆∞·ª£c g·ªçi l√† <em>Maximum Likelihood Estimation</em> hay <em>ML Estimation</em> ho·∫∑c <em>MLE</em>. C√°ch th·ª© hai kh√¥ng nh·ªØng d·ª±a tr√™n training data m√† c√≤n d·ª±a tr√™n nh·ªØng th√¥ng tin ƒë√£ bi·∫øt c·ªßa c√°c tham s·ªë. Nh·ªØng th√¥ng tin n√†y c√≥ th·ªÉ c√≥ ƒë∆∞·ª£c b·∫±ng <em>c·∫£m quan</em> c·ªßa ng∆∞·ªùi x√¢y d·ª±ng m√¥ h√¨nh. <em>C·∫£m quan</em> c√†ng r√µ r√†ng, c√†ng h·ª£p l√Ω th√¨ kh·∫£ nƒÉng thu ƒë∆∞·ª£c b·ªô tham s·ªë t·ªët l√† c√†ng cao. Ch·∫≥ng h·∫°n, th√¥ng tin bi·∫øt tr∆∞·ªõc c·ªßa \(\lambda\) trong Bernoulli distribution l√† vi·ªác n√≥ l√† m·ªôt s·ªë trong ƒëo·∫°n \([0, 1]\). V·ªõi b√†i to√°n tung ƒë·ªìng xu, v·ªõi \(\lambda\) l√† x√°c su·∫•t c√≥ ƒë∆∞·ª£c m·∫∑t <em>head</em>, ta d·ª± ƒëo√°n ƒë∆∞·ª£c r·∫±ng gi√° tr·ªã n√†y n√™n l√† m·ªôt s·ªë g·∫ßn v·ªõi \(0.5\). C√°ch ƒë√°nh gi√° tham s·ªë th·ª© hai n√†y ƒë∆∞·ª£c g·ªçi l√† <em>Maximum A Posteriori Estimation</em> hay <em>MAP Estimation</em>.</p>

<p>Trong b√†i vi·∫øt n√†y, t√¥i s·∫Ω tr√¨nh b√†y v·ªÅ √Ω t∆∞·ªüng v√† c√°ch gi·∫£i quy·∫øt b√†i to√°n ƒë√°nh gi√° tham s·ªë m√¥ h√¨nh theo <em>MLE</em> ho·∫∑c <em>MAP Estimation</em>. V√† nh∆∞ th∆∞·ªùng l·ªá, ch√∫ng ta s·∫Ω c√πng th·ª±c hi·ªán m·ªô v√†i v√≠ d·ª• ƒë∆°n gi·∫£n.</p>

<p><a name="-maximum-likelihood-estimation"></a></p>

<h2 id="2-maximum-likelihood-estimation">2. Maximum Likelihood Estimation</h2>

<p><a name="-y-tuong"></a></p>

<h3 id="21-√Ω-t∆∞·ªüng">2.1. √ù t∆∞·ªüng</h3>
<p>Gi·∫£ s·ª≠ c√≥ c√°c ƒëi·ªÉm d·ªØ li·ªáu \(\mathbf{x}_1, \mathbf{x}_2, \dots, \mathbf{x}_N\). Gi·∫£ s·ª≠ th√™m r·∫±ng ta ƒë√£ bi·∫øt c√°c ƒëi·ªÉm d·ªØ li·ªáu n√†y tu√¢n theo m·ªôt ph√¢n ph·ªëi n√†o ƒë√≥ ƒë∆∞·ª£c m√¥ t·∫£ b·ªüi b·ªô tham s·ªë \(\theta\).
<!-- V·ªõi c√°c b√†i to√°n Supervised Learning, m·ªói ƒëi·ªÉm d·ªØ li·ªáu n√†y c√≥ th·ªÉ coi nh∆∞ ƒë√£ bao g·ªìm c·∫£ ƒë·∫ßu ra. --></p>

<p>Maximum Likelihood Estimation l√† vi·ªác ƒëi t√¨m b·ªô tham s·ªë \(\theta\) sao cho x√°c su·∫•t sau ƒë√¢y ƒë·∫°t gi√° tr·ªã l·ªõn nh·∫•t:</p>

<p>\[
\theta = \max_{\theta} p(\mathbf{x}_1, \dots, \mathbf{x}_N | \theta) ~~~~ (1)
\]</p>

<p>Bi·ªÉu th·ª©c \((1)\) c√≥ √Ω nghƒ©a nh∆∞ th·∫ø n√†o v√† v√¨ sao vi·ªác n√†y c√≥ l√Ω?</p>

<p>Gi·∫£ s·ª≠ r·∫±ng ta ƒë√£ bi·∫øt m√¥ h√¨nh r·ªìi, v√† m√¥ h√¨nh n√†y ƒë∆∞·ª£c m√¥ t·∫£ b·ªüi b·ªô tham s·ªë \(\theta\). Th·∫ø th√¨, \(p(\mathbf{x}_1 | \theta)\) ch√≠nh l√† x√°c su·∫•t x·∫£y ra <em>s·ª± ki·ªán</em> \(\mathbf{x}_1\) bi·∫øt r·∫±ng m√¥ h√¨nh l√† (ƒë∆∞·ª£c m√¥ t·∫£ b·ªüi) \(\theta\) (ƒë√¢y l√† m·ªôt <a href="/2017/07/09/prob/#-conditional-probability">conditional probability</a>). V√† \(p(\mathbf{x}_1, \dots, \mathbf{x}_N | \theta)\) ch√≠nh l√† x√°c su·∫•t ƒë·ªÉ to√†n b·ªô c√°c <em>s·ª± ki·ªán</em> \(\mathbf{x}_1, \mathbf{x}_2, \dots, \mathbf{x}_N\) x·∫£y ra ƒë·ªìng th·ªùi (n√≥ l√† m·ªôt <a href="/2017/07/09/prob/#-joint-probability">joint probability</a>), x√°c su·∫•t ƒë·ªìng th·ªùi n√†y c√≤n ƒë∆∞·ª£c g·ªçi l√† <em>likelihood</em>. ·ªû ƒë√¢y, <em>likelihood</em> ch√≠nh l√† h√†m m·ª•c ti√™u.</p>

<p>B·ªüi v√¨ <em>s·ª± ƒë√£ r·ªìi</em>, t·ª©c d·ªØ li·ªáu training b·∫£n th√¢n n√≥ ƒë√£ l√† nh∆∞ th·∫ø r·ªìi, x√°c su·∫•t ƒë·ªìng th·ªùi n√†y c·∫ßn ph·∫£i c√†ng cao c√†ng t·ªët. Vi·ªác n√†y c≈©ng gi·ªëng nh∆∞ vi·ªác ƒë√£ bi·∫øt <em>k·∫øt qu·∫£</em>, v√† ta c·∫ßn ƒëi t√¨m <em>nguy√™n nh√¢n</em> sao cho x√°c su·∫•t x·∫£y ra k·∫øt qu·∫£ n√†y c√†ng cao c√†ng t·ªët.</p>

<p>Maximum Likelihood ch√≠nh l√† vi·ªác ƒëi t√¨m b·ªô tham s·ªë \(\theta\) sao cho Likelihood l√† l·ªõn nh·∫•t.</p>

<p><a name="-independence-assumption-va-log-likelihood"></a></p>

<h3 id="22-independence-assumption-v√†-log-likelihood">2.2. Independence Assumption v√† log-likelihood</h3>
<p>Vi·ªác gi·∫£i tr·ª±c ti·∫øp b√†i to√°n \((1)\) th∆∞·ªùng l√† ph·ª©c t·∫°p v√¨ vi·ªác ƒëi t√¨m m√¥ h√¨nh x√°c su·∫•t ƒë·ªìng th·ªùi cho to√†n b·ªô d·ªØ li·ªáu l√† √≠t khi kh·∫£ thi. M·ªôt c√°ch ti·∫øp c·∫≠n ph·ªï bi·∫øn l√† gi·∫£ s·ª≠ ƒë∆°n gi·∫£n r·∫±ng c√°c ƒëi·ªÉm d·ªØ li·ªáu \(\mathbf{x}_n\) l√† <a href="/2017/07/09/prob/#-independence">ƒë·ªôc l·∫≠p</a> v·ªõi nhau, n·∫øu bi·∫øt tham s·ªë m√¥ h√¨nh \(\theta\) (ƒë·ªôc l·∫≠p c√≥ ƒëi·ªÅu ki·ªán). N√≥i c√°ch kh√°c, ta x·∫•p x·ªâ likelihood trong \((1)\) b·ªüi:
\[
p(\mathbf{x}_1, \dots, \mathbf{x}_N | \theta) \approx \prod_{n = 1}^N p(\mathbf{x}_n |\theta) ~~~~ (2)
\]</p>

<p>(Nh·∫Øc l·∫°i r·∫±ng hai s·ª± ki·ªán \(x, y\) l√† ƒë·ªôc l·∫≠p n·∫øu x√°c su·∫•t ƒë·ªìng th·ªùi c·ªßa ch√∫ng b·∫±ng t√≠ch x√°c su·∫•t c·ªßa t·ª´ng s·ª± ki·ªán: \(p(x, y) = p(x)p(y)\). V√† khi l√† x√°c su·∫•t c√≥ ƒëi·ªÅu ki·ªán: \(p(x, y | z) = p(x|z)p(y|z)\))</p>

<p>L√∫c ƒë√≥, b√†i to√°n \((1)\) c√≥ th·ªÉ ƒë∆∞·ª£c gi·∫£i quy·∫øt b·∫±ng c√°ch gi·∫£i b√†i to√°n t·ªëi ∆∞u sau:</p>

<p>\[
\theta = \max_{\theta} \prod_{n=1}^N p(\mathbf{x}_n| \theta) ~~~~ (3)
\]</p>

<p>Vi·ªác t·ªëi ∆∞u ho√° m·ªôt t√≠ch th∆∞·ªùng ph·ª©c t·∫°p h∆°n vi·ªác t·ªëi ∆∞u m·ªôt t·ªïng, v√¨ v·∫≠y vi·ªác t·ªëi ƒëa h√†m m·ª•c ti√™u th∆∞·ªùng ƒë∆∞·ª£c chuy·ªÉn v·ªÅ vi·ªác t·ªëi ƒëa \(\log\) c·ªßa h√†m m·ª•c ti√™u. √în l·∫°i m·ªôt ch√∫t:</p>

<ul>
  <li>
    <p>\(\log\) c·ªßa m·ªôt t√≠ch b·∫±ng t·ªïng c·ªßa c√°c \(\log\).</p>
  </li>
  <li>
    <p>v√¨ r·∫±ng \(\log\) l√† m·ªôt h√†m ƒë·ªìng bi·∫øn, m·ªôt bi·ªÉu th·ª©c s·∫Ω l√† l·ªõn nh·∫•t n·∫øu \(\log\) c·ªßa n√≥ l√† l·ªõn nh·∫•t, v√† ng∆∞·ª£c l·∫°i.</p>
  </li>
</ul>

<p>B√†i to√°n Maximum Likelihood ƒë∆∞·ª£c ƒë∆∞a v·ªÅ b√†i to√°n Maximum Log-likelihood:
\[
\theta = \max_{\theta} \sum_{n = 1}^N \log\left(p(\mathbf{x}_n | \theta)\right) ~~~~ (4)
\]</p>

<p>B·∫°n v·∫´n ch∆∞a hi·ªÉu? Kh√¥ng lo, b√¢y gi·ªù ch√∫ng ta s·∫Ω l√†m m·ªôt v√†i v√≠ d·ª•.</p>

<p><a name="-vi-du"></a></p>

<h3 id="23-v√≠-d·ª•">2.3. V√≠ d·ª•</h3>
<p><a name="-vi-du--bernoulli-distribution"></a></p>

<h4 id="231-v√≠-d·ª•-1-bernoulli-distribution">2.3.1. V√≠ d·ª• 1: Bernoulli distribution</h4>
<hr />

<p><strong>B√†i to√°n</strong>: gi·∫£ s·ª≠ tung m·ªôt ƒë·ªìng xu \(N\) l·∫ßn v√† nh·∫≠n ƒë∆∞·ª£c \(n\) m·∫∑t <em>head</em>. T√≠nh x√°c su·∫•t c√≥ m·ªôt m·∫∑t <em>head</em> khi tung ƒë·ªìng xu ƒë√≥ ·ªü l·∫ßn ti·∫øp theo.</p>
<hr />

<p><strong>L·ªùi gi·∫£i:</strong>
M·ªôt c√°ch tr·ª±c quan nh·∫•t, ta c√≥ th·ªÉ d·ª± ƒëo√°n ƒë∆∞·ª£c r·∫±ng x√°c su·∫•t ƒë√≥ ch√≠nh l√† \(\lambda = \frac{n}{N}\). Tuy nhi√™n, l√† m·ªôt ng∆∞·ªùi mu·ªën bi·∫øt ng·ªçn ng√†nh v·∫•n ƒë·ªÅ, b·∫°n c√≥ th·ªÉ ch∆∞a c·∫£m th·∫•y thuy·∫øt ph·ª•c, v√† mu·ªën bi·∫øt li·ªáu c√≥ c∆° s·ªü to√°n h·ªçc <em>v·ªØng ch·∫Øc h∆°n</em> ch·ª©ng minh vi·ªác ƒë√≥ kh√¥ng.</p>

<p>Vi·ªác n√†y c√≥ th·ªÉ th·ª±c hi·ªán b·∫±ng Maximum Likelihood.</p>

<p>Th·∫≠t v·∫≠y, gi·∫£ s·ª≠ \(\lambda\) l√† x√°c su·∫•t ƒë·ªÉ nh·∫≠n ƒë∆∞·ª£c m·ªôt m·∫∑t <em>head</em>. ƒê·∫∑t \(x_1, x_2, \dots, x_N\) l√† c√°c ƒë·∫ßu ra nh·∫≠n ƒë∆∞·ª£c, trong ƒë√≥ c√≥ \(n\) gi√° tr·ªã b·∫±ng 1 t∆∞∆°ng ·ª©ng v·ªõi m·∫∑t <em>head</em> v√† \(m = N - n\) gi√° tr·ªã b·∫±ng 0 t∆∞∆°ng ·ª©ng v·ªõi m·∫∑t <em>tail</em>. Ta c√≥ th·ªÉ suy ra ngay:
\[
  \sum_{i=1}^N x_i = n, ~~N - \sum_{i=1}^N x_i = N - n = m
\]</p>

<p>C√≥ th·ªÉ nh·∫≠n th·∫•y vi·ªác nh·∫≠n ƒë∆∞·ª£c m·∫∑t <em>head</em> hay <em>tail</em> khi tung ƒë·ªìng xu tu√¢n theo <a href="/2017/07/09/prob/#-bernouli-distribution">Bernoulli distribution</a>:</p>

<p>\[
p(x_i | \lambda) = \lambda^{x_i} ( 1- \lambda)^{1 - x_i}
\]</p>

<p>Khi ƒë√≥ tham s·ªë m√¥ h√¨nh \(\lambda\) c√≥ th·ªÉ ƒë∆∞·ª£c ƒë√°nh gi√° b·∫±ng vi·ªác gi·∫£i b√†i to√°n t·ªëi ∆∞u:
\[
\begin{eqnarray}
  \lambda &amp; = &amp; \arg\max_{\lambda}\left[ p(x_1, x_2, \dots, x_N | \lambda)\right] \<br />
  &amp; = &amp; \arg\max_{\lambda} \left[\prod_{i = 1}^N p(x_i | \lambda)\right] &amp; (5) \<br />
  &amp; = &amp; \arg\max_{\lambda} \left[\prod_{i=1}^N  \lambda^{x_i} ( 1- \lambda)^{1 - x_i}\right] &amp; (6)\<br />
  &amp; = &amp; \arg\max_{\lambda} \left[\lambda^{\sum_{i=1}^N x_i} (1 - \lambda)^{N - \sum_{i=1}^N x_i}\right] &amp; (7) \<br />
  &amp; = &amp; \arg\max_{\lambda} \left[\lambda^{n} (1 - \lambda)^{m}\right] &amp; (8)\<br />
  &amp; = &amp; \arg\max_{\lambda} \left[ n\log(\lambda) + m\log(1 - \lambda) \right] &amp; (9)
\end{eqnarray}
\]</p>

<p>·ªü tr√™n, t√¥i ƒë√£ gi·∫£ s·ª≠ r·∫±ng k·∫øt qu·∫£ c·ªßa m·ªói l·∫ßn tung ƒë·ªìng xu l√† ƒë·ªôc l·∫≠p v·ªõi nhau. T·ª´ \((8)\) sang \((9)\) ta ƒë√£ l·∫•y \(\log\) c·ªßa h√†m m·ª•c ti√™u.</p>

<p>T·ªõi ƒë√¢y, b√†i to√°n t·ªëi ∆∞u \((9)\) c√≥ th·ªÉ ƒë∆∞·ª£c gi·∫£i b·∫±ng c√°ch l·∫•y ƒë·∫°o h√†m c·ªßa h√†m m·ª•c ti√™u b·∫±ng 0. T·ª©c \(\lambda\) l√† nghi·ªám c·ªßa ph∆∞∆°ng tr√¨nh:
\[
\begin{eqnarray}
  \frac{n}{\lambda} - \frac{m}{1 - \lambda} &amp; = &amp; 0 \<br />
  \Leftrightarrow \frac{n}{\lambda} &amp; = &amp; \frac{m}{1 - \lambda} \<br />
  \Leftrightarrow \lambda &amp; = &amp; \frac{n}{n + m} = \frac{n}{N}
\end{eqnarray}
\]</p>

<p>V·∫≠y k·∫øt qu·∫£ ta kh·∫≥ng ƒë·ªãnh ·ªü tr√™n l√† c√≥ c∆° s·ªü.</p>

<p><a name="-vi-du--categorical-distribution"></a></p>

<h4 id="232-v√≠-d·ª•-2-categorical-distribution">2.3.2. V√≠ d·ª• 2: Categorical distribution</h4>
<p>M·ªôt v√≠ d·ª• kh√°c kh√≥ h∆°n m·ªôt ch√∫t.</p>
<hr />

<p><strong>B√†i to√°n:</strong> gi·∫£ s·ª≠ tung m·ªôt vi√™n x√∫c x·∫Øc 6 m·∫∑t c√≥ x√°c su·∫•t r∆°i v√†o c√°c m·∫∑t c√≥ th·ªÉ kh√¥ng ƒë·ªÅu nhau. Gi·∫£ s·ª≠ trong \(N\) l·∫ßn tung, s·ªë l∆∞·ª£ng xu·∫•t hi·ªán c√°c m·∫∑t th·ª© nh·∫•t, th·ª© hai,‚Ä¶, th·ª© s√°u l·∫ßn l∆∞·ª£t l√† \(n_1, n_2, \dots, n_6\) l·∫ßn v·ªõi \(\sum_{i=1}^6 n_i = N\). T√≠nh x√°c su·∫•t r∆°i v√†o m·ªói m·∫∑t ·ªü l·∫ßn tung ti·∫øp theo.</p>
<hr />

<p><strong>L·ªùi gi·∫£i:</strong></p>

<p>B√†i to√°n n√†y c√≥ v·∫ª ph·ª©c t·∫°p h∆°n b√†i to√°n tr√™n m·ªôt ch√∫t, nh∆∞ng ta c≈©ng c√≥ th·ªÉ d·ª± ƒëo√°n ƒë∆∞·ª£c ƒë√°nh gi√° t·ªët nh·∫•t c·ªßa x√°c su·∫•t r∆°i v√†o m·∫∑t th·ª© \(i\) l√† \(\lambda_i = \frac{n_i}{N}\).</p>

<p><em>M√£ ho√°</em> m·ªói quan s√°t ƒë·∫ßu ra th·ª© \(i\) b·ªüi m·ªôt vector 6 chi·ªÅu \(\mathbf{x}_i \in \{0, 1\}^6\) trong ƒë√≥ c√°c ph·∫ßn t·ª≠ c·ªßa n√≥ b·∫±ng 0 tr·ª´ ph·∫ßn t·ª≠ t∆∞∆°ng ·ª©ng v·ªõi m·∫∑t quan s√°t ƒë∆∞·ª£c l√† b·∫±ng 1. (C√°ch l√†m n√†y gi·ªëng v·ªõi <em>one-hot encoding</em>). Ta c≈©ng c√≥ th·ªÉ suy ra:
\[
\begin{eqnarray}
  \sum_{i=1}^N x^j_i = n_j, ~ \forall j = 1, 2, \dots, 6
\end{eqnarray}
\]
trong ƒë√≥ \(x^j_i\) l√† th√†nh ph·∫ßn th·ª© \(j\) c·ªßa vector \(\mathbf{x}_i\).</p>

<p>C√≥ th·ªÉ th·∫•y r·∫±ng x√°c su·∫•t r∆°i v√†o m·ªói m·∫∑t tu√¢n theo <a href="/2017/07/09/prob/#-categorical-distribution">Categorical distribution</a> v·ªõi c√°c tham s·ªë \(\lambda_j &gt; 0, j = 1, 2, \dots, 6\) (ta b·ªè qua tr∆∞·ªùng h·ª£p t·∫ßm th∆∞·ªùng khi c√≥ m·ªôt \(\lambda_j = 0\)). Ta d√πng \(\lambda\) ƒë·ªÉ th·ªÉ hi·ªán cho c·∫£ 6 tham s·ªë n√†y. V·ªõi c√°c tham s·ªë n√†y, x√°c su·∫•t ƒë·ªÉ s·ª± ki·ªán \(\mathbf{x}_i\) x·∫£y ra l√†:</p>

<p>\[
\begin{eqnarray}
  p(\mathbf{x}_i | \lambda) = \prod_{j = 1}^6 \lambda_j^{x_i^j}
\end{eqnarray}
\]</p>

<p>Khi ƒë√≥, v·∫´n v·ªõi gi·∫£ s·ª≠ v·ªÅ s·ª± ƒë·ªôc l·∫≠p gi·ªØa c√°c l·∫ßn tung x√∫c x·∫Øc, ƒë√°nh gi√° b·ªô tham s·ªë \(\lambda\) d·ª±a tr√™n Maximum log-likelihood ta c√≥:
\[
\begin{eqnarray}
  \lambda &amp; = &amp; \arg\max_{\lambda} \left[ p(\mathbf{x}_1, \dots, \mathbf{x}_N  | \lambda) \right]\<br />
  &amp; = &amp; \arg\max_{\lambda} \left[ \prod_{i=1}^N p(\mathbf{x}_i | \lambda)  \right] &amp; (10) \<br />
  &amp; = &amp; \arg\max_{\lambda} \left[ \prod_{i=1}^N  \prod_{j = 1}^6 \lambda_j^{x_i^j} \right] &amp; (11) \<br />
  &amp; = &amp; \arg\max_{\lambda} \left[  \prod_{j = 1}^6 \lambda_j^{\sum_{i=1}^N x_i^j} \right] &amp; (12) \<br />
  &amp; = &amp; \arg\max_{\lambda} \left[  \prod_{j = 1}^6 \lambda_j^{n_j} \right] &amp; (13) \<br />
  &amp; = &amp; \arg\max_{\lambda} \left[  \sum_{j=1}^6 n_j\log(\lambda_j) \right] &amp; (14) \<br />
\end{eqnarray}
\]</p>

<p>Kh√°c v·ªõi b√†i to√°n \((9)\) m·ªôt ch√∫t, ch√∫ng ta kh√¥ng ƒë∆∞·ª£c qu√™n ƒëi·ªÅu ki·ªán \(\sum_{j=1}^6 \lambda_j = 1\). V·∫≠y ta c√≥ b√†i to√°n t·ªëi ∆∞u c√≥ r√†ng bu·ªôc:
\[
\begin{eqnarray}
  \max_{\lambda} &amp; \sum_{j=1}^6 n_j\log(\lambda_j) \<br />
  \text{subject to:} &amp; \sum_{j=1}^6 \lambda_j = 1~~~~~~~~ (15)
\end{eqnarray}
\]
B√†i to√°n t·ªëi ∆∞u n√†y c√≥ th·ªÉ ƒë∆∞·ª£c gi·∫£i b·∫±ng <a href="/2017/04/02/duality/#--phuong-phap-nhan-tu-lagrange">ph∆∞∆°ng ph√°p nh√¢n t·ª≠ Lagrange</a>.</p>

<p>Lagrangian c·ªßa b√†i to√°n n√†y l√†:
\[
  \mathcal{L}(\lambda, \mu) = \sum_{j=1}^6 n_j\log(\lambda_j) + \mu (1- \sum_{j=1}^6 \lambda_j)
\]</p>

<p>Nghi·ªám c·ªßa b√†i to√°n l√† nghi·ªám c·ªßa h·ªá ƒë·∫°o h√†m c·ªßa \(\mathcal{L}(.)\) theo t·ª´ng bi·∫øn b·∫±ng 0:
\[
\begin{eqnarray}
\frac{\partial \mathcal{L}(\lambda, \mu)}{\partial \lambda_j} &amp; = &amp;  \frac{n_j}{\lambda_j} - \mu &amp; = &amp; 0, ~~ \forall j = 1, 2, \dots, 6 ~~~~ (16) \<br />
\frac{\partial \mathcal{L}(\lambda, \mu)}{\partial \mu} &amp; = &amp; 1-\sum_{j=1}^6 \lambda_j &amp; = &amp; 0 ~~~~ (17)
\end{eqnarray}
\]</p>

<p>T·ª´ \((16)\) ta c√≥ \(\lambda_j = \frac{n_j}{\mu}\). Thay v√†o \((17)\):
\[
  \sum_{j=1}^6 \frac{n_j}{\mu} = 1 \Rightarrow \mu = \sum_{j=1}^6 n_j = N
\]</p>

<p>T·ª´ ƒë√≥ ta c√≥ ƒë√°nh gi√°:
\[
  \lambda_j = \frac{n_j}{N}, ~~\forall j = 1, 2, \dots, 6
\]</p>

<p>Qua hai v√≠ d·ª• tr√™n ta th·∫•y Maximum Likelihood cho k·∫øt qu·∫£ h·ª£p l√Ω.</p>

<p><a name="-vi-du--univariate-normal-distribution"></a></p>

<h4 id="233-v√≠-d·ª•-3-univariate-normal-distribution">2.3.3. V√≠ d·ª• 3: Univariate normal distribution</h4>

<hr />

<p><strong>B√†i to√°n:</strong> Khi th·ª±c hi·ªán m·ªôt ph√©p ƒëo, gi·∫£ s·ª≠ r·∫±ng r·∫•t kh√≥ ƒë·ªÉ c√≥ th·ªÉ ƒëo ch√≠nh x√°c ƒë·ªô d√†i c·ªßa m·ªôt v·∫≠t. Thay v√†o ƒë√≥, ng∆∞·ªùi ta th∆∞·ªùng ƒëo v·∫≠t ƒë√≥ nhi·ªÅu l·∫ßn r·ªìi suy ra k·∫øt qu·∫£, v·ªõi gi·∫£ thi·∫øt r·∫±ng c√°c ph√©p ƒëo l√† ƒë·ªôc l·∫≠p v·ªõi nhau v√† k·∫øt qu·∫£ m·ªói ph√©p ƒëo l√† m·ªôt ph√¢n ph·ªëi chu·∫©n. ƒê√°nh gi√° chi·ªÅu d√†i c·ªßa v·∫≠t ƒë√≥.</p>
<hr />

<p><strong>L·ªùi gi·∫£i:</strong></p>

<p>V√¨ ta bi·∫øt r·∫±ng k·∫øt qu·∫£ ph√©p ƒëo tu√¢n theo ph√¢n ph·ªëi chu·∫©n n√™n ta s·∫Ω c·ªë g·∫Øng ƒëi x√¢y d·ª±ng ph√¢n ph·ªëi chu·∫©n ƒë√≥. Chi·ªÅu d√†i c·ªßa v·∫≠t c√≥ th·ªÉ ƒë∆∞·ª£c coi l√† gi√° tr·ªã m√† h√†m m·∫≠t ƒë·ªô x√°c su·∫•t ƒë·∫°t gi√° tr·ªã cao nh·∫•t. Trong ph√¢n ph·ªëi chu·∫©n, ta bi·∫øt r·∫±ng ƒë√≥ ch√≠nh l√† k·ª≥ v·ªçng c·ªßa ph√¢n ph·ªëi ƒë√≥. Ch√∫ √Ω r·∫±ng k·ª≥ v·ªçng c·ªßa ph√¢n ph·ªëi v√† k·ª≥ v·ªçng c·ªßa d·ªØ li·ªáu quan s√°t ƒë∆∞·ª£c c√≥ th·ªÉ kh√¥ng b·∫±ng nhau, ch√∫ng ch·ªâ x·∫•p x·ªâ b·∫±ng nhau khi m√† s·ªë l∆∞·ª£ng ph√©p ƒë√≥ l√† m·ªôt s·ªë r·∫•t l·ªõn.</p>

<p>Tuy nhi√™n, n·∫øu ƒë√°nh gi√° k·ª≥ v·ªçng c·ªßa ph√¢n ph·ªëi nh∆∞ c√°ch l√†m d∆∞·ªõi ƒë√¢y s·ª≠ d·ª•ng Maximum Likelihood, ta s·∫Ω th·∫•y r·∫±ng k·ª≥ v·ªçng c·ªßa d·ªØ li·ªáu ch√≠nh l√† ƒë√°nh gi√° t·ªët nh·∫•t cho k·ª≥ v·ªçng c·ªßa ph√¢n ph·ªëi.</p>

<p>Th·∫≠t v·∫≠y, gi·∫£ s·ª≠ c√°c k√≠ch th∆∞·ªõc quan s√°t ƒë∆∞·ª£c l√† \(x_1, x_2, \dots, x_N\). Ta c·∫ßn ƒëi t√¨m m·ªôt ph√¢n ph·ªëi chu·∫©n, t·ª©c m·ªôt gi√° tr·ªã k·ª≥ v·ªçng \(\mu\) v√† ph∆∞∆°ng sai \(\sigma^2\), sao cho c√°c gi√° tr·ªã \(x_1, x_2, \dots, x_N\) l√† <em>likely nh·∫•t</em>.</p>

<p>Ta ƒë√£ bi·∫øt r·∫±ng, h√†m m·∫≠t ƒë·ªô x√°c su·∫•t t·∫°i \(x_i\) c·ªßa m·ªôt ph√¢n ph·ªëi chu·∫©n c√≥ k·ª≥ v·ªçng \(\mu\) v√† ph∆∞∆°ng sai \(\sigma^2\) l√†:
\[
  p(x_i | \mu, \sigma^2) = \frac{1}{\sqrt{2\pi \sigma^2}} \exp\left(-\frac{(x_i - \mu)^2}{2\sigma^2}\right)
\]</p>

<p>V·∫≠y, ƒë·ªÉ ƒë√°nh gi√° \(\mu\) v√† \(\sigma\), ta s·ª≠ d·ª•ng Maximum likelihood v·ªõi gi·∫£ thi·∫øt r·∫±ng k·∫øt qu·∫£ c√°c ph√©p ƒëo l√† ƒë·ªôc l·∫≠p:
\[
\begin{eqnarray}
  \mu, \sigma &amp; = &amp; \arg\max_{\mu, \sigma} \left[ \prod_{i=1}^N p(x_i | \mu, \sigma^2)\right] &amp; (18)\<br />
  &amp; = &amp; \arg\max_{\mu, \sigma} \left[ \frac{1}{(2\pi \sigma^2)^{N/2}} \exp\left(-\frac{\sum_{i=1}^N (x_i - \mu)^2}{2\sigma^2} \right) \right] &amp; (19)\<br />
  &amp; = &amp; \arg\max_{\mu, \sigma}\left[ -N\log(\sigma) - \frac{\sum_{i=1}^N (x_i - \mu)^2}{2\sigma^2}\right] \triangleq \arg\max_{\mu, \sigma} J(\mu, \sigma)(20)
\end{eqnarray}
\]</p>

<p>Ta ƒë√£ l·∫•y \(\log\) c·ªßa h√†m b√™n trong d·∫•u ngo·∫∑c vu√¥ng c·ªßa \((19)\) ƒë·ªÉ ƒë∆∞·ª£c \((20)\), ph·∫ßn h·∫±ng s·ªë c√≥ ch·ª©a \(2\pi\) c≈©ng ƒë∆∞·ª£c b·ªè ƒëi v√¨ n√≥ kh√¥ng ·∫£nh h∆∞·ªüng t·ªõi k·∫øt qu·∫£.</p>

<p>M·ªôt l·∫ßn n·ªØa, ƒë·ªÉ t√¨m \(\mu\) v√† \(\sigma\), ta gi·∫£i h·ªá ph∆∞∆°ng tr√¨nh ƒë·∫°o h√†m c·ªßa \(J(\mu, \sigma)\) theo m·ªói bi·∫øn b·∫±ng 0:</p>

<p>\[
\begin{eqnarray}
  \frac{\partial J}{\partial \mu} &amp; = &amp; \frac{1}{\sigma^2}\sum_{i=1}^N(x_i - \mu) = 0 &amp; (21) \<br />
  \frac{\partial J}{\partial \sigma} &amp; = &amp; -\frac{N}{\sigma} + \frac{1}{\sigma^3} \sum_{i=1}^N (x_i - \mu)^2  &amp; (22)
\end{eqnarray}
\]</p>

<p>T·ª´ ƒë√≥ ta c√≥:
\[
\begin{eqnarray}
  \mu &amp; = &amp; \frac{\sum_{i=1}^N x_i}{N} &amp; (23)\<br />
  \sigma^2 &amp; = &amp; \frac{\sum_{i=1}^N (x_i - \mu)^2}{N} &amp; (24)
\end{eqnarray}
\]</p>

<p><em>ƒê√¢y ch√≠nh l√† c√¥ng th·ª©c ƒë√°nh gi√° hai gi√° tr·ªã k·ª≥ v·ªçng v√† ph∆∞∆°ng sai c·ªßa d·ªØ li·ªáu m√† ch√∫ng ta quen d√πng.</em></p>

<p><a name="-vi-du--multivariate-normal-distribution"></a></p>

<h4 id="234-v√≠-d·ª•-4-multivariate-normal-distribution">2.3.4. V√≠ d·ª• 4: Multivariate normal distribution</h4>
<hr />

<p><strong>B√†i to√°n:</strong> Gi·∫£ s·ª≠ t·∫≠p d·ªØ li·ªáu ta thu ƒë∆∞·ª£c l√† c√°c gi√° tr·ªã nhi·ªÅu chi·ªÅu \(\mathbf{x}_1, \dots, \mathbf{x}_N\). Gi·∫£ s·ª≠ th√™m r·∫±ng d·ªØ li·ªáu n√†y tu√¢n theo ph√¢n ph·ªëi chu·∫©n nhi·ªÅu chi·ªÅu. H√£y ƒë√°nh gi√° c√°c tham s·ªë, vector k·ª≥ v·ªçng \(\mu\) v√† ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai \(\Sigma\), c·ªßa ph√¢n ph·ªëi n√†y d·ª±a tr√™n Maximum Likelihood, gi·∫£ s·ª≠ r·∫±ng c√°c \(\mathbf{x}_1, \dots, \mathbf{x}_N\) l√† ƒë·ªôc l·∫≠p.</p>
<hr />

<p><strong>L·ªùi gi·∫£i:</strong></p>

<p>Vi·ªác ch·ª©ng minh c√°c c√¥ng th·ª©c:
\[
\begin{eqnarray}
  \mu &amp; = &amp; \frac{\sum_{i=1}^N \mathbf{x}_i}{N} \<br />
  \Sigma &amp; = &amp; \frac{1}{N}\sum_{i=1}^N (\mathbf{x} - \mu)(\mathbf{x} - \mu)^T
\end{eqnarray}
\]
xin ƒë∆∞·ª£c d√†nh l·∫°i cho b·∫°n ƒë·ªçc nh∆∞ m·ªôt b√†i t·∫≠p nh·ªè. D∆∞·ªõi ƒë√¢y l√† m·ªôt v√†i g·ª£i √Ω:</p>

<ul>
  <li>H√†m m·∫≠t ƒë·ªô x√°c su·∫•t c·ªßa ph√¢n ph·ªëi chu·∫©n nhi·ªÅu chi·ªÅu l√†:
\[
p(\mathbf{x} | \mu, \Sigma) = \frac{1}{(2\pi)^{D/2} |\Sigma|^{1/2}} \exp \left(-\frac{1}{2} (\mathbf{x} - \mu)^T \Sigma^{-1} (\mathbf{x} - \mu)\right) ~~~ (33)
\]
Ch√∫ √Ω r·∫±ng ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai \(\Sigma\) l√† ma tr·∫≠n x√°c ƒë·ªãnh d∆∞∆°ng n√™n c√≥ ngh·ªãch ƒë·∫£o.</li>
  <li>M·ªôt v√†i ƒë·∫°o h√†m theo ma tr·∫≠n:
\[
\nabla_{\Sigma} \log |\Sigma| = (\Sigma^{-1})^T \triangleq \Sigma^{-T}~~~ \text{(transpose of inversion)}
\]</li>
</ul>

<p>\[
  \nabla_{\Sigma} (\mathbf{x}_i - \mu)^T \Sigma^{-1} (\mathbf{x}_i-\mu) = -\Sigma^{-T}(\mathbf{x}_i - \mu)(\mathbf{x}_i - \mu)^T\Sigma^{-T}
\]
(Xem th√™m <a href="https://ccrma.stanford.edu/~dattorro/matrixcalc.pdf">Matrix Calculus</a>, m·ª•c D.2.1 v√† D.2.4.)</p>

<p><a name="-maximum-a-posteriori"></a></p>

<h2 id="3-maximum-a-posteriori">3. Maximum a Posteriori</h2>
<p><a name="-y-tuong-1"></a></p>

<h3 id="31-√Ω-t∆∞·ªüng">3.1. √ù t∆∞·ªüng</h3>
<p>Quay l·∫°i v·ªõi v√≠ d·ª• 1 v·ªÅ tung ƒë·ªìng xu. N·∫øu tung 5 l·∫ßn v√† ch·ªâ nh·∫≠n ƒë∆∞·ª£c 1 m·∫∑t <em>head</em>, theo Maximum Likelihood, x√°c su·∫•t ƒë·ªÉ c√≥ m·ªôt m·∫∑t <em>head</em> ƒë∆∞·ª£c ƒë√°nh gi√° l√† \(1/5\). N·∫øu tung ƒë·ªìng xu 5000 l·∫ßn v√† nh·∫≠n ƒë∆∞·ª£c 1000 l·∫ßn <em>head</em>, ta c√≥ th·ªÉ ƒë√°nh gi√° x√°c su·∫•t c·ªßa <em>head</em> l√† \(1/5\) v√† vi·ªác ƒë√°nh gi√° n√†y l√† ƒë√°ng tin. Tuy nhi√™n, v√¨ ch·ªâ c√≥ 5 k·∫øt qu·∫£, th·∫≠t kh√≥ ƒë·ªÉ k·∫øt lu·∫≠n r·∫±ng k·∫øt qu·∫£ l√† \(1/5\). <em>N·∫øu k·∫øt lu·∫≠n ngay k·∫øt qu·∫£ l√† \(1/5\), r·∫•t c√≥ th·ªÉ ch√∫ng ta ƒë√£ b·ªã <a href="/2017/03/04/overfitting/#-regularization">overfitting</a></em>.</p>

<p>Khi c√≥ qu√° √≠t d·ªØ ki·ªán, t∆∞∆°ng ·ª©ng v·ªõi hi·ªán t∆∞·ª£ng c√≥ qu√° √≠t d·ªØ li·ªáu trong training (<em>low-training</em>) ch√∫ng ta c·∫ßn ph·∫£i t·ª± suy ra m·ªôt v√†i gi·∫£ thi·∫øt c·ªßa c√°c tham s·ªë. Ch·∫≥ng h·∫°n, v·ªõi vi·ªác tung ƒë·ªìng xu, gi·∫£ thi·∫øt c·ªßa ch√∫ng ta l√† x√°c su·∫•t nh·∫≠n ƒë∆∞·ª£c m·∫∑t <em>head</em> ph·∫£i g·∫ßn \(1/2\).</p>

<p>Maximum A Posteriori (MAP) ra ƒë·ªùi nh·∫±m gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ n√†y. Trong MAP, ch√∫ng ta gi·ªõi thi·ªáu m·ªôt gi·∫£ thi·∫øt bi·∫øt tr∆∞·ªõc, ƒë∆∞·ª£c g·ªçi l√† <em>prior</em>, c·ªßa tham s·ªë \(\theta\). T·ª´ nh·ªØng <em>kinh nghi·ªám</em> tr∆∞·ªõc ƒë√¢y, ch√∫ng ta c√≥ th·ªÉ suy ra c√°c kho·∫£ng gi√° tr·ªã v√† ph√¢n b·ªë c·ªßa tham s·ªë.</p>

<p>Ng∆∞·ª£c v·ªõi MLE, trong MAP, ch√∫ng ta s·∫Ω ƒë√°nh gi√° tham s·ªë nh∆∞ l√† m·ªôt conditional probability c·ªßa d·ªØ li·ªáu:
\[
  \theta = \arg\max_{\theta} \underbrace{p(\theta | \mathbf{x}_1, \dots, \mathbf{x}_N)}_{\text{posterior}} ~~~~~~~ (34)
\]</p>

<p>Bi·ªÉu th·ª©c \(p(\theta | \mathbf{x}_1, \dots, \mathbf{x}_N) \) c√≤n ƒë∆∞·ª£c g·ªçi l√† <em>posterior probability</em> c·ªßa \(\theta\). Ch√≠nh v√¨ v·∫≠y m√† vi·ªác ƒë√°nh gi√° \(\theta\) theo \((34)\) ƒë∆∞·ª£c g·ªçi l√† <em>Maximum A Posteriori</em>.</p>

<p>Th√¥ng th∆∞·ªùng, h√†m t·ªëi ∆∞u trong \((34)\) kh√≥ x√°c ƒë·ªãnh d·∫°ng m·ªôt c√°ch tr·ª±c ti·∫øp. Ch√∫ng ta th∆∞·ªùng bi·∫øt ƒëi·ªÅu ng∆∞·ª£c l·∫°i, t·ª©c n·∫øu bi·∫øt tham s·ªë, ta c√≥ th·ªÉ t√≠nh ƒë∆∞·ª£c h√†m m·∫≠t ƒë·ªô x√°c su·∫•t c·ªßa d·ªØ li·ªáu. V√¨ v·∫≠y, ƒë·ªÉ gi·∫£i b·∫£i to√°n MAP, ta th∆∞·ªùng s·ª≠ d·ª•ng <a href="/2017/07/09/prob/#-quy-tac-bayes">Bayes‚Äô rule</a>. B√†i to√°n MAP th∆∞·ªùng ƒë∆∞·ª£c bi·∫øn ƒë·ªïi th√†nh:</p>

<p>\[
\begin{eqnarray}
  \theta &amp; = &amp; \arg\max_{\theta} p(\theta | \mathbf{x}_1, \dots, \mathbf{x}_N) \<br />
  &amp; = &amp; \arg\max_{\theta} \left[ \frac{\overbrace{p(\mathbf{x}_1, \dots, \mathbf{x}_N | \theta)}^{\text{likelihood}} \overbrace{p(\theta)}^{\text{prior}}}{\underbrace{p(\mathbf{x}_1, \dots, \mathbf{x}_N)}_{\text{evidence}}} \right] &amp; (35)\<br />
  &amp; = &amp; \arg\max_{\theta} \left[ p(\mathbf{x}_1, \dots, \mathbf{x}_N | \theta) p(\theta) \right] &amp; (36) \<br />
  &amp; = &amp; \arg\max_{\theta} \left[ \prod_{i=1}^N p(\mathbf{x}_i | \theta) p(\theta) \right] &amp; (37)
\end{eqnarray}
\]</p>

<p>ƒê·∫≥ng th·ª©c \((35)\) x·∫£y ra l√† do Bayes‚Äô rule.</p>

<p>ƒê·∫≥ng th·ª©c \((36)\) x·∫£y ra v√¨ m·∫´u s·ªë c·ªßa \((35)\) kh√¥ng ph·ª• thu·ªôc v√†o tham s·ªë \(\theta\).</p>

<p>ƒê·∫≥ng th·ª©c \((37)\) x·∫£y ra n·∫øu ch√∫ng ta gi·∫£ thi·∫øt v·ªÅ s·ª± ƒë·ªôc l·∫≠p gi·ªØa c√°c \(\mathbf{x}_i\). Ch√∫ √Ω r·∫±ng gi·∫£ thi·∫øt ƒë·ªôc l·∫≠p th∆∞·ªùng xuy√™n ƒë∆∞·ª£c s·ª≠ d·ª•ng.</p>

<!-- Nh·∫Øc l·∫°i t√™n c√°c ƒë·∫°i l∆∞·ª£ng trong \\((35)\\): -->

<p>Nh∆∞ v·∫≠y, ƒëi·ªÉm kh√°c bi·ªát l·ªõn nh·∫•t gi·ªØa hai b√†i to√°n t·ªëi ∆∞u MLE v√† MAP l√† vi·ªác h√†m m·ª•c ti√™u c·ªßa MAP c√≥ th√™m \(p(\theta)\), t·ª©c ph√¢n ph·ªëi c·ªßa \(\theta\). Ph√¢n ph·ªëi n√†y ch√≠nh l√† nh·ªØng th√¥ng tin ta bi·∫øt tr∆∞·ªõc v·ªÅ \(\theta\) v√† ƒë∆∞·ª£c g·ªçi l√† <em>prior</em>. Ta c√≥ k·∫øt lu·∫≠n: <strong><em>posteriori</em> t·ªâ l·ªá thu·∫≠n v·ªõi t√≠ch c·ªßa <em>likelihood</em> v√† <em>prior</em></strong>.</p>

<p>Vi·ªác l·ª±a ch·ªçn c√°c <em>prior</em> nh∆∞ th·∫ø n√†o, ch√∫ng ta c√πng l√†m quen v·ªõi kh√°i ni·ªám m·ªõi: <em>Conjugate prior</em>.</p>

<p><a name="-conjugate-prior"></a></p>

<h3 id="32-conjugate-prior">3.2. Conjugate prior</h3>
<p>Khi nh√¢n m·ªôt ph√¢n ph·ªëi \(p_1\) m·ªôt ph√¢n ph·ªëi \(p_2\) kh√°c, k·∫øt qu·∫£ thu ƒë∆∞·ª£c t·ªâ l·ªá thu·∫≠n v·ªõi m·ªôt ph√¢n ph·ªëi c√≥ d·∫°ng gi·ªëng nh∆∞ ph√¢n ph·ªëi \(p_2\), ta n√≥i \(p_2\) l√† <em>conjugate distribution</em> c·ªßa \(p_1\). N·∫øu ƒëi·ªÅu n√†y x·∫£y ra, vi·ªác t·ªëi ∆∞u b√†i to√°n MAP s·∫Ω tr·ªü n√™n t∆∞∆°ng t·ª± nh∆∞ vi·ªác t√¥i ∆∞u b√†i to√°n MLE v√¨ nghi·ªám c√≥ c·∫•u tr√∫c gi·ªëng nhau.</p>

<p>N·∫øu <em>posterior distribution</em> \(p(\theta | \mathbf{X})\) v√† <em>likelihood</em> \(p(\mathbf{X} |\theta)\) c√≥ c√πng <em>h·ªç</em> (family), th√¨ <em>prior distribution</em> l√† <em>conjugate distribution</em> c·ªßa <em>likelihood distribution</em>.</p>

<p>T√¥i s·∫Ω kh√¥ng ƒëi s√¢u v√†o ph·∫ßn n√†y, b·∫°n ƒë·ªçc c√≥ th·ªÉ ƒë·ªçc th√™m <a href="https://en.wikipedia.org/wiki/Conjugate_prior">Conjugate prior</a>. T√¥i s·∫Ω n√™u m·ªôt v√†i c·∫∑p c√°c <em>conjugate distributions</em>:</p>

<ul>
  <li>
    <p>N·∫øu likelihood function l√† m·ªôt Gaussian (ph√¢n ph·ªëi chu·∫©n), v√† prior cho vector k·ª≥ v·ªçng c≈©ng l√† m·ªôt Gaussian, th·∫ø th√¨ posterior distribution c≈©ng l√† m·ªôt Gaussian. Ta n√≥i r·∫±ng Gaussian family conjugate v·ªõi ch√≠nh n√≥ (ho·∫∑c c√≤n g·ªçi l√† <em>self-conjugate</em>).</p>
  </li>
  <li>
    <p>N·∫øu likelihood function l√† m·ªôt Gaussian (ph√¢n ph·ªëi chu·∫©n), v√† prior cho ph∆∞∆°ng sai l√† m·ªôt <a href="https://en.wikipedia.org/wiki/Gamma_distribution">gamma distribution</a>, th√¨ posterior distribution c≈©ng l√† m·ªôt Gaussian. Ta n√≥i r·∫±ng gamma distribution l√† conjugate prior cho <em>ƒë·ªô ch√≠nh x√°c</em> c·ªßa Gaussian. Ch√∫ √Ω r·∫±ng ph∆∞∆°ng sai c√≥ th·ªÉ ƒë∆∞·ª£c coi l√† m·ªôt bi·∫øn gi√∫p ƒëo <em>ƒë·ªô ch√≠nh x√°c</em> c·ªßa m√¥ h√¨nh. Ph∆∞∆°ng sai c√†ng nh·ªè th√¨ ƒë·ªô ch√≠nh x√°c c√†ng cao.</p>
  </li>
  <li>
    <p>Beta distribution l√† conjugate c·ªßa Bernoulli distribution.</p>
  </li>
  <li>
    <p>Dirichlet distribution l√† conjugate c·ªßa Categorical distribution.</p>
  </li>
</ul>

<p><a name="-hyperparameters"></a></p>

<h3 id="33-hyperparameters">3.3. Hyperparameters</h3>
<p>Ch√∫ng ta s·∫Ω c√πng xem x√©t m·ªôt v√≠ d·ª• nh·ªè v·ªõi Bernoulli distribution:
\[
  p(x | \lambda) = \lambda^x ( 1 - \lambda)^{1 - x}
\]</p>

<p>V√† conjugate c·ªßa n√≥, Beta distribution, c√≥ h√†m m·∫≠t ƒë·ªô x√°c su·∫•t:</p>

<p>\[
  p(\lambda) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha) \Gamma(\beta)} \lambda^{\alpha - 1} ( 1 - \lambda) ^{\beta - 1}
\]
B·ªè qua th·ª´a s·ªë h·∫±ng s·ªë ch·ªâ mang m·ª•c ƒë√≠ch chu·∫©n ho√° cho t√≠ch ph√¢n c·ªßa h√†m m·∫≠t ƒë·ªô x√°c su·∫•t b·∫±ng 1, ta c√≥ th·ªÉ nh·∫≠n th·∫•y r·∫±ng ph·∫ßn c√≤n l·∫°i c·ªßa Beta distribution c√≥ c√πng <em>h·ªç</em> v·ªõi Bernoulli distribution.</p>

<p>C·ª• th·ªÉ, n·∫øu s·ª≠ d·ª•ng Beta distribution l√†m <em>prior</em> cho tham s·ªë \(\lambda\), v√† b·ªè qua ph·∫ßn th·ª´a s·ªë h·∫±ng s·ªë, posterior s·∫Ω c√≥ d·∫°ng:
\[
\begin{eqnarray}
  p(\lambda | x) &amp; \propto &amp; p(x | \lambda) p(\lambda) \<br />
      &amp; \propto &amp; \lambda^{x + \alpha - 1}(1 - \lambda)^{1 - x + \beta - 1} ~~~ (38)
\end{eqnarray}
\]</p>

<p>trong ƒë√≥, \(\propto\) l√† k√Ω hi·ªáu c·ªßa <em>t·ªâ l·ªá v·ªõi</em>.</p>

<p>Nh·∫≠n th·∫•y r·∫±ng \((38)\) <em>v·∫´n c√≥ d·∫°ng c·ªßa m·ªôt Bernoulli distribution.</em> Ch√≠nh v√¨ v·∫≠y m√† Beta distribution ƒë∆∞·ª£c g·ªçi l√† m·ªôt <em>conjugate prior</em> cho Bernoulli distribution.</p>

<p>Trong v√≠ d·ª• n√†y, tham s·ªë \(\lambda\) ph·ª• thu·ªôc v√†o hai tham s·ªë kh√°c l√† \(\alpha\) v√† \(\beta\). ƒê·ªÉ tr√°nh nh·∫ßm l·∫´n, hai tham s·ªë \((\alpha, \beta)\) ƒë∆∞·ª£c g·ªçi l√† <em>si√™u tham s·ªë</em> (hyperparameters).</p>

<p>Quay tr·ªü l·∫°i v√≠ d·ª• v·ªÅ b√†i to√°n tung ƒë·ªìng xu \(N\) l·∫ßn c√≥ \(n\) l·∫ßn nh·∫≠n ƒë∆∞·ª£c m·∫∑t <em>head</em> v√† \(m = N - n\) l·∫ßn nh·∫≠n ƒë∆∞·ª£c m·∫∑t <em>tail</em>. N·∫øu s·ª≠ d·ª•ng MLE, ta nh·∫≠n ƒë∆∞·ª£c ƒë√°nh gi√° \(\lambda = n/M\). N·∫øu s·ª≠ d·ª•ng MAP v·ªõi prior l√† m·ªôt \(\text{Beta}[\alpha, \beta]\) th√¨ sao:</p>

<p>B√†i to√°n t·ªëi ∆∞u MAP:
\[
\begin{eqnarray}
  \lambda &amp; = &amp; \arg\max_{\lambda} \left[p(x_1, \dots, x_N | \lambda) p(\lambda) \right] \<br />
  &amp; = &amp; \arg\max_{\lambda} \left[\left(\prod_{i=1}^N \lambda^{x_i} ( 1- \lambda)^{1 - x_i}\right) \lambda^{\alpha - 1} ( 1 - \lambda)^{\beta - 1} \right] \<br />
  &amp; = &amp; \arg\max_{\lambda} \left[ \lambda^{\sum_{i = 1}^N x_i + \alpha - 1} ( 1- \lambda)^{N - \sum_{i=1}^N x_i + \beta - 1} \right] \<br />
  &amp; = &amp; \arg\max_{\lambda} \left[ \lambda^{n + \alpha - 1} ( 1- \lambda)^{m + \beta - 1} \right] ~~~ (39)
\end{eqnarray}
\]</p>

<p>B√†i to√°n t·ªëi ∆∞u \((39)\) ch√≠nh l√† b√†i to√°n t·ªëi ∆∞u \((8)\) v·ªõi tham s·ªë thay ƒë·ªïi m·ªôt ch√∫t. T∆∞∆°ng t·ª± nh∆∞ \((8)\), nghi·ªám c·ªßa \((39)\) c√≥ th·ªÉ ƒë∆∞·ª£c suy ra l√†:</p>

<p>\[
\lambda = \frac{n + \alpha - 1}{N + \alpha + \beta - 2} ~~~ (40)
\]</p>

<p><strong>Ch√≠nh vi·ªác ch·ªçn prior ph√π h·ª£p, ·ªü ƒë√¢y l√† conjugate prior, m√† posterior v√† likelihood c√≥ d·∫°ng gi·ªëng nhau, khi·∫øn cho vi·ªác t·ªëi ∆∞u b√†i to√°n MAP ƒë∆∞·ª£c thu·∫≠n l·ª£i.</strong></p>

<p>Vi·ªác c√≤n l·∫°i l√† ch·ªçn c·∫∑p <em>hyperparameters</em> \(\alpha\) v√† \(\beta\).</p>

<p>Ch√∫ng ta c√πng xem l·∫°i h√¨nh d·∫°ng c·ªßa <a href="/2017/07/09/prob/#-beta-distribution">Beta distribution</a> v√† nh·∫≠n th·∫•y r·∫±ng khi \(\alpha = \beta &gt; 1\), ta c√≥ h√†m m·∫≠t ƒë·ªô x√°c su·∫•t c·ªßa Beta distribution ƒë·ªëi x·ª©ng qua ƒëi·ªÉm 0.5 v√† ƒë·∫°t gi√° tr·ªã cao nh·∫•t t·∫°i 0.5. X√©t H√¨nh 1, ta nh·∫≠n th·∫•y r·∫±ng khi \(\alpha = \beta &gt; 1\) th√¨ \(\lambda\) c√≥ xu h∆∞·ªõng ƒëi v·ªÅ ƒëi·ªÉm 0.5, xu h∆∞·ªõng n√†y c√†ng m·∫°nh n√™n gi√° tr·ªã c·ªßa ch√∫ng c√†ng cao.</p>

<p>N·∫øu ta ch·ªçn \(\alpha = \beta = 1\), ta th·∫•y ƒë√¢y l√† uniform distribution v√¨ ƒë·ªì th·ªã h√†m m·∫≠t ƒë·ªô x√°c su·∫•t l√† 1 ƒë∆∞·ªùng th·∫≥ng. L√∫c n√†y, x√°c su·∫•t c·ªßa \(\lambda\) t·∫°i m·ªçi v·ªã tr√≠ trong kho·∫£ng \([0, 1]\) l√† nh∆∞ nhau. Th·ª±c ch·∫•t, n·∫øu ta thay \(\alpha = \beta = 1\) v√†o \((40)\) ta s·∫Ω thu ƒë∆∞·ª£c \(\lambda = n/N\), ch√≠nh l√† ƒë√°nh gi√° thu ƒë∆∞·ª£c b·∫±ng MLE. MLE l√† m·ªôt tr∆∞·ªùng h·ª£p ƒë·∫∑c bi·ªát c·ªßa MAP khi prior l√† m·ªôt uniform distribution.</p>

<hr />

<div>
<table width="100%" style="border: 0px solid white">
    <tr>
        <td height="100%" style="border: 0px solid white" align="center">
        <img style="display:block;" width="100%" src="/assets/30_prob/beta1.png" />
         <br />

         </td>
         <td width="40%" style="border: 0px solid white" align="justify">
         H√¨nh 1: ƒê·ªì th·ªã h√†m m·∫≠t ƒë·ªô x√°c su·∫•t c·ªßa Beta distribution khi \(\alpha = \beta\) v√† nh·∫≠n c√°c gi√° tr·ªã kh√°c nhau. Khi c·∫£ hai gi√° tr·ªã n√†y l·ªõn, x√°c su·∫•t ƒë·ªÉ \(\lambda\) g·∫ßn 0.5 s·∫Ω cao h∆°n.
         </td>
    </tr>
</table>
</div>

<p>N·∫øu ta ch·ªçn \(\alpha = \beta = 2\), ta s·∫Ω thu ƒë∆∞·ª£c:
\[
  \lambda= \frac{n + 1}{N + 2}
\]</p>

<p>Ch·∫≥ng h·∫°n khi \(N = 5, n = 1\) nh∆∞ trong v√≠ d·ª•. MLE cho k·∫øt qu·∫£ \(\lambda = 1/5\), MAP s·∫Ω cho k·∫øt qu·∫£ \(\lambda = 2/6 = 1/3\).</p>

<p>N·∫øu ch·ªçn \(\alpha = \beta = 10\) ta s·∫Ω c√≥ \(\lambda = (1 + 9)/(5 + 18) = 10/23\). Ta th·∫•y r·∫±ng khi \(\alpha = \beta\) v√† c√†ng l·ªõn th√¨ ta s·∫Ω thu ƒë∆∞·ª£c \(\lambda\) c√†ng g·∫ßn \(1/2\). ƒêi·ªÅu n√†y c√≥ th·ªÉ d·ªÖ nh·∫≠n th·∫•y v√¨ prior nh·∫≠n gi√° tr·ªã r·∫•t cao t·∫°i 0.5 khi c√°c hyperparameters \(\alpha = \beta\) l·ªõn.</p>

<p><a name="-map-giup-tranh-overfitting"></a></p>

<h3 id="34-map-gi√∫p-tr√°nh-overfitting">3.4. MAP gi√∫p tr√°nh overfitting</h3>
<p>Vi·ªác ch·ªçn c√°c hyperparameter th∆∞·ªùng ƒë∆∞·ª£c d·ª±a tr√™n th·ª±c nghi·ªám, b·∫±ng <a href="/2017/03/04/overfitting/#-cross-validation">cross-validation</a> ch·∫≥ng h·∫°n. Vi·ªác th·ª≠ nhi·ªÅu b·ªô tham s·ªë r·ªìi ch·ªçn ra b·ªô t·ªët nh·∫•t l√† vi·ªác m√† c√°c k·ªπ s∆∞ machine learning th∆∞·ªùng xuy√™n ph·∫£i ƒë·ªëi m·∫∑t. C≈©ng gi·ªëng nh∆∞ ch·ªçn <a href="/2017/03/04/overfitting/#-regularization">regularization parameter</a> ƒë·ªÉ tr√°nh overfitting v·∫≠y.</p>

<p>R√µ r√†ng MAP cho ch√∫ng ta c√°c k·∫øt qu·∫£ <em>linh ho·∫°t</em> (flexible) v·ªõi s·ª± thay ƒë·ªïi c·ªßa hyperparameters. V√† l√† m·ªôt c√°ch ƒë·ªÉ tr√°nh <a href="/2017/03/04/overfitting/">overfitting</a>.</p>

<p>N·∫øu vi·∫øt l·∫°i b√†i to√°n MAP d∆∞·ªõi d·∫°ng:
\[
\begin{eqnarray}
  \theta &amp; = &amp; \arg\max_{\theta} p(\mathbf{X}| \theta) p(\theta) \<br />
  &amp; = &amp; \arg\max_{\lambda} \left[ \log \underbrace{p(\mathbf{X}| \theta)}_{\text{likelihood}} + \log \underbrace{p(\theta)}_{\text{prior}} \right]
\end{eqnarray}
\]</p>

<p>ta c√≥ th·ªÉ th·∫•y r·∫±ng ƒë√¢y gi·ªëng nh∆∞ k·ªπ thu·∫≠t regularization v·ªõi \(\log\) c·ªßa likelihood ƒë∆∞·ª£c coi nh∆∞ ph·∫ßn <em>loss</em> ch√≠nh, \(\log\) c·ªßa <em>prior</em> ƒë√≥ng vai tr√≤ nh∆∞ ph·∫ßn <em>regularization</em>. N·∫øu kh√¥ng c√≥ <em>regularization</em>, ta ƒë∆∞·ª£c b√†i to√°n Maximum (log-)likelihood.</p>

<p><a name="-tom-tat"></a></p>

<h2 id="4-t√≥m-t·∫Øt">4. T√≥m t·∫Øt</h2>
<ul>
  <li>
    <p>Khi s·ª≠ d·ª•ng c√°c m√¥ h√¨nh th·ªëng k√™ Machine Learning, ch√∫ng ta th∆∞·ªùng xuy√™n ph·∫£i ƒëi ƒë√°nh gi√° c√°c tham s·ªë c·ªßa m√¥ h√¨nh, ƒë·∫°i di·ªán cho c√°c tham s·ªë c·ªßa c√°c ph√¢n ph·ªëi x√°c su·∫•t. T·∫≠p h·ª£p tham s·ªë m√¥ h√¨nh th∆∞·ªùng ƒë∆∞·ª£c k√Ω hi·ªáu l√† \(\theta\). C√≥ hai ph∆∞∆°ng ph√°p ph·ªï bi·∫øn ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒë√°nh gi√° \(\theta\) l√† Maximum Likelihood Estimation (MLE) v√† Maximum A Posteriori Estimation (MAP).</p>
  </li>
  <li>
    <p>V·ªõi MLE, vi·ªác x√°c ƒë·ªãnh tham s·ªë \(\theta\) ƒë∆∞·ª£c th·ª±c hi·ªán b·∫±ng c√°ch ƒëi t√¨m c√°c tham s·ªë sao cho x√°c su·∫•t c·ªßa training data (s·ª± th·∫≠t), hay c√≤n g·ªçi l√† <em>likelihood</em>, l√† l·ªõn nh·∫•t, :
\[
\theta = \arg\max_{\theta} p(\mathbf{x}_1, \dots, \mathbf{x}_N |\theta)
\]</p>
  </li>
  <li>
    <p>ƒê·ªÉ gi·∫£i b√†i to√°n t·ªëi ∆∞u n√†y, gi·∫£ thi·∫øt c√°c d·ªØ li·ªáu \(\mathbf{x}_i\) ƒë·ªôc l·∫≠p th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng. V√† b√†i to√°n MLE tr·ªü th√†nh:
\[
\theta = \arg\max_{\theta} \prod_{i=1}^N p(\mathbf{x}_i | \theta)
\]</p>
  </li>
  <li>V·ªõi MAP, c√°c tham s·ªë ƒë∆∞·ª£c ƒë√°nh gi√° b·∫±ng c√°ch t·ªëi ƒëa <em>posterior</em>:
\[
  \theta = \arg\max_{\theta} p(\theta | \mathbf{x}_1, \dots, \mathbf{x}_N)
\]</li>
  <li>
    <p>ƒê·ªÉ gi·∫£i b√†i to√°n n√†y, ta th∆∞·ªùng s·ª≠ d·ª•ng Bayes‚Äô rule v√† gi·∫£ thi·∫øt ƒë·ªôc l·∫≠p c·ªßa d·ªØ li·ªáu:
\[
\theta = \arg\max_{\theta} \left[\prod_{i=1}^N p(\mathbf{x}_i | \theta) p(\theta) \right]
\]
H√†m m·ª•c ti√™u ch√≠nh l√† t√≠ch c·ªßa <em>likelihood</em> v√† <em>prior</em>.</p>
  </li>
  <li>
    <p><em>Prior</em> th∆∞·ªùng ƒë∆∞·ª£c ch·ªçn d·ª±a tr√™n c√°c th√¥ng tin bi·∫øt tr∆∞·ªõc c·ªßa tham s·ªë, v√† ph√¢n ph·ªëi ƒë∆∞·ª£c ch·ªçn th∆∞·ªùng l√† c√°c <em>conjugate distribution</em> v·ªõi likelihood, t·ª©c c√°c distribution khi·∫øn vi·ªác nh√¢n th√™m <em>prior</em> v·∫´n gi·ªØ ƒë∆∞·ª£c c·∫•u tr√∫c gi·ªëng nh∆∞ <em>likelihood</em>.</p>
  </li>
  <li>
    <p>MAP c√≥ th·ªÉ ƒë∆∞·ª£c coi l√† m·ªôt ph∆∞∆°ng ph√°p gi√∫p tr√°nh overfitting (ho·∫∑c overconfidence). MAP th∆∞·ªùng mang l·∫°i hi·ªáu qu·∫£ cao h∆°n MLE v·ªõi tr∆∞·ªùng h·ª£p c√≥ √≠t d·ªØ li·ªáu training.</p>
  </li>
  <li>Trong b√†i ti·∫øp theo, ch√∫ng ta s·∫Ω th·∫•y r√µ ∆∞u ƒëi·ªÉm c·ªßa MAP trong m·ªôt trong <a href="http://www.kdnuggets.com/2016/08/10-algorithms-machine-learning-engineers.html">10 thu·∫≠t to√°n c·∫ßn bi·∫øt trong Machine Learning</a> - Naive Bayes Classifier. M·ªùi b·∫°n ƒë√≥n ƒë·ªçc.</li>
</ul>

<p><a name="-tai-lieu-tham-khao"></a></p>

<h2 id="5-t√†i-li·ªáu-tham-kh·∫£o">5. T√†i li·ªáu tham kh·∫£o</h2>

<p>[1] Chapter 4, 6 c·ªßa <a href="http://www.computervisionmodels.com">Computer Vision:  Models, Learning, and Inference - Simon J.D. Prince</a></p>

<p>[2] <a href="https://en.wikipedia.org/wiki/Conjugate_prior">Conjugate prior</a></p>
:ET