I"jÜ<p><strong>Trong trang n√†y:</strong>
<!-- MarkdownTOC --></p>

<ul>
  <li><a href="#-moi-quan-he-giua-pca-va-svd">1. M·ªëi quan h·ªá gi·ªØa PCA v√† SVD</a>
    <ul>
      <li><a href="#-svd-cho-bai-toan-xap-xi-low-rank-tot-nhat">1.1. SVD cho b√†i to√°n x·∫•p x·ªâ low-rank t·ªët nh·∫•t</a></li>
      <li><a href="#-y-tuong-cua-pca">1.2. √ù t∆∞·ªüng c·ªßa PCA</a></li>
      <li><a href="#-quan-he-giua-pca-va-svd">1.3. Quan h·ªá gi·ªØa PCA v√† SVD</a></li>
    </ul>
  </li>
  <li><a href="#-lam-the-nao-de-chon-chieu-cua-du-lieu-moi">2. L√†m th·∫ø n√†o ƒë·ªÉ ch·ªçn chi·ªÅu c·ªßa d·ªØ li·ªáu m·ªõi</a></li>
  <li><a href="#-luu-y-ve-tinh-pca-trong-cac-bai-toan-thuc-te">3. L∆∞u √Ω v·ªÅ t√≠nh PCA trong c√°c b√†i to√°n th·ª±c t·∫ø</a>
    <ul>
      <li><a href="#-so-chieu-du-lieu-nhieu-hon-so-diem-du-lieu">3.1. S·ªë chi·ªÅu d·ªØ li·ªáu nhi·ªÅu h∆°n s·ªë ƒëi·ªÉm d·ªØ li·ªáu</a>
        <ul>
          <li><a href="#-chuan-hoa-cac-vector-rieng">3.2. Chu·∫©n ho√° c√°c vector ri√™ng</a></li>
        </ul>
      </li>
      <li><a href="#-voi-cac-bai-toan-large-scale">3.3. V·ªõi c√°c b√†i to√°n large-scale</a></li>
    </ul>
  </li>
  <li><a href="#-vi-du-tren-python">4. V√≠ d·ª• tr√™n Python</a>
    <ul>
      <li><a href="#-eigenface">4.1. Eigenface</a></li>
      <li><a href="#--unsupervised-abnormal-detection">4.2.  Unsupervised Abnormal Detection</a></li>
    </ul>
  </li>
  <li><a href="#-thao-luan">5. Th·∫£o lu·∫≠n</a></li>
  <li><a href="#-tai-lieu-tham-khao">6. T√†i li·ªáu tham kh·∫£o</a></li>
</ul>

<!-- /MarkdownTOC -->

<p>Trong <a href="/2017/06/15/pca/">ph·∫ßn 1 c·ªßa Principal Component Analysis</a> (PCA), m·ªôt ph∆∞∆°ng ph√°p gi·∫£m chi·ªÅu d·ªØ li·ªáu r·∫•t quan tr·ªçng, ch√∫ng ta ƒë√£ c√πng √¥n l·∫°i m·ªôt v√†i ki·∫øn th·ª©c v·ªÅ ƒê·∫°i s·ªë tuy·∫øn t√≠nh v√† Th·ªëng k√™, ƒë·ªìng th·ªùi, √Ω nghƒ©a to√°n h·ªçc v√† c√°c b∆∞·ªõc th·ª±c hi·ªán PCA c≈©ng ƒë√£ ƒë∆∞·ª£c tr√¨nh b√†y. Trong ph·∫ßn 2 n√†y, ch√∫ng ta c√πng t√¨m hi·ªÉu th√™m m·ªôt v√†i t√≠nh ch·∫•t quan tr·ªçng c·ªßa PCA c≈©ng nh∆∞ c√°c ·ª©ng d·ª•ng n·ªïi b·∫≠t c·ªßa PCA trong c√°c b√†i to√°n Machine Learning.</p>

<p><em>C√°c b·∫°n ƒë∆∞·ª£c khuy·∫øn kh√≠ch ƒë·ªçc <a href="/2017/06/07/svd/">B√†i 26</a> v√† <a href="/2017/06/15/pca/">B√†i 27</a> tr∆∞·ªõc khi ƒë·ªçc b√†i n√†y.</em></p>

<p><a name="-moi-quan-he-giua-pca-va-svd"></a></p>

<h2 id="1-m·ªëi-quan-h·ªá-gi·ªØa-pca-v√†-svd">1. M·ªëi quan h·ªá gi·ªØa PCA v√† SVD</h2>
<p>Gi·ªØa PCA v√† SVD c√≥ m·ªói quan h·ªá ƒë·∫∑c bi·ªát v·ªõi nhau. ƒê·ªÉ nh·∫≠n ra ƒëi·ªÅu n√†y, t√¥i xin ƒë∆∞·ª£c nh·∫Øc l·∫°i hai ƒëi·ªÉm ƒë√£ tr√¨nh b√†y sau ƒë√¢y:</p>

<p><a name="-svd-cho-bai-toan-xap-xi-low-rank-tot-nhat"></a></p>

<h3 id="11-svd-cho-b√†i-to√°n-x·∫•p-x·ªâ-low-rank-t·ªët-nh·∫•t">1.1. SVD cho b√†i to√°n x·∫•p x·ªâ low-rank t·ªët nh·∫•t</h3>
<p>Nghi·ªám \(\mathbf{A}\) c·ªßa b√†i to√°n x·∫•p x·ªâ m·ªôt ma tr·∫≠n b·ªüi m·ªôt ma tr·∫≠n kh√°c c√≥ rank kh√¥ng v∆∞·ª£t qu√° \(k\):
\[
\begin{eqnarray}
\min_{\mathbf{A}} &amp;&amp;||\mathbf{X} - \mathbf{A}||_F ~~~~~~~~~~~~~~ (1)\newline
\text{s.t.} &amp;&amp; \text{rank}(\mathbf{A}) = K
\end{eqnarray}
\]</p>

<p>ch√≠nh l√† <a href="http://machinelearningcoban.com/2017/06/07/svd/#-truncated-svd">Truncated SVD</a> c·ªßa \(\mathbf{A}\). C·ª• th·ªÉ, n·∫øu SVD c·ªßa \(\mathbf{X} \in\mathbb{R}^{D\times N}\) l√†:
\[
  \mathbf{X} = \mathbf{U}\mathbf{\Sigma}\mathbf{V}^T
\]
v·ªõi \(\mathbf{U} \in \mathbb{R}^{D \times D}\) v√† \(\mathbf{V}\in \mathbb{R}^{N\times N}\) l√† c√°c ma tr·∫≠n tr·ª±c giao, v√† \(\mathbf{\Sigma} \in \mathbb{R}^{D \times N}\) l√† ma tr·∫≠n ƒë∆∞·ªùng ch√©o (kh√¥ng nh·∫•t thi·∫øt vu√¥ng) v·ªõi c√°c ph·∫ßn t·ª≠ tr√™n ƒë∆∞·ªùng ch√©o kh√¥ng √¢m gi·∫£m d·∫ßn, th√¨ nghi·ªám c·ªßa b√†i to√°n \((1)\) ch√≠nh l√†:
\[
  \mathbf{A} = \mathbf{U}_K \mathbf{\Sigma}_K \mathbf{V}_K^T ~~~ (2)
\]</p>

<p>v·ªõi \(\mathbf{U} \in \mathbb{R}^{D \times K}\) v√† \(\mathbf{V}\in \mathbb{R}^{N\times K}\) l√† c√°c ma tr·∫≠n t·∫°o b·ªüi \(K\) c·ªôt ƒë·∫ßu ti√™n c·ªßa \(\mathbf{U}\) v√† \(\mathbf{V}\), v√† \(\mathbf{\Sigma}_K \in \mathbb{R}^{K \times K}\) l√† ma tr·∫≠n ƒë∆∞·ªùng ch√©o con ·ª©ng v·ªõi \(K\) h√†ng ƒë·∫ßu ti√™n v√† \(K\) c·ªôt ƒë·∫ßu ti√™n c·ªßa \(\mathbf{\Sigma}\).</p>

<p><a name="-y-tuong-cua-pca"></a></p>

<h3 id="12-√Ω-t∆∞·ªüng-c·ªßa-pca">1.2. √ù t∆∞·ªüng c·ªßa PCA</h3>
<p>Trong PCA, nh∆∞ ƒë√£ ch·ª©ng minh ·ªü <a href="/2017/06/15/pca/#eqn10">bi·ªÉu th·ª©c \((10)\) trong B√†i 27</a>, PCA l√† b√†i to√°n ƒëi t√¨m ma tr·∫≠n tr·ª±c giao \(\mathbf{U}\) v√† ma tr·∫≠n m√¥ t·∫£ d·ªØ li·ªáu ·ªü kh√¥ng gian th·∫•p chi·ªÅu \(\mathbf{Z}\) sao cho vi·ªác x·∫•p x·ªâ sau ƒë√¢y l√† t·ªët nh·∫•t:
\[
\mathbf{X} \approx \tilde{\mathbf{X}} = \mathbf{U}_K \mathbf{Z} + \bar{\mathbf{U}}_K \bar{\mathbf{U}}_K^T\bar{\mathbf{x}}\mathbf{1}^T ~~~ (3)
\]
v·ªõi \(\mathbf{U}_K, \bar{\mathbf{U}}_K\) l·∫ßn l∆∞·ª£t l√† c√°c ma tr·∫≠n ƒë∆∞·ª£c t·∫°o b·ªüi \(K\) c·ªôt ƒë·∫ßu ti√™n v√† \(D-K\) c·ªôt cu·ªëi c√πng c·ªßa ma tr·∫≠n tr·ª±c giao \(\mathbf{U}\), v√† \(\bar{\mathbf{x}}\) l√† vector k·ª≥ v·ªçng c·ªßa d·ªØ li·ªáu.</p>

<p><strong>Gi·∫£ s·ª≠ r·∫±ng vector k·ª≥ v·ªçng \(\bar{\mathbf{x}} = \mathbf{0}\)</strong>. Khi ƒë√≥, \((3)\) t∆∞∆°ng ƒë∆∞∆°ng v·ªõi:
\[
\mathbf{X} \approx \tilde{\mathbf{X}} = \mathbf{U}_K \mathbf{Z}~~~ (4)
\]</p>

<p>B√†i to√°n t·ªëi ∆∞u c·ªßa PCA s·∫Ω tr·ªü th√†nh:
\[
\begin{eqnarray}
  \mathbf{U}_K, \mathbf{Z} &amp;=&amp; \min_{\mathbf{U}_K, \mathbf{Z} } ||\mathbf{X} - \mathbf{U}_K \mathbf{Z}||_F&amp; (5)\newline
  \text{s.t.:}&amp;&amp; \mathbf{U}_K^T \mathbf{U}_K = \mathbf{I}_K &amp;
\end{eqnarray}
\]
v·ªõi \(\mathbf{I}_K \in \mathbb{R}^{K\times K}\) l√† ma tr·∫≠n ƒë∆°n v·ªã trong kh√¥ng gian \(K\) chi·ªÅu, v√† ƒëi·ªÅu ki·ªán r√†ng bu·ªôc l√† ƒë·ªÉ ƒë·∫£m b·∫£o c√°c c·ªôt c·ªßa \(\mathbf{U}_K\) t·∫°o th√†nh m·ªôt h·ªá tr·ª±c chu·∫©n.</p>

<p><a name="-quan-he-giua-pca-va-svd"></a></p>

<h3 id="13-quan-h·ªá-gi·ªØa-pca-v√†-svd">1.3. Quan h·ªá gi·ªØa PCA v√† SVD</h3>
<p>B·∫°n c√≥ nh·∫≠n ra ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng gi·ªØa hai b√†i to√°n t·ªëi ∆∞u \((1)\) v√† \((5)\) v·ªõi nghi·ªám c·ªßa b√†i to√°n ƒë·∫ßu ti√™n ƒë∆∞·ª£c cho trong \((2)\)? B·∫°n c√≥ th·ªÉ nh·∫≠n ra ngay nghi·ªám c·ªßa b√†i to√°n \((5)\) ch√≠nh l√†:
\[
\begin{eqnarray}
  \mathbf{U}_K \quad \text{in}\quad (5) &amp;=&amp; \mathbf{U}_K\quad \text{in} \quad(2) \newline
  \mathbf{Z} \quad\text{in}\quad (5) &amp;=&amp; \mathbf{\Sigma}_K \mathbf{V}_K^T \quad \text{in} \quad (2)
\end{eqnarray}
\]</p>

<p>Nh∆∞ v·∫≠y, n·∫øu c√°c ƒëi·ªÉm d·ªØ li·ªáu ƒë∆∞·ª£c bi·ªÖu di·ªÖn b·ªüi c√°c c·ªôt c·ªßa m·ªôt ma tr·∫≠n, v√† trung b√¨nh c·ªông c·ªßa m·ªói h√†ng c·ªßa ma tr·∫≠n ƒë√≥ b·∫±ng 0 (ƒë·ªÉ cho vector k·ª≥ v·ªçng b·∫±ng 0), th√¨ nghi·ªám c·ªßa b√†i to√°n PCA ƒë∆∞·ª£c r√∫t ra tr·ª±c ti·∫øp t·ª´ Truncated SVD c·ªßa ma tr·∫≠n ƒë√≥. N√≥i c√°ch kh√°c, nghi·ªám c·ªßa PCA ch√≠nh l√† m·ªôt tr∆∞·ªùng h·ª£p ƒë·∫∑c bi·ªát c·ªßa b√†i to√°n Matrix Factorization gi·∫£i b·∫±ng SVD.</p>

<p><a name="-lam-the-nao-de-chon-chieu-cua-du-lieu-moi"></a></p>

<h2 id="2-l√†m-th·∫ø-n√†o-ƒë·ªÉ-ch·ªçn-chi·ªÅu-c·ªßa-d·ªØ-li·ªáu-m·ªõi">2. L√†m th·∫ø n√†o ƒë·ªÉ ch·ªçn chi·ªÅu c·ªßa d·ªØ li·ªáu m·ªõi</h2>

<p>M·ªôt c√¢u h·ªèi ƒë∆∞·ª£c ƒë·∫∑t ra l√†, l√†m th·∫ø n√†o ƒë·ªÉ ch·ªçn ra gi√° tr·ªã \(K\) - chi·ªÅu c·ªßa d·ªØ li·ªáu m·ªõi - v·ªõi t·ª´ng lo·∫°i d·ªØ li·ªáu kh√°c nhau?</p>

<p>C√≥ m·ªôt c√°ch x√°c ƒë·ªãnh \(K\) l√† d·ª±a tr√™n vi·ªác <em>l∆∞·ª£ng th√¥ng tin mu·ªën gi·ªØ l·∫°i</em>. Nh∆∞ ƒë√£ tr√¨nh b√†y, PCA c√≤n ƒë∆∞·ª£c g·ªçi l√† ph∆∞∆°ng ph√°p t·ªëi ƒëa <em>t·ªïng ph∆∞∆°ng sai ƒë∆∞·ª£c gi·ªØ l·∫°i</em>. V·∫≠y ta c√≥ th·ªÉ coi t·ªïng c√°c ph∆∞∆°ng sai ƒë∆∞·ª£c gi·ªØ l·∫°i l√† l∆∞·ª£ng th√¥ng tin ƒë∆∞·ª£c gi·ªØ l·∫°i. V·ªõi ph∆∞∆°ng sai c√†ng l·ªõn, t·ª©c d·ªØ li·ªáu c√≥ ƒë·ªô ph√¢n t√°n cao, th·ªÉ hi·ªán l∆∞·ª£ng th√¥ng tin c√†ng l·ªõn.</p>

<p>Nh·∫Øc l·∫°i r·∫±ng trong m·ªçi h·ªá tr·ª•c to·∫° ƒë·ªô, t·ªïng ph∆∞∆°ng sai c·ªßa d·ªØ li·ªáu l√† nh∆∞ nhau v√† b·∫±ng t·ªïng c√°c tr·ªã ri√™ng c·ªßa ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai \(\sum_{i=1}^D \lambda_i\). Th√™m n·ªØa, PCA gi√∫p gi·ªØ l·∫°i l∆∞·ª£ng th√¥ng tin (t·ªïng c√°c ph∆∞∆°ng sai) l√†: \(\sum_{i=1}^K \lambda_i\). V·∫≠y ta c√≥ th·ªÉ coi bi·ªÉu th·ª©c:
 \[
   r_K = \frac{\sum_{i=1}^K \lambda_i}{\sum_{j=1}^D \lambda_j} \quad \quad (6)
 \]
l√† l∆∞·ª£ng th√¥ng tin ƒë∆∞·ª£c gi·ªØ l·∫°i khi s·ªë chi·ªÅu d·ªØ li·ªáu m·ªõi sau PCA l√† \(K\).</p>

<p>Nh∆∞ v·∫≠y, gi·∫£ s·ª≠ ta mu·ªën gi·ªØ l·∫°i 99% d·ªØ li·ªáu, ta ch·ªâ c·∫ßn ch·ªçn \(K\) l√† s·ªë t·ª± nhi√™n nh·ªè nh·∫•t sao cho \(r_K \geq 0.99\).</p>

<p>Khi d·ªØ li·ªáu ph√¢n b·ªë quanh m·ªôt kh√¥ng gian con, c√°c gi√° tr·ªã ph∆∞∆°ng sai l·ªõn nh·∫•t ·ª©ng v·ªõi c√°c \(\lambda_i\) ƒë·∫ßu ti√™n l·ªõn h∆°n nhi·ªÅu so v·ªõi c√°c ph∆∞∆°ng sai c√≤n l·∫°i. Khi ƒë√≥, ta c√≥ th·ªÉ ch·ªçn ƒë∆∞·ª£c \(K\) kh√° nh·ªè ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c \(r_K \geq 0.99\).</p>

<p><a name="-luu-y-ve-tinh-pca-trong-cac-bai-toan-thuc-te"></a></p>

<h2 id="3-l∆∞u-√Ω-v·ªÅ-t√≠nh-pca-trong-c√°c-b√†i-to√°n-th·ª±c-t·∫ø">3. L∆∞u √Ω v·ªÅ t√≠nh PCA trong c√°c b√†i to√°n th·ª±c t·∫ø</h2>
<p>C√≥ hai tr∆∞·ªùng h·ª£p trong th·ª±c t·∫ø m√† ch√∫ng ta c·∫ßn l∆∞u √Ω v·ªÅ PCA. Tr∆∞·ªùng h·ª£p th·ª© nh·∫•t l√† l∆∞·ª£ng d·ªØ li·ªáu c√≥ ƒë∆∞·ª£c nh·ªè h∆°n r·∫•t nhi·ªÅu so v·ªõi s·ªë chi·ªÅu d·ªØ li·ªáu. Tr∆∞·ªùng h·ª£p th·ª© hai l√† khi l∆∞·ª£ng d·ªØ li·ªáu trong t·∫≠p training l√† r·∫•t l·ªõn, c√≥ th·ªÉ l√™n t·ªõi c·∫£ tri·ªáu. Vi·ªác t√≠nh to√°n ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai v√† tr·ªã ri√™ng ƒë√¥i khi tr·ªü n√™n b·∫•t kh·∫£ thi. C√≥ nh·ªØng h∆∞·ªõng gi·∫£i quy·∫øt hi·ªáu qu·∫£ cho c√°c tr∆∞·ªùng h·ª£p n√†y.</p>

<p><strong>Trong m·ª•c n√†y, ta s·∫Ω coi nh∆∞ d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chu·∫©n ho√°, t·ª©c ƒë√£ ƒë∆∞·ª£c tr·ª´ ƒëi vector k·ª≥ v·ªçng. Khi ƒë√≥, ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai s·∫Ω l√† \(\mathbf{S} = \frac{1}{N}\mathbf{X}\mathbf{X}^T\).</strong>
<a name="-so-chieu-du-lieu-nhieu-hon-so-diem-du-lieu"></a></p>

<h3 id="31-s·ªë-chi·ªÅu-d·ªØ-li·ªáu-nhi·ªÅu-h∆°n-s·ªë-ƒëi·ªÉm-d·ªØ-li·ªáu">3.1. S·ªë chi·ªÅu d·ªØ li·ªáu nhi·ªÅu h∆°n s·ªë ƒëi·ªÉm d·ªØ li·ªáu</h3>

<p>ƒê√≥ l√† tr∆∞·ªùng h·ª£p \(D &gt; N\), t·ª©c ma tr·∫≠n d·ªØ li·ªáu \(\mathbf{X}\) l√† m·ªôt ‚Äòma tr·∫≠n cao‚Äô. Khi ƒë√≥, s·ªë tr·ªã ri√™ng kh√°c kh√¥ng c·ªßa ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai \(\mathbf{S}\) s·∫Ω kh√¥ng v∆∞·ª£t qu√° rank c·ªßa n√≥, t·ª©c kh√¥ng v∆∞·ª£t qu√° \(N\). V·∫≠y ta c·∫ßn ch·ªçn \(K \leq N\) v√¨ kh√¥ng th·ªÉ ch·ªçn ra ƒë∆∞·ª£c \(K &gt; N\) tr·ªã ri√™ng kh√°c 0 c·ªßa m·ªôt ma tr·∫≠n c√≥ rank b·∫±ng \(N\).</p>

<p>Vi·ªác t√≠nh to√°n c√°c tr·ªã ri√™ng v√† vector ri√™ng c≈©ng c√≥ th·ªÉ ƒë∆∞·ª£c th·ª±c hi·ªán m·ªôt c√°ch hi·ªáu qu·∫£ d·ª±a tr√™n c√°c t√≠nh ch·∫•t sau ƒë√¢y:</p>

<p><strong>T√≠nh ch·∫•t 1:</strong> Tr·ªã ri√™ng c·ªßa \(\mathbf{A}\) c≈©ng l√† tr·ªã ri√™ng c·ªßa \(k\mathbf{A}\) v·ªõi \(k \neq 0\) b·∫•t k·ª≥. ƒêi·ªÅu n√†y c√≥ th·ªÉ ƒë∆∞·ª£c suy ra tr·ª±c ti·∫øp t·ª´ ƒë·ªãnh nghƒ©a c·ªßa tr·ªã ri√™ng v√† vector ri√™ng.</p>

<p><strong>T√≠nh ch√¢t 2:</strong> Tr·ªã ri√™ng c·ªßa \(\mathbf{AB}\) c≈©ng l√† tr·ªã ri√™ng c·ªßa \(\mathbf{BA}\) v·ªõi \(\mathbf{A} \in \mathbb{R}^{d_1 \times d_2}, \mathbf{B} \in \mathbb{R} ^{d_2 \times d_1}\) l√† c√°c ma tr·∫≠n b·∫•t k·ª≥ v√† \(d_1, d_2\) l√† c√°c s·ªë t·ª± nhi√™n kh√°c kh√¥ng b·∫•t k·ª≥. T√¥i xin kh√¥ng ch·ª©ng minh quan s√°t n√†y.</p>

<p>Nh∆∞ v·∫≠y, thay v√¨ t√¨m tr·ªã ri√™ng c·ªßa ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai \(\mathbf{S} \in \mathbb{R}^{D\times D}\), ta ƒëi t√¨m tr·ªã ri√™ng c·ªßa ma tr·∫≠n \(\mathbf{T} = \mathbf{X}^T \mathbf{X} \in \mathbb{R}^{N \times N}\) c√≥ s·ªë chi·ªÅu nh·ªè h∆°n (v√¨ \(N &lt; D\)).</p>

<p><strong>T√≠nh ch·∫•t 3:</strong> Gi·∫£ s·ª≠ \((\lambda, \mathbf{u})\) l√† m·ªôt c·∫∑p tr·ªã ri√™ng - vector ri√™ng c·ªßa \(\mathbf{T}\), th·∫ø th√¨ \((\lambda, \mathbf{Xu})\) l√† m·ªôt c·∫∑p tr·ªã ri√™ng - vector ri√™ng c·ªßa \(\mathbf{S}\).</p>

<p>Th·∫≠t v·∫≠y:
\[
\begin{eqnarray}
  \mathbf{X}^T \mathbf{Xu} &amp;=&amp; \lambda \mathbf{u}&amp; \quad (7) \newline
  \Rightarrow (\mathbf{X}\mathbf{X}^T)(\mathbf{Xu}) &amp;=&amp; \lambda \mathbf{Xu} &amp; \quad (8)
\end{eqnarray}
\]</p>

<p>Bi·ªÉu th·ª©c \((7)\) l√† theo ƒë·ªãnh nghƒ©a c·ªßa tr·ªã ri√™ng v√† vector ri√™ng. Bi·ªÉu th·ª©c \((8)\) thu ƒë∆∞·ª£c t·ª´ \((7)\) b·∫±ng c√°ch nh√¢n b√™n tr√°i c·∫£ hai v·∫ø v·ªõi ma tr·∫≠n \(\mathbf{X}\). T·ª´ \((8)\) ta suy ra <strong>Quan s√°t 3</strong>.</p>

<p>Nh∆∞ v·∫≠y, ta c√≥ th·ªÉ ho√†n to√†n t√≠nh ƒë∆∞·ª£c tr·ªã ri√™ng v√† vector ri√™ng c·ªßa ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai d·ª±a tr√™n m·ªôt ma tr·∫≠n nh·ªè h∆°n.</p>

<p><a name="-chuan-hoa-cac-vector-rieng"></a></p>

<h4 id="32-chu·∫©n-ho√°-c√°c-vector-ri√™ng">3.2. Chu·∫©n ho√° c√°c vector ri√™ng</h4>

<p><em>Nh·∫Øc l·∫°i ƒë·ªãnh nghƒ©a kh√¥ng gian ri√™ng: Kh√¥ng gian ri√™ng ·ª©ng v·ªõi tr·ªã ri√™ng c·ªßa m·ªôt ma tr·∫≠n l√† kh√¥ng gian sinh (span subspace) t·∫°o b·ªüi to√†n b·ªô c√°c vector ri√™ng ·ª©ng v·ªõi tr·ªã ri√™ng ƒë√≥.</em></p>

<p>Vi·ªác cu·ªëi c√πng ph·∫£i l√†m l√† chu·∫©n ho√° c√°c vector ri√™ng t√¨m ƒë∆∞·ª£c sao cho ch√∫ng t·∫°o th√†nh m·ªôt h·ªá tr·ª±c chu·∫©n. Vi·ªác n√†y c√≥ th·ªÉ d·ª±a tr√™n hai ƒëi·ªÉm sau ƒë√¢y:</p>

<p><strong>Th·ª© nh·∫•t</strong>, n·∫øu \(\mathbf{A}\) l√† m·ªôt ma tr·∫≠n ƒë·ªëi x·ª©ng, \((\lambda_1, \mathbf{x}_1), (\lambda_2, \mathbf{x}_2)\) l√† c√°c cƒÉp tr·ªã ri√™ng - vector ri√™ng c·ªßa \(\mathbf{A}\) v·ªõi \(\lambda_1 \neq \lambda_2\), th·∫ø th√¨ \(\mathbf{x}_1^T\mathbf{x}_2 = 0\). N√≥i c√°ch kh√°c, hai vector b·∫•t k·ª≥ trong hai kh√¥ng gian ri√™ng kh√°c nhau c·ªßa m·ªôt ma tr·∫≠n ƒë·ªëi x·ª©ng th√¨ tr·ª±c giao v·ªõi nhau. Ch·ª©ng minh cho t√≠nh ch·∫•t n√†y c√≥ th·ªÉ ƒë∆∞·ª£c th·∫•y trong m·ªôt d√≤ng d∆∞·ªõi ƒë√¢y:
\[
\begin{eqnarray}
  \mathbf{x}_2^T \mathbf{Ax}_1 = \mathbf{x}_1^T \mathbf{Ax}_2 = \lambda_1 \mathbf{x}_2^T \mathbf{x}_1 = \lambda_2 \mathbf{x}_1^T \mathbf{x}_2 \Rightarrow \mathbf{x}_1^T \mathbf{x}_2 = 0
\end{eqnarray}
\]
D·∫•u b·∫±ng cu·ªëi c√πng x·∫£y ra v√¨ \(\lambda_1 \neq \lambda_2\).</p>

<p><strong>Th·ª© hai</strong>, v·ªõi c√°c tr·ªã ri√™ng ƒë·ªôc l·∫≠p t√¨m ƒë∆∞·ª£c trong m·ªôt kh√¥ng gian ri√™ng, ta c√≥ th·ªÉ d√πng Gram-Schmit process ƒë·ªÉ chu·∫©n ho√° ch√∫ng v·ªÅ m·ªôt h·ªá tr·ª±c chu·∫©n.</p>

<p>K·∫øt h·ª£p hai ƒëi·ªÉm tr√™n, ta c√≥ th·ªÉ thu ƒë∆∞·ª£c c√°c vector ri√™ng t·∫°o th√†nh m·ªôt h·ªá tr·ª±c chu·∫©n, ch√≠nh l√† ma tr·∫≠n \(\mathbf{U}_K\) trong PCA.</p>

<p><a name="-voi-cac-bai-toan-large-scale"></a></p>

<h3 id="33-v·ªõi-c√°c-b√†i-to√°n-large-scale">3.3. V·ªõi c√°c b√†i to√°n large-scale</h3>
<p>Trong r·∫•t nhi·ªÅu b√†i to√°n, c·∫£ \(D\) v√† \(N\) ƒë·ªÅu l√† c√°c s·ªë r·∫•t l·ªõn, ƒë·ªìng nghƒ©a v·ªõi vi·ªác ta ph·∫£i t√¨m tr·ªã ri√™ng cho m·ªôt ma tr·∫≠n r·∫•t l·ªõn. V√≠ d·ª•, c√≥ 1 tri·ªáu b·ª©c ·∫£nh 1000 \(\times\) 1000 pixel, nh∆∞ v·∫≠y \(D = N = 10^6\) l√† m·ªôt s·ªë r·∫•t l·ªõn, vi·ªác tr·ª±c ti·∫øp t√≠nh to√°n tr·ªã ri√™ng v√† vector ri√™ng cho ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai l√† kh√¥ng kh·∫£ thi. Tuy nhi√™n, c√≥ m·ªôt ph∆∞∆°ng ph√°p cho ph√©p t√≠nh x·∫•p x·ªâ c√°c gi√° tr·ªã n√†y m·ªôt c√°ch nhanh h∆°n. Ph∆∞∆°ng ph√°p ƒë√≥ c√≥ t√™n l√† <a href="http://www.cs.huji.ac.il/~csip/tirgul2.pdf">Power Method</a>.</p>

<p>Ph∆∞∆°ng ph√°p n√†y n√≥i r·∫±ng, n·∫øu th·ª±c hi·ªán quy tr√¨nh sau, ta s·∫Ω t√¨m ƒë∆∞·ª£c c·∫∑p tr·ªã ri√™ng v√† vector ƒë·∫ßu ti√™n c·ªßa m·ªôt ma tr·∫≠n n·ª≠a x√°c ƒë·ªãnh d∆∞∆°ng:</p>
<hr />

<p><strong>Ph∆∞∆°ng ph√°p Power t√¨m tr·ªã ri√™ng v√† vector ri√™ng c·ªßa m·ªôt ma tr·∫≠n n·ª≠a x√°c ƒë·ªãnh d∆∞∆°ng \(\mathbf{A} \in \mathbb{R}^{n \times n}\)</strong>:</p>
<ol>
  <li>Ch·ªçn m·ªôt vector \(\mathbf{q}^{(0)} \in \mathbb{R}^n, ||\mathbf{q}^{(0)}||_2 = 1\) b·∫•t k·ª≥.</li>
  <li>V·ªõi \(k = 1, 2, \dots\), t√≠nh: \(\mathbf{z} = \mathbf{Aq}^{(k-1)}\).</li>
  <li>Chu·∫©n ho√°: \(\mathbf{q}^{(k)} = \mathbf{z} / ||\mathbf{z}||_2\).</li>
  <li>N·∫øu \(||\mathbf{q}^{(k)} - \mathbf{q}^{(k-1)}||_2\) ƒë·ªß nh·ªè th√¨ d·ª´ng l·∫°i. N·∫øu kh√¥ng, \(k := k + 1\) r·ªìi quay l·∫°i B∆∞·ªõc 2.</li>
  <li>\(\mathbf{q}^{(k)}\) ch√≠nh l√† vector ri√™ng ·ª©ng v·ªõi tr·ªã ri√™ng l·ªõn nh·∫•t \(\lambda_1 = (\mathbf{q}^{(k)})^T\mathbf{A}\mathbf{q}^{(k)}\).</li>
</ol>
<hr />

<p>Quy tr√¨nh n√†y h·ªôi t·ª• kh√° nhanh v√† ƒë√£ ƒë∆∞·ª£c ch·ª©ng minh <a href="http://www.cs.huji.ac.il/~csip/tirgul2.pdf">t·∫°i ƒë√¢y</a>. Ph·∫ßn ch·ª©ng minh t∆∞∆°ng ƒë·ªëi ƒë∆°n gi·∫£n v√† kh√¥ng mang l·∫°i nhi·ªÅu th√¥ng tin h·ªØu √≠ch, t√¥i xin ƒë∆∞·ª£c b·ªè qua.</p>

<p>ƒê·ªÉ t√¨m vector ri√™ng v√† tr·ªã ri√™ng th·ª© hai c·ªßa ma tr·∫≠n \(\mathbf{A}\), ch√∫ng ta d·ª±a tr√™n ƒë·ªãnh l√Ω sau:</p>
<hr />

<p><strong>ƒê·ªãnh l√Ω:</strong> N·∫øu ma tr·∫≠n n·ª≠a x√°c ƒë·ªãnh d∆∞∆°ng \(\mathbf{A}\) c√≥ c√°c tr·ªã ri√™ng \(\lambda_1 \geq \lambda_2 \geq \dots \geq \lambda_n ( \geq 0)\) v√† c√°c vector ri√™ng t∆∞∆°ng ·ª©ng \(\mathbf{v}_1, \dots, \mathbf{v}_n\), h∆°n n·ªØa c√°c vector ri√™ng n√†y t·∫°o th√†nh 1 h·ªá tr·ª±c chu·∫©n, th√¨ ma tr·∫≠n:
\[
  \mathbf{B} = \mathbf{A} - \lambda_1 \mathbf{v}_1 \mathbf{v}_1^T
\]
c√≥ c√°c tr·ªã ri√™ng \(\lambda_2 \geq \lambda_3 \geq \dots \geq \lambda_n \geq 0\) v√† c√°c vector ri√™ng t∆∞∆°ng ·ª©ng l√† \(\mathbf{v}_2, \mathbf{v}_3, \dots, \mathbf{v}_n, \mathbf{v}_1\).</p>
<hr />

<p>Ch·ª©ng minh:</p>

<p>V·ªõi \(i = 1\):
\[
\begin{eqnarray}
  \mathbf{Bv}_1 &amp;=&amp; (\mathbf{A} - \lambda_1 \mathbf{v}_1 \mathbf{v}_1^T) \mathbf{v}
  &amp;= &amp; \mathbf{Av}_1 - \lambda_1 \mathbf{v}_1 = \mathbf{0} \newline
\end{eqnarray}
\]</p>

<p>V·ªõi \(i &gt; 1\):
\[
\begin{eqnarray}
  \mathbf{Bv}_i &amp;=&amp; (\mathbf{A} - \lambda_1 \mathbf{v}_1 \mathbf{v}_1^T)\mathbf{v}_i \newline
  &amp;=&amp; \mathbf{Av}_i - \lambda_1 \mathbf{v}_1 (\mathbf{v}_1^T \mathbf{v}_i) \newline
  &amp;=&amp; \mathbf{Av}_i = \lambda_i \mathbf{v}_i
\end{eqnarray}
\]</p>

<p>Nh∆∞ v·∫≠y ƒë·ªãnh l√Ω ƒë√£ ƒë∆∞·ª£c ch·ª©ng minh.</p>

<p>L√∫c n√†y, \((\lambda_2, \mathbf{v}_2)\) l·∫°i tr·ªü th√†nh c·∫∑p tr·ªã ri√™ng-vector ri√™ng l·ªõn nh·∫•t c·ªßa \(\mathbf{B}\). C√°ch t√¨m hai bi·∫øn s·ªë n√†y m·ªôt l·∫ßn n·ªØa ƒë∆∞·ª£c th·ª±c hi·ªán b·∫±ng Ph∆∞∆°ng ph√°p Power.</p>

<p>Ti·∫øp t·ª•c quy tr√¨nh n√†y, ta s·∫Ω t√¨m ƒë∆∞·ª£c (x·∫•p x·ªâ) t·∫•t c·∫£ c√°c tr·ªã ri√™ng v√† vector ri√™ng t∆∞∆°ng ·ª©ng c·ªßa ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai. C≈©ng xin l∆∞u √Ω r·∫±ng ta ch·ªâ c·∫ßn t√¨m t·ªõi tr·ªã ri√™ng th·ª© \(K\) c·ªßa ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai. C√°ch l√†m n√†y tr√™n th·ª±c t·∫ø ƒë∆∞·ª£c s·ª≠ d·ª•ng r·∫•t nhi·ªÅu.</p>

<p>Ph∆∞∆°ng ph√°p Power c√≤n l√† thu·∫≠t to√°n c∆° b·∫£n trong <a href="https://en.wikipedia.org/wiki/PageRank">Google PageRank</a> gi√∫p s·∫Øp x·∫øp c√°c website theo m·ª©c ƒë·ªô ph·ªï bi·∫øn gi·∫£m d·∫ßn. PageRank ch√≠nh l√† n·ªÅn m√≥ng c·ªßa Google; ng√†y nay, vi·ªác t√¨m ki·∫øm trong Google s·ª≠ d·ª•ng nhi·ªÅu thu·∫≠t to√°n n√¢ng cao h∆°n PageRank. T√¥i s·∫Ω c√≥ m·ªôt b√†i ri√™ng v·ªÅ Google PageRank sau khi n√≥i v·ªÅ Chu·ªói Markov v√† M√¥ h√¨nh Markov ·∫©n.</p>

<p><a name="-vi-du-tren-python"></a></p>

<h2 id="4-v√≠-d·ª•-tr√™n-python">4. V√≠ d·ª• tr√™n Python</h2>

<p><a name="-eigenface"></a></p>

<h3 id="41-eigenface">4.1. Eigenface</h3>
<p><a href="https://en.wikipedia.org/wiki/Eigenface">Eigenface</a> l√† m·ªôt trong c√°c ph∆∞∆°ng ph√°p ph·ªï bi·∫øn nh·∫•t trong b√†i to√°n nh·∫≠n d·∫°ng khu√¥n m·∫∑t. √ù t∆∞·ªüng c·ªßa Eigenface l√† ƒëi t√¨m m·ªôt kh√¥ng gian c√≥ s·ªë chi·ªÅu nh·ªè h∆°n ƒë·ªÉ m√¥ t·∫£ m·ªói khu√¥n m·∫∑t, t·ª´ ƒë√≥ s·ª≠ d·ª•ng vector trong kh√¥ng gian th·∫•p n√†y nh∆∞ l√† feature vector cho vi·ªác th·ª±c hi·ªán classification. ƒêi·ªÅu ƒë√°ng n√≥i l√† m·ªôt b·ª©c ·∫£nh khu√¥n m·∫∑t c√≥ k√≠ch th∆∞·ªõc kho·∫£ng 200 \(\times\) 200 s·∫Ω c√≥ s·ªë chi·ªÅu l√† 40k - l√† m·ªôt s·ªë c·ª±c l·ªõn, trong khi ƒë√≥, feature vector th∆∞·ªùng ch·ªâ c√≥ s·ªë chi·ªÅu b·∫±ng v√†i trƒÉm.</p>

<p>Eigenface th·ª±c ra ch√≠nh l√† PCA. C√°c Eigenfaces ch√≠nh l√† c√°c eigenvectors ·ª©ng v·ªõi c√°c tr·ªã ri√™ng l·ªõn nh·∫•t c·ªßa ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai.</p>

<p>Trong ph·∫ßn n√†y, ch√∫ng ta c√πng l√†m m·ªôt th√≠ nghi·ªám nh·ªè tr√™n c∆° s·ªü d·ªØ li·ªáu <a href="http://vismod.media.mit.edu/vismod/classes/mas622-00/datasets/">Yale face database</a>. C√°c b·ª©c ·∫£nh trong th√≠ nghi·ªám n√†y ƒë√£ ƒë∆∞·ª£c cƒÉn ch·ªânh cho c√πng v·ªõi k√≠ch th∆∞·ªõc v√† khu√¥n m·∫∑t n·∫±m tr·ªçn v·∫πn trong m·ªôt h√¨nh ch·ªØ nh·∫≠t c√≥ k√≠ch th∆∞·ªõc \(116 \times  98\) pixel. C√≥ t·∫•t c·∫£ 15 ng∆∞·ªùi kh√°c nhau, m·ªói ng∆∞·ªùi c√≥ 11 b·ª©c ·∫£nh ƒë∆∞·ª£c ch·ª•p ·ªü c√°c ƒëi·ªÅu ki·ªán √°nh s√°ng v√† c·∫£m x√∫c kh√°c nhau, bao g·ªìm: ‚Äòcenterlight‚Äô, ‚Äòglasses‚Äô, ‚Äòhappy‚Äô, ‚Äòleftlight‚Äô, ‚Äònoglasses‚Äô, ‚Äònormal‚Äô, ‚Äòrightlight‚Äô,‚Äôsad‚Äô, ‚Äòsleepy‚Äô, ‚Äòsurprised‚Äô, v√† ‚Äòwink‚Äô.</p>

<p>H√¨nh 1 d∆∞·ªõi ƒë√¢y l√† v√≠ d·ª• v·ªÅ c√°c b·ª©c ·∫£nh c·ªßa ng∆∞·ªùi c√≥ id l√† 10.</p>
<hr />

<div class="imgcap">
<img src="/assets/28_pca2/yaleb_exs.png" align="center" width="800" />
</div>

<div class="thecap" align="left">H√¨nh 1: V√≠ d·ª• v·ªÅ ·∫£nh c·ªßa m·ªôt ng∆∞·ªùi trong Yale Face Database. </div>
<hr />

<p>Ta c√≥ th·ªÉ th·∫•y r·∫±ng s·ªë chi·ªÅu d·ªØ li·ªáu l√† \(116 \times 98 = 11368\) l√† m·ªôt s·ªë kh√° l·ªõn. Tuy nhi√™n, v√¨ ch·ªâ c√≥ t·ªïng c·ªông \(15 \times 11 = 165\) b·ª©c ·∫£nh n√™n ta c√≥ th·ªÉ n√©n c√°c b·ª©c ·∫£nh n√†y v·ªÅ d·ªØ li·ªáu m·ªõi c√≥ chi·ªÅu nh·ªè h∆°n 165. Trong v√≠ d·ª• n√†y, t√¥i ch·ªçn \(K = 100\).</p>

<p>D∆∞·ªõi ƒë√¢y l√† ƒëo·∫°n code th·ª±c hi·ªán PCA cho to√†n b·ªô d·ªØ li·ªáu. Ch√∫ √Ω r·∫±ng t√¥i s·ª≠ d·ª•ng th∆∞ vi·ªán <code class="language-plaintext highlighter-rouge">sklearn</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">misc</span>                     <span class="c1"># for loading image
</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># filename structure
</span><span class="n">path</span> <span class="o">=</span> <span class="s">'unpadded/'</span> <span class="c1"># path to the database
</span><span class="n">ids</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span> <span class="c1"># 15 persons
</span><span class="n">states</span> <span class="o">=</span> <span class="p">[</span><span class="s">'centerlight'</span><span class="p">,</span> <span class="s">'glasses'</span><span class="p">,</span> <span class="s">'happy'</span><span class="p">,</span> <span class="s">'leftlight'</span><span class="p">,</span>
          <span class="s">'noglasses'</span><span class="p">,</span> <span class="s">'normal'</span><span class="p">,</span> <span class="s">'rightlight'</span><span class="p">,</span><span class="s">'sad'</span><span class="p">,</span>
          <span class="s">'sleepy'</span><span class="p">,</span> <span class="s">'surprised'</span><span class="p">,</span> <span class="s">'wink'</span> <span class="p">]</span>
<span class="n">prefix</span> <span class="o">=</span> <span class="s">'subject'</span>
<span class="n">surfix</span> <span class="o">=</span> <span class="s">'.pgm'</span>

<span class="c1"># data dimension
</span><span class="n">h</span> <span class="o">=</span> <span class="mi">116</span> <span class="c1"># hight
</span><span class="n">w</span> <span class="o">=</span> <span class="mi">98</span> <span class="c1"># width
</span><span class="n">D</span> <span class="o">=</span> <span class="n">h</span> <span class="o">*</span> <span class="n">w</span>
<span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">states</span><span class="p">)</span><span class="o">*</span><span class="mi">15</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># collect all data
</span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">D</span><span class="p">,</span> <span class="n">N</span><span class="p">))</span>
<span class="n">cnt</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">person_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">state</span> <span class="ow">in</span> <span class="n">states</span><span class="p">:</span>
        <span class="n">fn</span> <span class="o">=</span> <span class="n">path</span> <span class="o">+</span> <span class="n">prefix</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">person_id</span><span class="p">).</span><span class="n">zfill</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="s">'.'</span> <span class="o">+</span> <span class="n">state</span> <span class="o">+</span> <span class="n">surfix</span>
        <span class="n">X</span><span class="p">[:,</span> <span class="n">cnt</span><span class="p">]</span> <span class="o">=</span> <span class="n">misc</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fn</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>
        <span class="n">cnt</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="c1"># Doing PCA, note that each row is a datapoint
</span><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">K</span><span class="p">)</span> <span class="c1"># K = 100
</span><span class="n">pca</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>

<span class="c1"># projection matrix
</span><span class="n">U</span> <span class="o">=</span> <span class="n">pca</span><span class="p">.</span><span class="n">components_</span><span class="p">.</span><span class="n">T</span>
</code></pre></div></div>

<p>Ch√∫ √Ω r·∫±ng c√°c h√†m c·ªßa <code class="language-plaintext highlighter-rouge">sklearn</code> ƒë·ªÅu ch·ªçn d·ªØ li·ªáu ·ªü d·∫°ng h√†ng. C√≤n t√¥i th∆∞·ªùng ch·ªçn d·ªØ li·ªáu ·ªü d·∫°ng c·ªôt cho thu·∫≠n ti·ªán trong bi·ªÉu di·ªÖn to√°n h·ªçc. Tr∆∞·ªõc khi s·ª≠ d·ª•ng <code class="language-plaintext highlighter-rouge">sklearn</code>, b·∫°n ƒë·ªçc ch√∫ √Ω chuy·ªÉn v·ªã ma tr·∫≠n d·ªØ li·ªáu.</p>

<p>Trong d√≤ng <code class="language-plaintext highlighter-rouge">pca = PCA(n_components=K)</code>, n·∫øu <code class="language-plaintext highlighter-rouge">n_components</code> l√† m·ªôt s·ªë th·ª±c trong kho·∫£ng \((0, 1)\), PCA s·∫Ω th·ª±c hi·ªán vi·ªác t√¨m \(K\) d·ª±a tr√™n bi·ªÉu th·ª©c \((6)\).</p>

<p>H√¨nh 2 d∆∞·ªõi ƒë√¢y bi·ªÉu di·ªÖn 18 vector ri√™ng ƒë·∫ßu ti√™n t√¨m ƒë∆∞·ª£c b·∫±ng PCA. C√°c vector t√¨m ƒë∆∞·ª£c ·ªü d·∫°ng vector c·ªôt, ta c·∫ßn ph·∫£i <code class="language-plaintext highlighter-rouge">reshape</code> ch√∫ng ƒë·ªÉ c√≥ th·ªÉ minh ho·∫° nh∆∞ c√°c b·ª©c ·∫£nh.</p>

<hr />

<div class="imgcap">
<img src="/assets/28_pca2/yaleb_eig.png" align="center" width="800" />
</div>

<div class="thecap" align="left">H√¨nh 2: C√°c eigenfaces t√¨m ƒë∆∞·ª£c b·∫±ng PCA. </div>
<hr />

<p>C√≥ m·ªôt ƒëi·ªÅu d·ªÖ nh·∫≠n ra l√† c√°c ·∫£nh minh ho·∫° c√°c vector thu ƒë∆∞·ª£c √≠t nhi·ªÅu mang th√¥ng tin c·ªßa m·∫∑t ng∆∞·ªùi. Th·ª±c t·∫ø, m·ªôt khu√¥n m·∫∑t g·ªëc s·∫Ω ƒë∆∞·ª£c x·∫•p x·ªâ nh∆∞ t·ªïng c√≥ tr·ªçng s·ªë c·ªßa c√°c <em>khu√¥n m·∫∑t</em> n√†y. V√¨ c√°c vector ri√™ng n√†y ƒë√≥ng vai tr√≤ nh∆∞ c∆° s·ªü c·ªßa kh√¥ng gian m·ªõi v·ªõi √≠t chi·ªÅu h∆°n, ch√∫ng c√≤n ƒë∆∞·ª£c g·ªçi l√† <em>khu√¥n m·∫∑t ri√™ng</em>, t·ª©c <em>eigenfaces</em>.</p>

<p>ƒê·ªÉ xem m·ª©c ƒë·ªô hi·ªáu qu·∫£ c·ªßa Eigenfaces nh∆∞ th·∫ø n√†o, ch√∫ng ta th·ª≠ minh ho·∫° c√°c b·ª©c ·∫£nh g·ªëc v√† c√°c b·ª©c ·∫£nh ƒë∆∞·ª£c x·∫•p x·ªâ b·∫±ng PCA, k·∫øt qu·∫£ ƒë∆∞·ª£c cho nh∆∞ H√¨nh 3 d∆∞·ªõi ƒë√¢y:
<!-- ============ --></p>
<hr />

<div class="imgcap">
<img src="/assets/28_pca2/yaleb_ori_res.png" align="center" width="800" />
</div>

<div class="thecap" align="left">H√¨nh 3: H√†ng tr√™n: c√°c ·∫£nh g·ªëc. H√†ng d∆∞·ªõi: c√°c ·∫£nh ƒë∆∞·ª£c <em>suy ra</em> t·ª´ eigenfaces. ·∫¢nh ·ªü h√†ng d∆∞·ªõi c√≥ nhi·ªÅu nhi·ªÖu nh∆∞ng v·∫´n mang nh·ªØng ƒë·∫∑c ƒëi·ªÉm ri√™ng m√† m·∫Øt ng∆∞·ªùi c√≥ th·ªÉ ph√¢n bi·ªát ƒë∆∞·ª£c. </div>
<hr />

<p>Nh∆∞ v·∫≠y, vector v·ªõi s·ªë chi·ªÅu \(K = 100\) trong kh√¥ng gian m·ªõi mang <em>kh√°</em> ƒë·∫ßy ƒë·ªß th√¥ng tin c·ªßa vector c√≥ s·ªë chi·ªÅu \(D = 11368\) trong kh√¥ng gian ban ƒë·∫ßu.</p>

<p>Ph·∫ßn c√≤n l·∫°i c·ªßa source code c√≥ th·ªÉ ƒë∆∞·ª£c t√¨m th·∫•y <a href="https://github.com/tiepvupsu/tiepvupsu.github.io/blob/master/assets/28_pca2/python/EigenFaces.ipynb">t·∫°i ƒë√¢y</a>.</p>

<p><a name="--unsupervised-abnormal-detection"></a></p>

<h3 id="42--unsupervised-abnormal-detection">4.2.  Unsupervised Abnormal Detection</h3>
<p>Ngo√†i c√°c ·ª©ng d·ª•ng v·ªÅ n√©n v√† classification, PCA c√≤n ƒë∆∞·ª£c s·ª≠ d·ª•ng trong nhi·ªÅu lƒ©nh v·ª±c kh√°c nhau. Abnormal Detection (d√≤ t√¨m c√°c hi·ªán t∆∞·ª£ng kh√¥ng b√¨nh th∆∞·ªùng) l√† m·ªôt trong s·ªë ƒë√≥. Th√™m n·ªØa, gi·∫£ s·ª≠ ch√∫ng ta kh√¥ng bi·∫øt nh√£n c·ªßa c√°c s·ª± ki·ªán n√†y, t·ª©c ta ƒëang l√†m vi·ªác v·ªõi m·ªôt b√†i to√°n Unsupervised.</p>

<p>√ù t∆∞·ªüng c∆° b·∫£n l√† c√°c s·ª± ki·ªán ‚Äònormal‚Äô th∆∞·ªùng n·∫±m g·∫ßn m·ªôt kh√¥ng gian con n√†o ƒë√≥, trong khi c√°c s·ª± ki·ªán ‚Äòabnormal‚Äô th∆∞·ªùng kh√°c bi·ªát v·ªõi c√°c s·ª± ki·ªán ‚Äònormal‚Äô, t·ª©c n·∫±m xa kh√¥ng gian con ƒë√≥. H∆°n n·ªØa, v√¨ l√† ‚Äòabnormal‚Äô n√™n s·ªë l∆∞·ª£ng c√°c s·ª± ki·ªán thu·ªôc lo·∫°i n√†y l√† r·∫•t nh·ªè so v·ªõi ‚Äònormal‚Äô.</p>

<p>Nh∆∞ v·∫≠y, ch√∫ng ta c√≥ th·ªÉ l√†m PCA tr√™n to√†n b·ªô d·ªØ li·ªáu ƒë·ªÉ t√¨m ra c√°c th√†nh ph·∫ßn ch√≠nh c·ªßa d·ªØ li·ªáu, t·ª´ ƒë√≥ suy ra kh√¥ng gian con m√† c√°c ƒëi·ªÉm ‚Äònormal‚Äô n·∫±m g·∫ßn. Vi·ªác x√°c ƒë·ªãnh m·ªôt ƒëi·ªÉm l√† ‚Äònormal‚Äô hay ‚Äòabnoral‚Äô ƒë∆∞·ª£c x√°c ƒë·ªãnh b·∫±ng c√°ch ƒëo kho·∫£ng c√°ch t·ª´ ƒëi·ªÉm ƒë√≥ t·ªõi kh√¥ng gian con t√¨m ƒë∆∞·ª£c.</p>

<p>H√¨nh 4 d∆∞·ªõi ƒë√¢y minh ho·∫° cho vi·ªác x√°c ƒë·ªãnh c√°c s·ª± ki·ªán kh√¥ng b√¨nh th∆∞·ªùng.</p>

<hr />

<div>
<table width="100%" style="border: 0px solid white">

    <tr>
        <td width="40%" style="border: 0px solid white" align="center">
        <img style="display:block;" width="100%" src="/assets/28_pca2/abnormal.png" />
         </td>
        <td width="40%" style="border: 0px solid white" align="justify">
        H√¨nh 4: PCA cho vi·ªác x√°c ƒë·ªãnh c√°c s·ª± ki·ªán 'abnormal' v·ªõi gi·∫£ s·ª≠ r·∫±ng c√°c s·ª± ki·ªán 'normal' chi·∫øm ƒëa s·ªë v√† n·∫±m g·∫ßn trong m·ªôt kh√¥ng gian con n√†o ƒë√≥. Khi ƒë√≥, n·∫øu l√†m PCA tr√™n to√†n b·ªô d·ªØ li·ªáu, kh√¥ng gian con thu ƒë∆∞·ª£c g·∫ßn v·ªõi kh√¥ng gian con c·ªßa t·∫≠p c√°c s·ª± ki·ªán 'normal'. L√∫c n√†y, c√°c ƒëi·ªÉm qu√° xa kh√¥ng gian con n√†y, trong tr∆∞·ªùng h·ª£p n√†y l√† c√°c ƒëi·ªÉm m√†u cam, c√≥ th·ªÉ ƒë∆∞·ª£c coi l√† c√°c s·ª± ki·ªán 'abnormal'.
        </td>
    </tr>
</table>
</div>
<hr />

<p>M·ªôt ·ª©ng d·ª•ng c·ªßa vi·ªác n√†y c√≥ th·ªÉ ƒë∆∞·ª£c t√¨m th·∫•y trong b√†i b√°o: <a href="http://www.cs.bu.edu/fac/crovella/paper-archive/sigc04-network-wide-anomalies.pdf">Diagnosing Network-Wide Traffic Anomalies</a>.</p>

<p><a name="-thao-luan"></a></p>

<h2 id="5-th·∫£o-lu·∫≠n">5. Th·∫£o lu·∫≠n</h2>

<ul>
  <li>
    <p>PCA l√† m·ªôt ph∆∞∆°ng ph√°p Unsupervised. Vi·ªác th·ª±c hi·ªán PCA tr√™n to√†n b·ªô d·ªØ li·ªáu kh√¥ng ph·ª• thu·ªôc v√†o class(n·∫øu c√≥) c·ªßa m·ªói d·ªØ li·ªáu. Vi·ªác n√†y ƒë√¥i khi khi·∫øn cho PCA kh√¥ng mang l·∫°i hi·ªáu qu·∫£ cho c√°c b√†i to√°n classification. Th·∫≠t v·∫≠y, gi·∫£ s·ª≠ trong kh√¥ng gian hai chi·ªÅu, 2 classes ph√¢n b·ªë d·ªçc hai b√™n c·ªßa 1 ƒë∆∞·ªùng th·∫≥ng. Nh∆∞ v·∫≠y, PCA nhi·ªÅu kh·∫£ nƒÉng s·∫Ω cho ch√∫ng ta gi·ªØ l·∫°i th√†nh ph·∫ßn ch√≠nh ch√≠nh l√† ƒë∆∞·ªùng th·∫≥ng ƒë√≥. Khi chi·∫øu d·ªØ li·ªáu l√™n ƒë∆∞·ªùng th·∫≥ng n√†y, c·∫£ hai classes b·ªã tr·ªôn l·∫´n v√†o nhau, khi·∫øn cho vi·ªác classification ƒë·∫°t k·∫øt qu·∫£ th·∫•p. C√≥ m·ªôt ph∆∞∆°ng ph√°p t∆∞∆°ng t·ª± nh∆∞ PCA gi√∫p t·∫≠n d·ª•ng th√¥ng tin v·ªÅ c√°c class ƒë·ªÉ x√°c ƒë·ªãnh chi·∫øu theo chi·ªÅu n√†o, ph∆∞∆°ng ph√°p ƒë√≥ c√≥ t√™n l√† <a href="https://en.wikipedia.org/wiki/Linear_discriminant_analysis">Linear Discriminant Analysis</a>, s·∫Ω ƒë∆∞·ª£c th·∫£o lu·∫≠n trong b√†i ti·∫øp theo.</p>
  </li>
  <li>
    <p>V·ªõi c√°c b√†i to√°n Large-scale, ƒë√¥i khi vi·ªác t√≠nh to√°n tr√™n to√†n b·ªô d·ªØ li·ªáu l√† kh√¥ng kh·∫£ thi v√¨ c√≤n c√≥ v·∫•n ƒë·ªÅ v·ªÅ b·ªô nh·ªõ. Gi·∫£i ph√°p l√† th·ª±c hi·ªán PCA l·∫ßn ƒë·∫ßu tr√™n m·ªôt t·∫≠p con d·ªØ li·ªáu v·ª´a v·ªõi b·ªô nh·ªõ, sau ƒë√≥ l·∫•y m·ªôt t·∫≠p con kh√°c ƒë·ªÉ (incrementally) c·∫≠p nh·∫≠t nghi·ªám c·ªßa PCA t·ªõi khi n√†o h·ªôi t·ª•. √ù t∆∞·ªüng n√†y kh√° gi·ªëng v·ªõi <a href="http://machinelearningcoban.com/2017/01/16/gradientdescent2/#-mini-batch-gradient-descent">Mini-batch Gradient Descent</a>, v√† ƒë∆∞·ª£c g·ªçi l√† <a href="http://cseweb.ucsd.edu/~dasgupta/papers/incremental-pca.pdf">Incremental PCA</a>.</p>
  </li>
  <li>
    <p>Ngo√†i ra, c√≤n r·∫•t nhi·ªÅu h∆∞·ªõng m·ªü r·ªông c·ªßa PCA, b·∫°n ƒë·ªçc c√≥ th·ªÉ t√¨m ki·∫øm theo t·ª´ kho√°: Sparse PCA, Kernel PCA, Robust PCA. T√¥i s·∫Ω ƒë·ªÅ c·∫≠p t·ªõi c√°c ph∆∞∆°ng ph√°p n√†y khi c√≥ d·ªãp.</p>
  </li>
</ul>

<p><a name="-tai-lieu-tham-khao"></a></p>

<h2 id="6-t√†i-li·ªáu-tham-kh·∫£o">6. T√†i li·ªáu tham kh·∫£o</h2>
<p>[1] <a href="https://www.youtube.com/watch?v=F-nfsSq42ow">PCA, SVD</a></p>

<p>[2] <a href="https://en.wikipedia.org/wiki/Eigenface">Eigenface</a></p>

<p>[3] <a href="http://cseweb.ucsd.edu/~dasgupta/papers/incremental-pca.pdf">The Fast Convergence of Incremental PCA</a></p>

<p>[4] <a href="http://www.cs.bu.edu/fac/crovella/paper-archive/sigc04-network-wide-anomalies.pdf">Diagnosing Network-Wide Traffic  Anomalies</a></p>

:ET