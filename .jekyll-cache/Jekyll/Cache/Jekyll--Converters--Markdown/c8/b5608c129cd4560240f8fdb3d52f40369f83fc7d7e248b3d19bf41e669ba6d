I"3*<!-- MarkdownTOC -->

<ul>
  <li><a href="#a">A</a></li>
  <li><a href="#b">B</a></li>
  <li><a href="#c">C</a></li>
  <li><a href="#d">D</a></li>
  <li><a href="#f">F</a></li>
  <li><a href="#g">G</a></li>
  <li><a href="#h">H</a></li>
  <li><a href="#k">K</a></li>
  <li><a href="#l">L</a></li>
  <li><a href="#m">M</a></li>
  <li><a href="#n">N</a></li>
  <li><a href="#o">O</a></li>
  <li><a href="#p">P</a></li>
  <li><a href="#q">Q</a></li>
  <li><a href="#r">R</a></li>
  <li><a href="#s">S</a></li>
  <li><a href="#t">T</a></li>
  <li><a href="#u">U</a></li>
</ul>

<!-- /MarkdownTOC -->

<p><a name="a"></a></p>

<h2 id="a">A</h2>
<ul>
  <li><a href="/2017/02/24/mlp/#-activation-functions">activation function</a></li>
  <li><a href="/2017/03/12/convexity/#-affine-functions">Affine function</a></li>
  <li><a href="/2017/03/12/convexity/#-\\\alpha-\\-sublevel-sets">\(\alpha\)-sublevel set</a></li>
  <li><a href="/2017/01/01/kmeans/#ham-mat-mat-va-bai-toan-toi-uu">arg min</a></li>
</ul>

<p><a name="b"></a></p>

<h2 id="b">B</h2>

<ul>
  <li><a href="/2017/02/24/mlp/#-backpropagation">Backpropagation</a></li>
  <li><a href="/general/2017/02/06/featureengineering/#bag-of-words">Bag of Words</a></li>
  <li><a href="/2017/04/28/multiclasssmv/#-bias-trick">Bias trick</a></li>
  <li><a href="/2017/02/11/binaryclassifiers/">Binary classifiers</a>
    <ul>
      <li><a href="/2017/02/11/binaryclassifiers/#one-vs-one">one-vs-one</a></li>
      <li><a href="/2017/02/11/binaryclassifiers/#hierarchical-phan-tang">Hierarchical</a></li>
      <li><a href="/2017/02/11/binaryclassifiers/#binary-coding">Binary coding</a></li>
      <li><a href="/2017/02/11/binaryclassifiers/#one-vs-rest-hay-one-hot-coding">one-vs-rest or one-hot coding</a> (<a href="/2017/01/01/kmeans/#one-hot">2</a>)</li>
    </ul>
  </li>
</ul>

<p><a name="c"></a></p>

<h2 id="c">C</h2>

<ul>
  <li><a href="/2017/04/28/multiclasssmv/#-bo-co-so-du-lieu-cifar">CIFAR-10</a></li>
  <li><a href="/2016/12/27/categories/#classification-phan-loai">Classification</a></li>
  <li><a href="/2016/12/27/categories/#clustering-phan-nhom">Clustering</a>
    <ul>
      <li><a href="/2017/01/01/kmeans/">K-means Clustering</a></li>
    </ul>
  </li>
  <li><a href="/2017/05/24/collaborativefiltering/">Collaborative Filtering</a>
    <ul>
      <li><a href="/2017/05/24/collaborativefiltering/#-item-item-collaborative-filtering">Item-item Collaborative Filtering</a></li>
      <li><a href="/2017/05/31/matrixfactorization/">Matrix Factorization Collaborative Filtering</a></li>
      <li><a href="/2017/05/24/collaborativefiltering/">Neighborhood-based</a></li>
      <li><a href="/2017/05/24/collaborativefiltering/#-user-user-collaborative-filtering">User-user Collaborative Filtering</a></li>
    </ul>
  </li>
  <li><a href="/2017/03/12/convexity/#-convex-combination-va-convex-hulls">Convex combination</a></li>
  <li><a href="/2017/03/12/convexity/#-convex-functions">Convex function</a>
    <ul>
      <li><a href="/2017/03/12/convexity/#-first-order-condition">First-order condition</a></li>
      <li><a href="/2017/03/12/convexity/#-second-order-condition">Second-order condition</a></li>
    </ul>
  </li>
  <li><a href="/2017/03/12/convexity/#-convex-combination-va-convex-hulls">Convex hull</a></li>
  <li><a href="/2017/03/19/convexopt/">Convex optimization problems</a></li>
  <li><a href="/2017/06/15/pca/#-ky-vong-va-ma-tran-hiep-phuong-sai">Covariance Matrix</a></li>
  <li><a href="/2017/03/12/convexity/#-convex-sets">Convex sets</a></li>
  <li><a href="/2017/02/17/softmax/#-cross-entropy">Cross entropy</a></li>
  <li><a href="/2017/03/04/overfitting/#-cross-validation">Cross validation</a></li>
</ul>

<p><a name="d"></a></p>

<h2 id="d">D</h2>
<ul>
  <li><a href="/2017/06/15/pca/#-gioi-thieu">Dimensionality Reduction</a> <a href="/general/2017/02/06/featureengineering/#dimensionality-reduction">2</a>
<a name="f"></a></li>
</ul>

<h2 id="f">F</h2>

<ul>
  <li><a href="/general/2017/02/06/featureengineering/">Feature Engineering</a>
    <ul>
      <li><a href="/general/2017/02/06/featureengineering/#feature-selection">Feature selection</a></li>
      <li><a href="/general/2017/02/06/featureengineering/#dimensionality-reduction">Dimensionality reduction</a></li>
      <li><a href="/general/2017/02/06/featureengineering/#feature-scaling-and-normalization">Feature Scaling and Normalization</a>
<a name="g"></a></li>
    </ul>
  </li>
</ul>

<h2 id="g">G</h2>

<ul>
  <li><a href="/2017/03/19/convexopt/#-geometric-programming">Geometric Programming</a></li>
  <li><a href="/2017/01/12/gradientdescent/">Gradient Descent (GD)</a>
    <ul>
      <li><a href="/2017/01/16/gradientdescent2/#-batch-gradient-descent">Batch Gradient Descent</a></li>
      <li><a href="/2017/01/16/gradientdescent2/#-mini-batch-gradient-descent">Mini-batch Gradient Descnet</a></li>
      <li><a href="/2017/01/16/gradientdescent2/#-momentum">Momentum</a></li>
      <li><a href="https://tiepvupsu.github.io/2017/01/16/gradientdescent2/#-nesterov-accelerated-gradient-nag">Nesterov accelerated gradient (NAG)</a></li>
      <li><a href="/2017/01/16/gradientdescent2/#-stochastic-gradient-descent">Stochastic Gradient Descent (SGD)</a></li>
    </ul>
  </li>
  <li><a href="/2017/01/08/knn/#ground-truth">Ground truth</a></li>
</ul>

<p><a name="h"></a></p>

<h2 id="h">H</h2>

<ul>
  <li><a href="/2017/02/24/mlp/#-layers">Hidden layer</a></li>
  <li><a href="/2017/04/13/softmarginsmv/#-hinge-loss">Hinge loss</a></li>
</ul>

<p><a name="k"></a></p>

<h2 id="k">K</h2>

<ul>
  <li><a href="/2017/01/01/kmeans/">K-means Clustering</a></li>
  <li><a href="/2017/01/08/knn/">K-nearest neighbors</a></li>
  <li><a href="/2017/04/22/kernelsmv/#-ham-so-kernel">Kernel functions</a>
<a name="l"></a></li>
</ul>

<h2 id="l">L</h2>

<ul>
  <li><a href="/2017/01/12/gradientdescent/#large-scale">Large-sclae problem</a></li>
  <li><a href="/2017/01/12/gradientdescent/#duong-dong-muc-level-sets">Level sets</a></li>
  <li><a href="/2017/03/19/convexopt/#-linear-programming">Linear Programming</a></li>
  <li><a href="/2017/01/21/perceptron/#bai-toan-perceptron">Linearly separable</a></li>
  <li><a href="/2017/03/19/convexopt/#-optimal-and-locally-optimal-points">Locally optimal points</a></li>
  <li><a href="/2017/01/27/logisticregression/">Logistic Regression</a></li>
  <li><a href="/2016/12/28/linearregression/#ham-mat-mat">Loss function (Hàm mất mát)</a> (<a href="/2017/01/01/kmeans/#ham-mat-mat-va-bai-toan-toi-uu">2</a>)</li>
  <li><a href="/2017/06/07/svd/#-best-rank-\\k\\-approximation">Low-rank approximation</a></li>
</ul>

<p><a name="m"></a></p>

<h2 id="m">M</h2>
<ul>
  <li><a href="/2017/05/31/matrixfactorization/">Matrix Factorization</a></li>
  <li><a href="/2017/05/17/contentbasedrecommendersys/#-bai-toan-voi-co-so-du-lieu-movielens-k">MovieLens 100k</a></li>
  <li><a href="/2017/02/24/mlp/">Multi-layer Perceptron</a></li>
</ul>

<p><a name="n"></a></p>

<h2 id="n">N</h2>

<ul>
  <li><a href="/2017/01/21/perceptron/#-mo-hinh-neural-network-dau-tien">Neural Networks</a></li>
  <li><a href="/2017/01/16/gradientdescent2/#-mot-phuong-phap-toi-uu-don-gian-khac-newtons-method">Newton’s Method</a></li>
  <li><a href="https://tiepvupsu.github.io/math/#-norms-chuan">Norms (chuẩn)</a></li>
  <li><a href="/2017/03/12/convexity/#-norm-balls">Norm balls</a></li>
</ul>

<p><a name="o"></a></p>

<h2 id="o">O</h2>

<ul>
  <li><a href="/2017/03/12/convexity/#-gioi-thieu">Objective function</a></li>
  <li><a href="/2017/01/16/gradientdescent2/#online-learning">Online Learning</a></li>
  <li><a href="/2017/06/07/svd/#-he-truc-giao-va-truc-chuan">Orthogonal basis and matrices</a>
<a name="p"></a></li>
</ul>

<h2 id="p">P</h2>

<ul>
  <li><a href="/2017/01/21/perceptron/">Perceptron Learning Algorithm</a></li>
  <li><a href="/2017/01/21/perceptron/#pocket-algorithm">Pocket Algorithm</a></li>
  <li><a href="/2017/03/12/convexity/#positive-semidefinite">Positive Semidefinite Matrices</a></li>
  <li><a href="/2017/06/15/pca/">Principal Component Analysis</a></li>
</ul>

<p><a name="q"></a></p>

<h2 id="q">Q</h2>

<ul>
  <li><a href="/2017/03/12/convexity/#-quadratic-forms">Quadratic form</a></li>
  <li><a href="/2017/03/19/convexopt/#-quadratic-programming">Quadratic programming</a></li>
</ul>

<p><a name="r"></a></p>

<h2 id="r">R</h2>
<ul>
  <li><a href="/2017/05/17/contentbasedrecommendersys/">Recommendation Systems</a></li>
  <li><a href="/2016/12/27/categories/#regression-hoi-quy">Regression</a>
    <ul>
      <li><a href="/2016/12/28/linearregression/">Linear Regression</a></li>
    </ul>
  </li>
  <li><a href="/2016/12/27/categories/#reinforcement-learning-hoc-cung-co">Reinforement Learning (Học Củng Cố)</a></li>
  <li><a href="/2017/02/24/mlp/#-relu">Rectified Linear Unit (ReLU)</a></li>
  <li><a href="/2017/03/04/overfitting/#-regularization">Regularization</a></li>
</ul>

<p><a name="s"></a></p>

<h2 id="s">S</h2>

<ul>
  <li><a href="/2016/12/27/categories/#semi-supervised-learning-hoc-ban-giam-sat">Semi-supervised Learning (Học Bán Giám Sát)</a></li>
  <li><a href="/2017/01/27/logisticregression/#sigmoid-function">Sigmoid function</a></li>
  <li><a href="/2017/05/24/collaborativefiltering/#-similarity-functions">Similarity function</a></li>
  <li><a href="/2017/06/07/svd/#-he-truc-giao-va-truc-chuan">Singular Value Decomposition - SVD</a>
    <ul>
      <li><a href="/2017/06/07/svd/#-compact-svd">Compact SVD</a></li>
      <li><a href="/2017/06/07/svd/#-truncated-svd">Truncated SVD</a></li>
    </ul>
  </li>
  <li><a href="/2017/02/17/softmax/">Softmax Regression</a>
    <ul>
      <li><a href="/2017/02/17/softmax/#-softmax-function">Softmax function</a></li>
    </ul>
  </li>
  <li><a href="/2016/12/27/categories/#supervised-learning-hoc-co-giam-sat">Supervised Learning (Học Có Giám Sát)</a></li>
  <li><a href="/2017/04/09/smv/">Support vector machine</a>
    <ul>
      <li><a href="/2017/04/13/softmarginsmv/#hard-margin">Hard Margin</a></li>
      <li><a href="/2017/04/13/softmarginsmv/#-hinge-loss">Hinge loss</a></li>
      <li><a href="/2017/04/22/kernelsmv/">Kernel SVM</a></li>
      <li><a href="/2017/04/28/multiclasssmv/">Multi-class SVM</a></li>
      <li><a href="/2017/04/13/softmarginsmv/">Soft Margin</a></li>
    </ul>
  </li>
</ul>

<p><a name="t"></a></p>

<h2 id="t">T</h2>

<ul>
  <li><a href="/2016/12/27/categories/#supervised-learning-hoc-co-giam-sat">Training data (dữ liệu huấn luyện) </a></li>
</ul>

<p><a name="u"></a></p>

<h2 id="u">U</h2>
<ul>
  <li><a href="/2017/05/17/contentbasedrecommendersys/#-utility-matrix">Utility Matrix</a></li>
  <li><a href="/2016/12/27/categories/#unsupervised-learning-hoc-khong-giam-sat">Unsupervised Learning (Học Không Giám Sát)</a></li>
</ul>

:ET