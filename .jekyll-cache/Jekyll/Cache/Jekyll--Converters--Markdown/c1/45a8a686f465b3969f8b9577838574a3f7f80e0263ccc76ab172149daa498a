I"π”<p><strong>Trong trang n√†y:</strong></p>

<!-- MarkdownTOC -->

<ul>
  <li>
    <ol>
      <li>Naive Bayes Classifier</li>
    </ol>
  </li>
  <li>
    <ol>
      <li>C√°c ph√¢n ph·ªëi th∆∞·ªùng d√πng cho \(p(x_i | c)\)
        <ul>
          <li>2.1 Gaussian Naive Bayes</li>
          <li>2.2. Multinomial Naive Bayes</li>
          <li>2.3. Bernoulli Naive Bayes</li>
        </ul>
      </li>
    </ol>
  </li>
  <li>
    <ol>
      <li>V√≠ d·ª•
        <ul>
          <li>3.1. B·∫Øc hay Nam</li>
          <li>3.2. B·∫Øc hay Nam v·ªõi sklearn</li>
          <li>3.3. Naive Bayes Classifier cho b√†i to√°n Spam Filtering</li>
        </ul>
      </li>
    </ol>
  </li>
  <li>
    <ol>
      <li>T√≥m t·∫Øt</li>
    </ol>
  </li>
  <li>
    <ol>
      <li>T√†i li·ªáu tham kh·∫£o</li>
    </ol>
  </li>
</ul>

<!-- /MarkdownTOC -->

<p><em>B·∫°n ƒë∆∞·ª£c khuy·∫øn kh√≠ch ƒë·ªçc <a href="/2017/07/17/mlemap/">B√†i 31: Maximum Likelihood v√† Maximum A Posteriori estimation</a> tr∆∞·ªõc khi ƒë·ªçc b√†i n√†y</em>
<a name="-naive-bayes-classifier"></a></p>

<h2 id="1-naive-bayes-classifier">1. Naive Bayes Classifier</h2>

<p>X√©t b√†i to√°n classification v·ªõi \(C\) classes \(1, 2, \dots, C\). Gi·∫£ s·ª≠ c√≥ m·ªôt ƒëi·ªÉm d·ªØ li·ªáu \(\mathbf{x} \in \mathbb{R}^d\). H√£y t√≠nh x√°c su·∫•t ƒë·ªÉ ƒëi·ªÉm d·ªØ li·ªáu n√†y r∆°i v√†o class \(c\). N√≥i c√°ch kh√°c, h√£y t√≠nh:</p>

<p>\[
p(y = c |\mathbf{x}) ~~~ (1)
\]
ho·∫∑c vi·∫øt g·ªçn th√†nh \(p(c|\mathbf{x})\).</p>

<p>T·ª©c t√≠nh x√°c su·∫•t ƒë·ªÉ ƒë·∫ßu ra l√† class \(c\) bi·∫øt r·∫±ng ƒë·∫ßu v√†o l√† vector \(\mathbf{x}\).</p>

<p>Bi·ªÉu th·ª©c n√†y, n·∫øu t√≠nh ƒë∆∞·ª£c, s·∫Ω gi√∫p ch√∫ng ta x√°c ƒë·ªãnh ƒë∆∞·ª£c x√°c su·∫•t ƒë·ªÉ ƒëi·ªÉm d·ªØ li·ªáu r∆°i v√†o m·ªói class. T·ª´ ƒë√≥ c√≥ th·ªÉ gi√∫p x√°c ƒë·ªãnh class c·ªßa ƒëi·ªÉm d·ªØ li·ªáu ƒë√≥ b·∫±ng c√°ch ch·ªçn ra class c√≥ x√°c su·∫•t cao nh·∫•t:</p>

<p>\[
c = \arg\max_{c \in \{1, \dots, C\}} p(c | \mathbf{x}) ~~~~ (2)
\]</p>

<p>Bi·ªÉu th·ª©c \((2)\) th∆∞·ªùng kh√≥ ƒë∆∞·ª£c t√≠nh tr·ª±c ti·∫øp. Thay v√†o ƒë√≥, quy t·∫Øc Bayes th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng:</p>

<p>\[
\begin{eqnarray}
  c &amp; = &amp; \arg\max_c p(c | \mathbf{x}) &amp; (3) \<br />
      &amp; = &amp; \arg\max_c \frac{p(\mathbf{x} | c) p(c)}{p(\mathbf{x})} ~~~&amp; 4)\<br />
      &amp; = &amp; \arg\max_c p(\mathbf{x} | c) p(c) &amp; (5)\<br />
\end{eqnarray}
\]</p>

<p>T·ª´ \((3)\) sang \((4)\) l√† v√¨ quy t·∫Øc Bayes. T·ª´ \((4)\) sang \((5)\) l√† v√¨ m·∫´u s·ªë \(p(\mathbf{x})\) kh√¥ng ph·ª• thu·ªôc v√†o \(c\).</p>

<p>Ti·∫øp t·ª•c x√©t bi·ªÉu th·ª©c \((5)\), \(p(c)\) c√≥ th·ªÉ ƒë∆∞·ª£c hi·ªÉu l√† x√°c su·∫•t ƒë·ªÉ m·ªôt ƒëi·ªÉm r∆°i v√†o class \(c\). Gi√° tr·ªã n√†y c√≥ th·ªÉ ƒë∆∞·ª£c t√≠nh b·∫±ng <a href="/2017/07/17/mlemap/#-maximum-likelihood-estimation">MLE</a>, t·ª©c t·ªâ l·ªá s·ªë ƒëi·ªÉm d·ªØ li·ªáu trong t·∫≠p training r∆°i v√†o class n√†y chia cho t·ªïng s·ªë l∆∞·ª£ng d·ªØ li·ªáu trong t·∫≠p training; ho·∫∑c c≈©ng c√≥ th·ªÉ ƒë∆∞·ª£c ƒë√°nh gi√° b·∫±ng <a href="/2017/07/17/mlemap/#-maximum-a-posteriori">MAP estimation</a>. Tr∆∞·ªùng h·ª£p th·ª© nh·∫•t th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng nhi·ªÅu h∆°n.</p>

<p>Th√†nh ph·∫ßn c√≤n l·∫°i \(p(\mathbf{x} | c)\), t·ª©c ph√¢n ph·ªëi c·ªßa c√°c ƒëi·ªÉm d·ªØ li·ªáu trong class \(c\), th∆∞·ªùng r·∫•t kh√≥ t√≠nh to√°n v√¨ \(\mathbf{x}\) l√† m·ªôt bi·∫øn ng·∫´u nhi√™n nhi·ªÅu chi·ªÅu, c·∫ßn r·∫•t r·∫•t nhi·ªÅu d·ªØ li·ªáu training ƒë·ªÉ c√≥ th·ªÉ x√¢y d·ª±ng ƒë∆∞·ª£c ph√¢n ph·ªëi ƒë√≥. ƒê·ªÉ gi√∫p cho vi·ªác t√≠nh to√°n ƒë∆∞·ª£c ƒë∆°n gi·∫£n, ng∆∞·ªùi ta th∆∞·ªùng gi·∫£ s·ª≠ m·ªôt c√°ch ƒë∆°n gi·∫£n nh·∫•t r·∫±ng c√°c th√†nh ph·∫ßn c·ªßa bi·∫øn ng·∫´u nhi√™n \(\mathbf{x}\) l√† <a href="/2017/07/09/prob/#-independence">ƒë·ªôc l·∫≠p v·ªõi nhau</a>, n·∫øu bi·∫øt \(c\) (given \(c\)). T·ª©c l√†:</p>

<p>\[
p(\mathbf{x} | c) = p(x_1, x_2, \dots, x_d | c) =  \prod_{i = 1}^d p(x_i | c) ~~~~~ (6)
\]</p>

<p>Gi·∫£ thi·∫øt c√°c chi·ªÅu c·ªßa d·ªØ li·ªáu ƒë·ªôc l·∫≠p v·ªõi nhau, n·∫øu bi·∫øt \(c\), l√† qu√° ch·∫∑t v√† √≠t khi t√¨m ƒë∆∞·ª£c d·ªØ li·ªáu m√† c√°c th√†nh ph·∫ßn ho√†n to√†n ƒë·ªôc l·∫≠p v·ªõi nhau. Tuy nhi√™n, gi·∫£ thi·∫øt <em>ng√¢y ng√¥</em> n√†y l·∫°i mang l·∫°i nh·ªØng k·∫øt qu·∫£ t·ªët b·∫•t ng·ªù. Gi·∫£ thi·∫øt v·ªÅ s·ª± ƒë·ªôc l·∫≠p c·ªßa c√°c chi·ªÅu d·ªØ li·ªáu n√†y ƒë∆∞·ª£c g·ªçi l√† <em>Naive Bayes</em> (xin kh√¥ng d·ªãch). C√°ch x√°c ƒë·ªãnh class c·ªßa d·ªØ li·ªáu d·ª±a tr√™n gi·∫£ thi·∫øt n√†y c√≥ t√™n l√† <em>Naive Bayes Classifier (NBC)</em>.</p>

<p>NBC, nh·ªù v√†o t√≠nh ƒë∆°n gi·∫£n m·ªôt c√°ch <em>ng√¢y th∆°</em>, c√≥ t·ªëc ƒë·ªô training v√† test r·∫•t nhanh. Vi·ªác n√†y gi√∫p n√≥ mang l·∫°i hi·ªáu qu·∫£ cao trong c√°c b√†i to√°n large-scale.</p>

<p>·ªû b∆∞·ªõc <strong>training</strong>, c√°c ph√¢n ph·ªëi \(p(c)\) v√† \(p(x_i | c), i = 1, \dots, d\) s·∫Ω ƒë∆∞·ª£c x√°c ƒë·ªãnh d·ª±a v√†o training data. Vi·ªác x√°c ƒë·ªãnh c√°c gi√° tr·ªã n√†y c√≥ th·ªÉ d·ª±a v√†o <a href="/2017/07/17/mlemap/">Maximum Likelihood Estimation ho·∫∑c Maximum A Posteriori</a>.</p>

<p>·ªû b∆∞·ªõc <strong>test</strong>, v·ªõi m·ªôt ƒëi·ªÉm d·ªØ li·ªáu m·ªõi \(\mathbf{x}\), class c·ªßa n√≥ s·∫Ω ƒë∆∞·ª£c x√°c ƒëinh b·ªüi:</p>

<p>\[
c = \arg\max_{c \in \{1, \dots, C\}} p(c) \prod_{i=1}^d p(x_i | c) ~~~~~ (7)
\]</p>

<p>Khi \(d\) l·ªõn v√† c√°c x√°c su·∫•t nh·ªè, bi·ªÉu th·ª©c ·ªü v·∫ø ph·∫£i c·ªßa \((7)\) s·∫Ω l√† m·ªôt s·ªë r·∫•t nh·ªè, khi t√≠nh to√°n c√≥ th·ªÉ g·∫∑p sai s·ªë. ƒê·ªÉ gi·∫£i quy·∫øt vi·ªác n√†y, \((7)\) th∆∞·ªùng ƒë∆∞·ª£c vi·∫øt l·∫°i d∆∞·ªõi d·∫°ng t∆∞∆°ng ƒë∆∞∆°ng b·∫±ng c√°ch l·∫•y \(\log\) c·ªßa v·∫ø ph·∫£i: 
\[
c = \arg\max_{c \in \{1, \dots, C\}} = \log(p(c)) + \sum_{i=1}^d \log(p(x_i | c)) ~~~~ (7.1)
\]</p>

<p>Vi·ªác n√†y kh√¥ng ·∫£nh h∆∞·ªüng t·ªõi k·∫øt qu·∫£ v√¨ \(\log\) l√† m·ªôt h√†m ƒë·ªìng bi·∫øn tr√™n t·∫≠p c√°c s·ªë d∆∞∆°ng.</p>

<!-- L√Ω thuy·∫øt v·ªÅ Naive Bayes Classifier c√≥ th·ªÉ d·ª´ng l·∫°i ·ªü ƒë√¢y (_th·∫≠t l√† naive_). Ch√∫ng ta s·∫Ω hi·ªÉu r√µ h∆°n ph∆∞∆°ng ph√°p n√†y th√¥ng qua c√°c v√≠ d·ª•.  -->
<p>M·∫∑c d√π gi·∫£ thi·∫øt m√† Naive Bayes Classifiers s·ª≠ d·ª•ng l√† qu√° phi th·ª±c t·∫ø, ch√∫ng v·∫´n ho·∫°t ƒë·ªông kh√° hi·ªáu qu·∫£ trong nhi·ªÅu b√†i to√°n th·ª±c t·∫ø, ƒë·∫∑c bi·ªát l√† trong c√°c b√†i to√°n ph√¢n lo·∫°i vƒÉn b·∫£n, v√≠ d·ª• nh∆∞ l·ªçc tin nh·∫Øn r√°c hay l·ªçc email spam. Trong ph·∫ßn sau c·ªßa b√†i vi·∫øt, ch√∫ng ta c√πng x√¢y d·ª±ng m·ªôt b·ªô l·ªçc email spam ti·∫øng Anh ƒë∆°n gi·∫£n.</p>

<p>C·∫£ vi·ªác training v√† test c·ªßa NBC l√† c·ª±c k·ª≥ nhanh khi so v·ªõi c√°c ph∆∞∆°ng ph√°p classification ph·ª©c t·∫°p kh√°c. Vi·ªác gi·∫£ s·ª≠ c√°c th√†nh ph·∫ßn trong d·ªØ li·ªáu l√† ƒë·ªôc l·∫≠p v·ªõi nhau, n·∫øu bi·∫øt class, khi·∫øn cho vi·ªác t√≠nh to√°n m·ªói ph√¢n ph·ªëi \(p(\mathbf{x}_i|c)\) tr·ªü n√™n c·ª±c k·ª≥ nhanh.</p>

<p>M·ªói gi√° tr·ªã \(p(c), c = 1, 2, \dots, C\) c√≥ th·ªÉ ƒë∆∞·ª£c x√°c ƒë·ªãnh nh∆∞ l√† t·∫ßn su·∫•t xu·∫•t hi·ªán c·ªßa class \(c\) trong training data.</p>

<p>Vi·ªác t√≠nh to√°n \(p(\mathbf{x_i} | c) \) ph·ª• thu·ªôc v√†o lo·∫°i d·ªØ li·ªáu. <a href="http://scikit-learn.org/dev/modules/classes.html#module-sklearn.naive_bayes">C√≥ ba lo·∫°i ƒë∆∞·ª£c s·ª≠ d·ª•ng ph·ªï bi·∫øn</a> l√†: Gaussian Naive Bayes, Multinomial Naive Bayes, v√† Bernoulli Naive .</p>

<p><a name="-cac-phan-phoi-thuong-dung-cho-\\pxi-\|-c\\"></a></p>

<h2 id="2-c√°c-ph√¢n-ph·ªëi-th∆∞·ªùng-d√πng-cho-px_i--c">2. C√°c ph√¢n ph·ªëi th∆∞·ªùng d√πng cho \(p(x_i | c)\)</h2>

<p><em>M·ª•c n√†y ch·ªß y·∫øu ƒë∆∞·ª£c d·ªãch t·ª´ <a href="http://scikit-learn.org/dev/modules/naive_bayes.html#naive-bayes">t√†i li·ªáu c·ªßa th∆∞ vi·ªán sklearn</a>.</em>
<a name="-gaussian-naive-bayes"></a></p>

<h3 id="21-gaussian-naive-bayes">2.1 Gaussian Naive Bayes</h3>

<p>M√¥ h√¨nh n√†y ƒë∆∞·ª£c s·ª≠ d·ª•ng ch·ªß y·∫øu trong lo·∫°i d·ªØ li·ªáu m√† c√°c th√†nh ph·∫ßn l√† c√°c bi·∫øn li√™n t·ª•c.</p>

<p>V·ªõi m·ªói chi·ªÅu d·ªØ li·ªáu \(i\) v√† m·ªôt class \(c\), \(x_i\) tu√¢n theo m·ªôt ph√¢n ph·ªëi chu·∫©n c√≥ k·ª≥ v·ªçng \(\mu_{ci}\) v√† ph∆∞∆°ng sai \(\sigma_{ci}^2\):</p>

<p>\[
p(x_i|c) = p(x_i | \mu_{ci}, \sigma_{ci}^2) =  \frac{1}{\sqrt{2\pi \sigma_{ci}^2}} \exp\left(- \frac{(x_i - \mu_{ci})^2}{2 \sigma_{ci}^2}\right) ~~~~ (8)
\]</p>

<p>Trong ƒë√≥, b·ªô tham s·ªë \(\theta = \{\mu_{ci}, \sigma_{ci}^2\}\) ƒë∆∞·ª£c x√°c ƒë·ªãnh b·∫±ng Maximum Likelihood:</p>

<p>\[
(\mu_{ci}, \sigma_{ci}^2) = \arg\max_{\mu_{ci}, \sigma_{ci}^2} \prod_{n = 1}^N p(x_i^{(n)} | \mu_{ci}, \sigma_{ci}^2) ~~~~ (9)
\]</p>

<p><em>ƒê√¢y l√† c√°ch t√≠nh c·ªßa th∆∞ vi·ªán sklearn. Ch√∫ng ta c≈©ng c√≥ th·ªÉ ƒë√°nh gi√° c√°c tham s·ªë b·∫±ng MAP n·∫øu bi·∫øt tr∆∞·ªõc priors c·ªßa \(\mu_{ci}\) v√† \(\sigma^2_{ci}\)</em></p>

<p><a name="-multinomial-naive-bayes"></a></p>

<h3 id="22-multinomial-naive-bayes">2.2. Multinomial Naive Bayes</h3>
<p>M√¥ h√¨nh n√†y ch·ªß y·∫øu ƒë∆∞·ª£c s·ª≠ d·ª•ng trong ph√¢n lo·∫°i vƒÉn b·∫£n m√† feature vectors ƒë∆∞·ª£c t√≠nh b·∫±ng <a href="https://machinelearningcoban.com/general/2017/02/06/featureengineering/#bag-of-words">Bags of Words</a>. L√∫c n√†y, m·ªói vƒÉn b·∫£n ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·ªüi m·ªôt vector c√≥ ƒë·ªô d√†i \(d\) ch√≠nh l√† s·ªë t·ª´ trong t·ª´ ƒëi·ªÉn. Gi√° tr·ªã c·ªßa th√†nh ph·∫ßn th·ª© \(i\) trong m·ªói vector ch√≠nh l√† s·ªë l·∫ßn t·ª´ th·ª© \(i\) xu·∫•t hi·ªán trong vƒÉn b·∫£n ƒë√≥.</p>

<p>Khi ƒë√≥, \(p(x_i |c) \) t·ªâ l·ªá v·ªõi t·∫ßn su·∫•t t·ª´ th·ª© \(i\) (hay feature th·ª© \(i\) cho tr∆∞·ªùng h·ª£p t·ªïng qu√°t) xu·∫•t hi·ªán trong c√°c vƒÉn b·∫£n c·ªßa class \(c\). Gi√° tr·ªã n√†y c√≥ th·ªÉ ƒë∆∞·ª£c t√≠nh b·∫±ng c√°ch: 
\[
\lambda_{ci} = p(x_i | c) = \frac{N_{ci}}{N_c} ~~~~ (10)
\]
Trong ƒë√≥:</p>

<ul>
  <li>
    <p>\(N_{ci}\) l√† t·ªïng s·ªë l·∫ßn t·ª´ th·ª© \(i\) xu·∫•t hi·ªán trong c√°c vƒÉn b·∫£n c·ªßa class \(c\), n√≥ ƒë∆∞·ª£c t√≠nh l√† t·ªïng c·ªßa t·∫•t c·∫£ c√°c th√†nh ph·∫ßn th·ª© \(i\) c·ªßa c√°c feature vectors ·ª©ng v·ªõi class \(c\).</p>
  </li>
  <li>
    <p>\(N_c\) l√† t·ªïng s·ªë t·ª´ (k·ªÉ c·∫£ l·∫∑p) xu·∫•t hi·ªán trong class \(c\). N√≥i c√°ch kh√°c, n√≥ b·∫±ng t·ªïng ƒë·ªô d√†i c·ªßa to√†n b·ªô c√°c vƒÉn b·∫£n thu·ªôc v√†o class \(c\). C√≥ th·ªÉ suy ra r·∫±ng \(N_c = \sum_{i = 1}^d N_{ci}\), t·ª´ ƒë√≥ \(\sum_{i=1}^d \lambda_{ci} = 1\).</p>
  </li>
</ul>

<p>C√°ch t√≠nh n√†y c√≥ m·ªôt h·∫°n ch·∫ø l√† n·∫øu c√≥ m·ªôt t·ª´ m·ªõi ch∆∞a bao gi·ªù xu·∫•t hi·ªán trong class \(c\) th√¨ bi·ªÉu th·ª©c \((10)\) s·∫Ω b·∫±ng 0, ƒëi·ªÅu n√†y d·∫´n ƒë·∫øn v·∫ø ph·∫£i c·ªßa \((7)\) b·∫±ng 0 b·∫•t k·ªÉ c√°c gi√° tr·ªã c√≤n l·∫°i c√≥ l·ªõn th·∫ø n√†o. Vi·ªác n√†y s·∫Ω d·∫´n ƒë·∫øn k·∫øt qu·∫£ kh√¥ng ch√≠nh x√°c (xem th√™m v√≠ d·ª• ·ªü m·ª•c sau).</p>

<p>ƒê·ªÉ gi·∫£i quy·∫øt vi·ªác n√†y, m·ªôt k·ªπ thu·∫≠t ƒë∆∞·ª£c g·ªçi l√† <em>Laplace smoothing</em> ƒë∆∞·ª£c √°p d·ª•ng:</p>

<p>\[
\hat{\lambda}_{ci} = \frac{N_{ci} + \alpha}{N_{c} + d\alpha} ~~~~~~ (11)
\]</p>

<p>V·ªõi \(\alpha\) l√† m·ªôt s·ªë d∆∞∆°ng, th∆∞·ªùng b·∫±ng 1, ƒë·ªÉ tr√°nh tr∆∞·ªùng h·ª£p t·ª≠ s·ªë b·∫±ng 0. M·∫´u s·ªë ƒë∆∞·ª£c c·ªông v·ªõi \(d\alpha\) ƒë·ªÉ ƒë·∫£m b·∫£o t·ªïng x√°c su·∫•t \(\sum_{i=1}^d \hat{\lambda}_{ci} = 1\).</p>

<p>Nh∆∞ v·∫≠y, m·ªói class \(c\) s·∫Ω ƒë∆∞·ª£c m√¥ t·∫£ b·ªüi b·ªô c√°c s·ªë d∆∞∆°ng c√≥ t·ªïng b·∫±ng 1: \(\hat{\lambda}_c = \{\hat{\lambda}_{c1}, \dots, \hat{\lambda}_{cd}\}\).</p>

<p><a name="-bernoulli-naive-bayes"></a></p>

<h3 id="23-bernoulli-naive-bayes">2.3. Bernoulli Naive Bayes</h3>

<p>M√¥ h√¨nh n√†y ƒë∆∞·ª£c √°p d·ª•ng cho c√°c lo·∫°i d·ªØ li·ªáu m√† m·ªói th√†nh ph·∫ßn l√† m·ªôt gi√° tr·ªã binary - b·∫≥ng 0 ho·∫∑c 1. V√≠ d·ª•: c≈©ng v·ªõi lo·∫°i vƒÉn b·∫£n nh∆∞ng thay v√¨ ƒë·∫øm t·ªïng s·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa 1 t·ª´ trong vƒÉn b·∫£n, ta ch·ªâ c·∫ßn quan t√¢m t·ª´ ƒë√≥ c√≥ xu·∫•t hi·ªán hay kh√¥ng.</p>

<p>Khi ƒë√≥, \(p(x_i | c) \) ƒë∆∞·ª£c t√≠nh b·∫±ng: 
\[
p(x_i | c) = p(i | c)^{x_i} (1 - p(i | c) ^{1 - x_i}
\]
v·ªõi \(p(i | c)\) c√≥ th·ªÉ ƒë∆∞·ª£c hi·ªÉu l√† x√°c su·∫•t t·ª´ th·ª© \(i\) xu·∫•t hi·ªán trong c√°c vƒÉn b·∫£n c·ªßa class \(c\).</p>

<p><a name="-vi-du"></a></p>

<h2 id="3-v√≠-d·ª•">3. V√≠ d·ª•</h2>

<p><a name="-bac-hay-nam"></a></p>

<h3 id="31-b·∫Øc-hay-nam">3.1. B·∫Øc hay Nam</h3>
<p>Gi·∫£ s·ª≠ trong t·∫≠p training c√≥ c√°c vƒÉn b·∫£n \(\text{d1, d2, d3, d4}\) nh∆∞ trong b·∫£ng d∆∞·ªõi ƒë√¢y. M·ªói vƒÉn b·∫£n n√†y thu·ªôc v√†o 1 trong 2 classes: \(\text{B}\) (<em>B·∫Øc</em>) ho·∫∑c \(\text{N}\) (<em>Nam</em>). H√£y x√°c ƒë·ªãnh class c·ªßa vƒÉn b·∫£n \(\text{d5}\).</p>

<table>
  <thead>
    <tr>
      <th>¬†</th>
      <th style="text-align: center">Document</th>
      <th>Content</th>
      <th style="text-align: center">Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Training</strong></td>
      <td style="text-align: center">\(\text{d1}\)</td>
      <td>\(\text{hanoi pho chaolong hanoi}\)</td>
      <td style="text-align: center">\(\text{B}\)</td>
    </tr>
    <tr>
      <td>¬†</td>
      <td style="text-align: center">\(\text{d2}\)</td>
      <td>\(\text{hanoi buncha pho omai}\)</td>
      <td style="text-align: center">\(\text{B}\)</td>
    </tr>
    <tr>
      <td>¬†</td>
      <td style="text-align: center">\(\text{d3}\)</td>
      <td>\(\text{pho banhgio omai}\)</td>
      <td style="text-align: center">\(\text{B}\)</td>
    </tr>
    <tr>
      <td>¬†</td>
      <td style="text-align: center">\(\text{d4}\)</td>
      <td>\(\text{saigon hutiu banhbo pho}\)</td>
      <td style="text-align: center">\(\text{N}\)</td>
    </tr>
    <tr>
      <td><strong>Test</strong></td>
      <td style="text-align: center">\(\text{d5}\)</td>
      <td>\(\text{hanoi hanoi buncha hutiu}\)</td>
      <td style="text-align: center">?</td>
    </tr>
  </tbody>
</table>

<p><br />
Ta c√≥ th·ªÉ d·ª± ƒëo√°n r·∫±ng \(\text{d5}\) thu·ªôc class <em>B·∫Øc</em>.</p>

<p>B√†i to√°n n√†y c√≥ th·ªÉ ƒë∆∞·ª£c gi·∫£i quy·∫øt b·ªüi hai m√¥ h√¨nh: Multinomial Naive Bayes v√† Bernoulli Naive Bayes. T√¥i s·∫Ω l√†m v√≠ d·ª• minh ho·∫° v·ªõi m√¥ h√¨nh th·ª© nh·∫•t v√† th·ª±c hi·ªán code cho c·∫£ hai m√¥ h√¨nh. Vi·ªác m√¥ h√¨nh n√†o t·ªët h∆°n ph·ª• thu·ªôc v√†o m·ªói b√†i to√°n. Ch√∫ng ta c√≥ th·ªÉ th·ª≠ c·∫£ hai ƒë·ªÉ ch·ªçn ra m√¥ h√¨nh t·ªët h∆°n.</p>

<p>Nh·∫≠n th·∫•y r·∫±ng ·ªü ƒë√¢y c√≥ 2 class \(\text{B}\) v√† \(\text{N}\), ta c·∫ßn ƒëi t√¨m \(p(\text{B})\) v√† \(p(\text{N})\). √† d·ª±a tr√™n t·∫ßn s·ªë xu·∫•t hi·ªán c·ªßa m·ªói class trong t·∫≠p training. Ta s·∫Ω c√≥:</p>

<p>\[
p(\text{B}) = \frac{3}{4}, ~~~~~ p(\text{N}) = \frac{1}{4} ~~~~~~ (8)
\]</p>

<p>T·∫≠p h·ª£p to√†n b·ªô c√°c t·ª´ trong vƒÉn b·∫£n, hay c√≤n g·ªçi l√† t·ª´ ƒëi·ªÉn, l√†: \(V = \{\text{hanoi, pho, chaolong, buncha, omai, banhgio, saigon, hutiu, banhbo}\}\). T·ªïng c·ªông s·ªë ph·∫ßn t·ª≠ trong t·ª´ ƒëi·ªÉn l√† \(|V| = 9\).</p>

<p>H√¨nh d∆∞·ªõi ƒë√¢y minh ho·∫° qu√° tr√¨nh Training v√† Test cho b√†i to√°n n√†y khi s·ª≠ d·ª•ng Multinomial Naive Bayes, trong ƒë√≥ c√≥ s·ª≠ d·ª•ng Laplace smoothing v·ªõi \(\alpha = 1\).</p>

<hr />

<div class="imgcap">
<img src="/assets/32_nbc/nbc.png" align="center" width="100%" />
</div>

<div class="thecap" style="text-align: center">H√¨nh 1: Minh ho·∫° Multinomial Naive Bayes.</div>
<hr />

<p>Ch√∫ √Ω, hai gi√° tr·ªã t√¨m ƒë∆∞·ª£c \(1.5\times 10^{-4}\) v√† \(1.75\times 10^{-5}\) kh√¥ng ph·∫£i l√† hai x√°c su·∫•t c·∫ßn t√¨m m√† ch·ªâ l√† hai ƒë·∫°i l∆∞·ª£ng <strong>t·ªâ l·ªá thu·∫≠n</strong> v·ªõi hai x√°c su·∫•t ƒë√≥. ƒê·ªÉ t√≠nh c·ª• th·ªÉ, ta c√≥ th·ªÉ l√†m nh∆∞ sau:</p>

<p>\[
p(\text{B} | \text{d5}) = \frac{1.5\times 10^{-4}}{1.5\times 10^{-4} + 1.75\times 10^{-5}} \approx 0.8955, ~~~~ p(\text{N} | \text{d5}) = 1 - p(\text{B} | \text{d5}) \approx 0.1045
\]</p>

<p>B·∫°n ƒë·ªçc c√≥ th·ªÉ t·ª± t√≠nh v·ªõi v√≠ d·ª• kh√°c: \(\text{d6 = pho hutiu banhbo}\). N·∫øu b·∫°n v√† t√¥i t√≠nh ra k·∫øt qu·∫£ gi·ªëng nhau, ch√∫ng ta s·∫Ω thu ƒë∆∞·ª£c:
\[
p(\text{B} | \text{d6}) \approx 0.29, ~~~~ p(\text{N} | \text{d6}) \approx 0.71
\]</p>

<p>v√† suy ra \(\text{d6}\) thu·ªôc v√†o class <em>Nam</em>.
<a name="-bac-hay-nam-voi-sklearn"></a></p>

<h3 id="32-b·∫Øc-hay-nam-v·ªõi-sklearn">3.2. B·∫Øc hay Nam v·ªõi sklearn</h3>

<p>ƒê·ªÉ ki·ªÉm tra l·∫°i c√°c ph√©p t√≠nh to√°n ph√≠a tr√™n, ch√∫ng ta c√πng gi·∫£i quy·∫øt b√†i to√°n n√†y v·ªõi <a href="http://scikit-learn.org/dev/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB">sklearn</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">MultinomialNB</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span> 

<span class="c1"># train data
</span><span class="n">d1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">d2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">d3</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">d4</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">d1</span><span class="p">,</span> <span class="n">d2</span><span class="p">,</span> <span class="n">d3</span><span class="p">,</span> <span class="n">d4</span><span class="p">])</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="s">'B'</span><span class="p">,</span> <span class="s">'B'</span><span class="p">,</span> <span class="s">'B'</span><span class="p">,</span> <span class="s">'N'</span><span class="p">])</span> 

<span class="c1"># test data
</span><span class="n">d5</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">d6</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>

<span class="c1">## call MultinomialNB
</span><span class="n">clf</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">()</span>
<span class="c1"># training 
</span><span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>

<span class="c1"># test
</span><span class="k">print</span><span class="p">(</span><span class="s">'Predicting class of d5:'</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">d5</span><span class="p">)[</span><span class="mi">0</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Probability of d6 in each class:'</span><span class="p">,</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">d6</span><span class="p">))</span>
</code></pre></div></div>

<p>K·∫øt qu·∫£:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Predicting class of d5: B
Probability of d6 in each class: [[ 0.29175335  0.70824665]]
</code></pre></div></div>

<p>N·∫øu s·ª≠ d·ª•ng m√¥ h√¨nh Bernoulli Naive Bayes, ch√∫ng ta c·∫ßn thay ƒë·ªïi m·ªôt ch√∫t v·ªÅ feature vectors. L√∫c n√†y, c√°c gi√° tr·ªã kh√°c kh√¥ng s·∫Ω ƒë·ªÅu ƒë∆∞·ª£c ƒë∆∞a v·ªÅ 1 v√¨ ta ch·ªâ quan t√¢m ƒë·∫øn vi·ªác t·ª´ ƒë√≥ c√≥ xu·∫•t hi·ªán trong vƒÉn b·∫£n kh√¥ng.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">BernoulliNB</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span> 

<span class="c1"># train data
</span><span class="n">d1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">d2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">d3</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">d4</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">d1</span><span class="p">,</span> <span class="n">d2</span><span class="p">,</span> <span class="n">d3</span><span class="p">,</span> <span class="n">d4</span><span class="p">])</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="s">'B'</span><span class="p">,</span> <span class="s">'B'</span><span class="p">,</span> <span class="s">'B'</span><span class="p">,</span> <span class="s">'N'</span><span class="p">])</span> <span class="c1"># 0 - B, 1 - N 
</span>
<span class="c1"># test data
</span><span class="n">d5</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">d6</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>

<span class="c1">## call MultinomialNB
</span><span class="n">clf</span> <span class="o">=</span> <span class="n">BernoulliNB</span><span class="p">()</span>
<span class="c1"># training 
</span><span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>

<span class="c1"># test
</span><span class="k">print</span><span class="p">(</span><span class="s">'Predicting class of d5:'</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">d5</span><span class="p">)[</span><span class="mi">0</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Probability of d6 in each class:'</span><span class="p">,</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">d6</span><span class="p">))</span>
</code></pre></div></div>

<p>K·∫øt qu·∫£:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Predicting class of d5: B
Probability of d6 in each class: [[ 0.16948581  0.83051419]]
</code></pre></div></div>

<p>Ta th·∫•y r·∫±ng, v·ªõi b√†i to√°n nh·ªè n√†y, c·∫£ hai m√¥ h√¨nh ƒë·ªÅu cho k·∫øt qu·∫£ gi·ªëng nhau (x√°c su·∫•t t√¨m ƒë∆∞·ª£c kh√°c nhau nh∆∞ng kh√¥ng ·∫£nh h∆∞·ªüng t·ªõi quy·∫øt ƒë·ªãnh cu·ªëi c√πng).</p>

<p><a name="-naive-bayes-classifier-cho-bai-toan-spam-filtering"></a></p>

<h3 id="33-naive-bayes-classifier-cho-b√†i-to√°n-spam-filtering">3.3. Naive Bayes Classifier cho b√†i to√°n Spam Filtering</h3>

<p>D·ªØ li·ªáu trong v√≠ d·ª• n√†y ƒë∆∞·ª£c l·∫•y trong <a href="http://openclassroom.stanford.edu/MainFolder/DocumentPage.php?course=MachineLearning&amp;doc=exercises/ex6/ex6.html">Exercise 6: Naive Bayes - Machine Learning - Andrew Ng</a>.</p>

<p>Trong v√≠ d·ª• n√†y, d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω, v√† l√† m·ªôt t·∫≠p con c·ªßa c∆° s·ªü d·ªØ li·ªáu <a href="http://csmining.org/index.php/ling-spam-datasets.html">Ling-Spam Dataset</a>.</p>

<p><strong>M√¥ t·∫£ d·ªØ li·ªáu:</strong></p>

<p>T·∫≠p d·ªØ li·ªáu n√†y bao g·ªìm t·ªïng c·ªông 960 emails ti·∫øng Anh, ƒë∆∞·ª£c t√°ch th√†nh t·∫≠p training v√† test theo t·ªâ l·ªá 700:260, 50% trong m·ªói t·∫≠p l√† c√°c spam emails.</p>

<p>D·ªØ li·ªáu trong c∆° s·ªü d·ªØ li·ªáu n√†y ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω kh√° ƒë·∫πp. C√°c quy t·∫Øc x·ª≠ l√Ω nh∆∞ sau:</p>

<ol>
  <li>
    <p><strong>Lo·∫°i b·ªè <em>stop words</em></strong>: Nh·ªØng t·ª´ xu·∫•t hi·ªán th∆∞·ªùng xuy√™n nh∆∞ ‚Äòand‚Äô, ‚Äòthe‚Äô, ‚Äòof‚Äô, ‚Ä¶ ƒë∆∞·ª£c lo·∫°i b·ªè.</p>
  </li>
  <li>
    <p><strong>Lemmatization</strong>: Nh·ªØng t·ª´ c√≥ c√πng ‚Äòg·ªëc‚Äô ƒë∆∞·ª£c ƒë∆∞a v·ªÅ c√πng lo·∫°i. V√≠ d·ª•, ‚Äòinclude‚Äô, ‚Äòincludes‚Äô, ‚Äòincluded‚Äô ƒë·ªÅu ƒë∆∞·ª£c ƒë∆∞a chung v·ªÅ ‚Äòinclude‚Äô. T·∫•t c·∫£ c√°c t·ª´ c≈©ng ƒë√£ ƒë∆∞·ª£c ƒë∆∞a v·ªÅ d·∫°ng k√Ω t·ª± th∆∞·ªùng (kh√¥ng ph·∫£i HOA).</p>
  </li>
  <li>
    <p><strong>Lo·∫°i b·ªè <em>non-words</em></strong>: S·ªë, d·∫•u c√¢u, k√Ω t·ª± ‚Äòtabs‚Äô, k√Ω t·ª± ‚Äòxu·ªëng d√≤ng‚Äô ƒë√£ ƒë∆∞·ª£c lo·∫°i b·ªè.</p>
  </li>
</ol>

<p>D∆∞·ªõi ƒë√¢y l√† m·ªôt v√≠ d·ª• c·ªßa 1 email kh√¥ng ph·∫£i spam, <strong>tr∆∞·ªõc khi ƒë∆∞·ª£c x·ª≠ l√Ω</strong>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Subject: Re: 5.1344 Native speaker intuitions
  
The discussion on native speaker intuitions has been extremely interesting, 
but I worry that my brief intervention may have muddied the waters. I take 
it that there are a number of separable issues. The first is the extent to
which a native speaker is likely to judge a lexical string as grammatical 
or ungrammatical per se. The second is concerned with the relationships 
between syntax and interpretation (although even here the distinction may 
not be entirely clear cut). 
</code></pre></div></div>

<p>v√† <strong>sau khi ƒë∆∞·ª£c x·ª≠ l√Ω</strong>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>re native speaker intuition discussion native speaker intuition extremely 
interest worry brief intervention muddy waters number separable issue first 
extent native speaker likely judge lexical string grammatical ungrammatical 
per se second concern relationship between syntax interpretation although 
even here distinction entirely clear cut 
</code></pre></div></div>

<p>V√† ƒë√¢y l√† m·ªôt v√≠ d·ª• v·ªÅ <strong>spam email sau khi ƒë∆∞·ª£c x·ª≠ l√Ω</strong>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>financial freedom follow financial freedom work ethic extraordinary desire 
earn least per month work home special skills experience required train 
personal support need ensure success legitimate homebased income 
opportunity put back control finance life ve try opportunity past 
fail live promise 
</code></pre></div></div>

<p>Ch√∫ng ta th·∫•y r·∫±ng trong ƒëo·∫°n n√†y c√≥ c√°c t·ª´ nh∆∞: <em>financial, extraordinary, earn, opportunity, ‚Ä¶</em> l√† nh·ªØng t·ª´ th∆∞·ªùng th·∫•y trong c√°c email spam.</p>

<p>Trong v√≠ d·ª• n√†y, ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng Multinomial Naive Bayes.</p>

<p>ƒê·ªÉ cho b√†i to√°n ƒë∆∞·ª£c ƒë∆°n gi·∫£n h∆°n, t√¥i ti·∫øp t·ª•c s·ª≠ d·ª•ng d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω, c√≥ th·ªÉ ƒë∆∞·ª£c download ·ªü ƒë√¢y: <a href="http://openclassroom.stanford.edu/MainFolder/courses/MachineLearning/exercises/ex6materials/ex6DataPrepared.zip">ex6DataPrepared.zip</a>. Trong folder sau khi gi·∫£i n√©n, ch√∫ng ta s·∫Ω th·∫•y c√°c files:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>test-features.txt
test-labels.txt
train-features-50.txt
train-features-100.txt
train-features-400.txt
train-features.txt
train-labels-50.txt
train-labels-100.txt
train-labels-400.txt
train-labels.txt
</code></pre></div></div>

<p>t∆∞∆°ng ·ª©ng v·ªõi c√°c file ch·ª©a d·ªØ li·ªáu c·ªßa t·∫≠p training v√† t·∫≠p test. File <code class="language-plaintext highlighter-rouge">train-features-50.txt</code> ch·ª©a d·ªØ li·ªáu c·ªßa t·∫≠p training thu g·ªçn v·ªõi ch·ªâ c√≥ t·ªïng c·ªông 50 training emails.</p>

<p>M·ªói file <code class="language-plaintext highlighter-rouge">*labels*.txt</code> ch·ª©a nhi·ªÅu d√≤ng, m·ªói d√≤ng l√† m·ªôt k√Ω t·ª± 0 ho·∫∑c 1 th·ªÉ hi·ªán email l√† <em>non-spam</em> ho·∫∑c <em>spam</em>.</p>

<p>M·ªói file <code class="language-plaintext highlighter-rouge">*features*.txt</code> ch·ª©a nhi·ªÅu d√≤ng, m·ªói d√≤ng c√≥ 3 s·ªë, v√≠ d·ª•:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1 564 1
1 19 2
</code></pre></div></div>

<p>trong ƒë√≥ s·ªë ƒë·∫ßu ti√™n l√† ch·ªâ s·ªë c·ªßa email, b·∫Øt ƒë·∫ßu t·ª´ 1; s·ªë th·ª© hai l√† th·ª© t·ª± c·ªßa t·ª´ trong t·ª´ ƒëi·ªÉn (t·ªïng c·ªông 2500 t·ª´); s·ªë th·ª© ba l√† s·ªë l∆∞·ª£ng c·ªßa t·ª´ ƒë√≥ trong email ƒëang x√©t. D√≤ng ƒë·∫ßu ti√™n n√≥i r·∫±ng trong email th·ª© nh·∫•t, t·ª´ th·ª© 564 trong t·ª´ ƒëi·ªÉn xu·∫•t hi·ªán 1 l·∫ßn. C√°ch l∆∞u d·ªØ li·ªáu nh∆∞ th·∫ø n√†y gi√∫p ti·∫øt ki·ªám b·ªô nh·ªõ v√¨ 1 email th∆∞·ªùng kh√¥ng ch·ª©a h·∫øt t·∫•t c·∫£ c√°c t·ª´ trong t·ª´ ƒëi·ªÉn m√† ch·ªâ ch·ª©a m·ªôt l∆∞·ª£ng nh·ªè, ta ch·ªâ c·∫ßn l∆∞u c√°c gi√° tr·ªã kh√°c kh√¥ng.</p>

<p>N·∫øu ta bi·ªÉu di·ªÖn feature vector c·ªßa m·ªói email l√† m·ªôt vector h√†ng c√≥ ƒë·ªô d√†i b·∫±ng ƒë·ªô d√†i t·ª´ ƒëi·ªÉn (2500) th√¨ d√≤ng th·ª© nh·∫•t n√≥i r·∫±ng th√†nh ph·∫ßn th·ª© 564 c·ªßa vector n√†y b·∫±ng 1. T∆∞∆°ng t·ª±, th√†nh ph·∫ßn th·ª© 19 c·ªßa vector n√†y b·∫±ng 1. N·∫øu kh√¥ng xu·∫•t hi·ªán, c√°c th√†nh ph·∫ßn kh√°c ƒë∆∞·ª£c m·∫∑c ƒë·ªãnh b·∫±ng 0.</p>

<p>D·ª±a tr√™n c√°c th√¥ng tin n√†y, ch√∫ng ta c√≥ th·ªÉ ti·∫øn h√†nh l·∫≠p tr√¨nh v·ªõi th∆∞ vi·ªán sklearn.</p>

<p><strong>Khai b√°o th∆∞ vi·ªán v√† ƒë∆∞·ªùng d·∫´n t·ªõi files:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">## packages 
</span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">division</span><span class="p">,</span> <span class="n">print_function</span><span class="p">,</span> <span class="n">unicode_literals</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">coo_matrix</span> <span class="c1"># for sparse matrix
</span><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">MultinomialNB</span><span class="p">,</span> <span class="n">BernoulliNB</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span> <span class="c1"># for evaluating results
</span>
<span class="c1"># data path and file name 
</span><span class="n">path</span> <span class="o">=</span> <span class="s">'ex6DataPrepared/'</span>
<span class="n">train_data_fn</span> <span class="o">=</span> <span class="s">'train-features.txt'</span>
<span class="n">test_data_fn</span> <span class="o">=</span> <span class="s">'test-features.txt'</span>
<span class="n">train_label_fn</span> <span class="o">=</span> <span class="s">'train-labels.txt'</span>
<span class="n">test_label_fn</span> <span class="o">=</span> <span class="s">'test-labels.txt'</span>
</code></pre></div></div>

<p>H√†m s·ªë ƒë·ªçc d·ªØ li·ªáu t·ª´ file <code class="language-plaintext highlighter-rouge">data_fn</code> v·ªõi labels t∆∞∆°ng ·ª©ng <code class="language-plaintext highlighter-rouge">label_fn</code>. Ch√∫ √Ω r·∫±ng <a href="http://openclassroom.stanford.edu/MainFolder/DocumentPage.php?course=MachineLearning&amp;doc=exercises/ex6/ex6.html">s·ªë l∆∞·ª£ng t·ª´ trong t·ª´ ƒëi·ªÉn l√† 2500</a>.</p>

<p>D·ªØ li·ªáu s·∫Ω ƒë∆∞·ª£c l∆∞u trong m·ªôt ma tr·∫≠n m√† m·ªói h√†ng th·ªÉ hi·ªán m·ªôt email. Ma tr·∫≠n n√†y l√† m·ªôt ma tr·∫≠n sparse n√™n ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng h√†m <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html"><code class="language-plaintext highlighter-rouge">scipy.sparse.coo_matrix</code></a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nwords</span> <span class="o">=</span> <span class="mi">2500</span> 

<span class="k">def</span> <span class="nf">read_data</span><span class="p">(</span><span class="n">data_fn</span><span class="p">,</span> <span class="n">label_fn</span><span class="p">):</span>
    <span class="c1">## read label_fn
</span>    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="n">label_fn</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">content</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="n">readlines</span><span class="p">()</span>
    <span class="n">label</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">strip</span><span class="p">())</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">content</span><span class="p">]</span>

    <span class="c1">## read data_fn
</span>    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="n">data_fn</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">content</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="n">readlines</span><span class="p">()</span>
    <span class="c1"># remove '\n' at the end of each line
</span>    <span class="n">content</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">content</span><span class="p">]</span> 

    <span class="n">dat</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">content</span><span class="p">),</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="nb">int</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">content</span><span class="p">):</span> 
        <span class="n">a</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">' '</span><span class="p">)</span>
        <span class="n">dat</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">int</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="nb">int</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="mi">2</span><span class="p">])])</span>
    
    <span class="c1"># remember to -1 at coordinate since we're in Python
</span>    <span class="c1"># check this: https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html
</span>    <span class="c1"># for more information about coo_matrix function 
</span>    <span class="n">data</span> <span class="o">=</span> <span class="n">coo_matrix</span><span class="p">((</span><span class="n">dat</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">(</span><span class="n">dat</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dat</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)),</span>\
             <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">label</span><span class="p">),</span> <span class="n">nwords</span><span class="p">))</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
</code></pre></div></div>

<p>ƒê·ªçc training data v√† test data, s·ª≠ d·ª•ng class <code class="language-plaintext highlighter-rouge">MultinomialNB</code> trong sklearn ƒë·ªÉ x√¢y d·ª±ng m√¥ h√¨nh v√† d·ª± ƒëo√°n ƒë·∫ßu ra cho test data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_label</span><span class="p">)</span>  <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="n">train_data_fn</span><span class="p">,</span> <span class="n">train_label_fn</span><span class="p">)</span>
<span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">test_label</span><span class="p">)</span>  <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="n">test_data_fn</span><span class="p">,</span> <span class="n">test_label_fn</span><span class="p">)</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">()</span>
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_label</span><span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Training size = %d, accuracy = %.2f%%'</span> <span class="o">%</span> \
      <span class="p">(</span><span class="n">train_data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Training size = 700, accuracy = 98.08%
</code></pre></div></div>

<p>V·∫≠y l√† c√≥ t·ªõi 98.08% c√°c email ƒë∆∞·ª£c ph√¢n lo·∫°i ƒë√∫ng. Ch√∫ng ta ti·∫øp t·ª•c th·ª≠ v·ªõi c√°c b·ªô d·ªØ li·ªáu training nh·ªè h∆°n:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_data_fn</span> <span class="o">=</span> <span class="s">'train-features-100.txt'</span>
<span class="n">train_label_fn</span> <span class="o">=</span> <span class="s">'train-labels-100.txt'</span>
<span class="n">test_data_fn</span> <span class="o">=</span> <span class="s">'test-features.txt'</span>
<span class="n">test_label_fn</span> <span class="o">=</span> <span class="s">'test-labels.txt'</span>

<span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_label</span><span class="p">)</span>  <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="n">train_data_fn</span><span class="p">,</span> <span class="n">train_label_fn</span><span class="p">)</span>
<span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">test_label</span><span class="p">)</span>  <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="n">test_data_fn</span><span class="p">,</span> <span class="n">test_label_fn</span><span class="p">)</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">()</span>
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_label</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Training size = %d, accuracy = %.2f%%'</span> <span class="o">%</span> \
      <span class="p">(</span><span class="n">train_data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Training size = 100, accuracy = 97.69%
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_data_fn</span> <span class="o">=</span> <span class="s">'train-features-50.txt'</span>
<span class="n">train_label_fn</span> <span class="o">=</span> <span class="s">'train-labels-50.txt'</span>
<span class="n">test_data_fn</span> <span class="o">=</span> <span class="s">'test-features.txt'</span>
<span class="n">test_label_fn</span> <span class="o">=</span> <span class="s">'test-labels.txt'</span>

<span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_label</span><span class="p">)</span>  <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="n">train_data_fn</span><span class="p">,</span> <span class="n">train_label_fn</span><span class="p">)</span>
<span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">test_label</span><span class="p">)</span>  <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="n">test_data_fn</span><span class="p">,</span> <span class="n">test_label_fn</span><span class="p">)</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">()</span>
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_label</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Training size = %d, accuracy = %.2f%%'</span> <span class="o">%</span> \
      <span class="p">(</span><span class="n">train_data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Training size = 50, accuracy = 97.31%
</code></pre></div></div>

<p>Ta th·∫•y r·∫±ng th·∫≠m ch√≠ khi t·∫≠p training l√† r·∫•t nh·ªè, 50 emails t·ªïng c·ªông, k·∫øt qu·∫£ ƒë·∫°t ƒë∆∞·ª£c ƒë√£ r·∫•t ·∫•n t∆∞·ª£ng.</p>

<p>N·∫øu b·∫°n mu·ªën ti·∫øp t·ª•c th·ª≠ m√¥ h√¨nh <code class="language-plaintext highlighter-rouge">BernoulliNB</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clf</span> <span class="o">=</span> <span class="n">BernoulliNB</span><span class="p">(</span><span class="n">binarize</span> <span class="o">=</span> <span class="p">.</span><span class="mi">5</span><span class="p">)</span>
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_label</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Training size = %d, accuracy = %.2f%%'</span> <span class="o">%</span> \
      <span class="p">(</span><span class="n">train_data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Training size = 50, accuracy = 69.62%
</code></pre></div></div>

<p>Ta th·∫•y r·∫±ng trong b√†i to√°n n√†y, <code class="language-plaintext highlighter-rouge">MultinomialNB</code> ho·∫°t ƒë·ªông hi·ªáu qu·∫£ h∆°n.</p>

<p><a name="-tom-tat"></a></p>

<h2 id="4-t√≥m-t·∫Øt">4. T√≥m t·∫Øt</h2>

<ul>
  <li>
    <p>Naive Bayes Classifiers (NBC) th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng trong c√°c b√†i to√°n Text Classification.</p>
  </li>
  <li>
    <p>NBC c√≥ th·ªùi gian training v√† test r·∫•t nhanh. ƒêi·ªÅu n√†y c√≥ ƒë∆∞·ª£c l√† do gi·∫£ s·ª≠ v·ªÅ t√≠nh ƒë·ªôc l·∫≠p gi·ªØa c√°c th√†nh ph·∫ßn, n·∫øu bi·∫øt class.</p>
  </li>
  <li>
    <p>N·∫øu gi·∫£ s·ª≠ v·ªÅ t√≠nh ƒë·ªôc l·∫≠p ƒë∆∞·ª£c tho·∫£ m√£n (d·ª±a v√†o b·∫£n ch·∫•t c·ªßa d·ªØ li·ªáu), NBC ƒë∆∞·ª£c cho l√† cho k·∫øt qu·∫£ t·ªët h∆°n so v·ªõi SVM v√† logistic regression khi c√≥ √≠t d·ªØ li·ªáu training.</p>
  </li>
  <li>
    <p>NBC c√≥ th·ªÉ ho·∫°t ƒë·ªông v·ªõi c√°c feature vector m√† m·ªôt ph·∫ßn l√† li√™n t·ª•c (s·ª≠ d·ª•ng Gaussian Naive Bayes), ph·∫ßn c√≤n l·∫°i ·ªü d·∫°ng r·ªùi r·∫°c (s·ª≠ d·ª•ng Multinomial ho·∫∑c Bernoulli).</p>
  </li>
  <li>
    <p>Khi s·ª≠ d·ª•ng Multinomial Naive Bayes, Laplace smoothing th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ tr√°nh tr∆∞·ªùng h·ª£p 1 th√†nh ph·∫ßn trong test data ch∆∞a xu·∫•t hi·ªán ·ªü training data.</p>
  </li>
  <li>
    <p><a href="https://github.com/tiepvupsu/tiepvupsu.github.io/blob/master/assets/32_nbc/python/Spam%20filtering.ipynb">Source code</a>.</p>
  </li>
</ul>

<p><a name="-tai-lieu-tham-khao"></a></p>

<h2 id="5-t√†i-li·ªáu-tham-kh·∫£o">5. T√†i li·ªáu tham kh·∫£o</h2>

<p>[1] <a href="https://web.stanford.edu/class/cs124/lec/naivebayes.pdf">Text Classification and Naive Bayes - Stanford</a></p>

<p>[2] <a href="http://openclassroom.stanford.edu/MainFolder/DocumentPage.php?course=MachineLearning&amp;doc=exercises/ex6/ex6.html">Exercise 6: Naive Bayes - Machine Learning - Andrew Ng</a></p>

<p>[3] <a href="http://scikit-learn.org/dev/modules/classes.html#module-sklearn.naive_bayes"><code class="language-plaintext highlighter-rouge">sklearn.naive_bayes</code></a></p>

<p>[4] <a href="https://www.analyticsvidhya.com/blog/2015/09/naive-bayes-explained/">6 Easy Steps to Learn Naive Bayes Algorithm (with code in Python)</a></p>
:ET